{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import textattack\n",
    "from textattack.models.wrappers import ModelWrapper\n",
    "from typing import List, Tuple\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from string import punctuation\n",
    "import argparse\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "import os\n",
    "import tarfile\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from bs4 import BeautifulSoup\n",
    "import torch\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import subprocess\n",
    "import zipfile\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure experiment\n",
    "perturbation_type = 'homoglyphs'  # options: 'homoglyphs', 'invisible', 'deletions', 'reorderings'\n",
    "store_temp_files = False\n",
    "store_results = True\n",
    "class Args:\n",
    "    pass\n",
    "args = Args()\n",
    "args.perturbation_type = perturbation_type\n",
    "args.store_temp_files = store_temp_files\n",
    "args.store_results = store_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(46313) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /opt/anaconda3/envs/disspt2/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (0.0.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/disspt2/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/envs/disspt2/lib/python3.9/site-packages (from bs4->-r requirements.txt (line 1)) (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/disspt2/lib/python3.9/site-packages (from requests->-r requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/disspt2/lib/python3.9/site-packages (from requests->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/disspt2/lib/python3.9/site-packages (from requests->-r requirements.txt (line 2)) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/disspt2/lib/python3.9/site-packages (from requests->-r requirements.txt (line 2)) (2025.4.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/disspt2/lib/python3.9/site-packages (from beautifulsoup4->bs4->-r requirements.txt (line 1)) (2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.51.3\n",
      "Uninstalling transformers-4.51.3:\n",
      "  Would remove:\n",
      "    /opt/anaconda3/envs/projenvconda39/bin/transformers-cli\n",
      "    /opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/transformers-4.51.3.dist-info/*\n",
      "    /opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/transformers/*\n",
      "Proceed (Y/n)? ^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e89d301f7b4b2d9fbb99777d2dd597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 50 files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f6ad096ac848b1a2cd26f54f02cd71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00050.safetensors:   5%|5         | 231M/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a9c700fd4e461ea10a285db2f706ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00050.safetensors:   5%|5         | 231M/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6021df7620774145a38188160faa9c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00050.safetensors:   5%|4         | 220M/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbe61c21aae4505a199be78fc1c993b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00050.safetensors:   5%|5         | 231M/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b240aaa8dc97433c835b75400e5a0a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00050.safetensors:   5%|4         | 199M/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c420a073d54401298caadc601730e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00050.safetensors:   5%|5         | 231M/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128ab8d02bbb43dfbcf2735e644bdedb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00050.safetensors:   6%|5         | 220M/3.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc8e14019e744db86e4449c807727ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00050.safetensors:   5%|5         | 231M/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/huggingface_hub/file_download.py:752: UserWarning: Not enough free disk space to download the file. The expected file size is: 4404.21 MB. The target location /Users/vlwk/.cache/huggingface/hub/models--meta-llama--Llama-4-Scout-17B-16E-Instruct/blobs only has 85.49 MB free disk space.\n",
      "  warnings.warn(\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f52299dabc048469b085d677e9a1060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00010-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d5a8081c0f4ba6830cf4c14c7fdb7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7c431367534a8796c778644404ad22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00011-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/huggingface_hub/file_download.py:752: UserWarning: Not enough free disk space to download the file. The expected file size is: 4404.21 MB. The target location /Users/vlwk/.cache/huggingface/hub/models--meta-llama--Llama-4-Scout-17B-16E-Instruct/blobs only has 84.80 MB free disk space.\n",
      "  warnings.warn(\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc919b2424694b5cacb3065df6d77153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00013-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0971e7ab166f4788ac2fef475af756a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00012-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/huggingface_hub/file_download.py:752: UserWarning: Not enough free disk space to download the file. The expected file size is: 4404.21 MB. The target location /Users/vlwk/.cache/huggingface/hub/models--meta-llama--Llama-4-Scout-17B-16E-Instruct/blobs only has 85.18 MB free disk space.\n",
      "  warnings.warn(\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d134f79a1cd44727ad5a4458b990e539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00014-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/huggingface_hub/file_download.py:752: UserWarning: Not enough free disk space to download the file. The expected file size is: 4404.21 MB. The target location /Users/vlwk/.cache/huggingface/hub/models--meta-llama--Llama-4-Scout-17B-16E-Instruct/blobs only has 85.15 MB free disk space.\n",
      "  warnings.warn(\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31444c20e244ab0a11ea06a3f25be07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00015-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6ecf423f034dc08bc7f1a35ffff50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00016-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "meta-llama/Llama-4-Scout-17B-16E-Instruct does not appear to have files named ('model-00001-of-00050.safetensors', 'model-00002-of-00050.safetensors', 'model-00003-of-00050.safetensors', 'model-00004-of-00050.safetensors', 'model-00005-of-00050.safetensors', 'model-00006-of-00050.safetensors', 'model-00007-of-00050.safetensors', 'model-00008-of-00050.safetensors', 'model-00009-of-00050.safetensors', 'model-00010-of-00050.safetensors', 'model-00011-of-00050.safetensors', 'model-00012-of-00050.safetensors', 'model-00013-of-00050.safetensors', 'model-00014-of-00050.safetensors', 'model-00015-of-00050.safetensors', 'model-00016-of-00050.safetensors', 'model-00017-of-00050.safetensors', 'model-00018-of-00050.safetensors', 'model-00019-of-00050.safetensors', 'model-00020-of-00050.safetensors', 'model-00021-of-00050.safetensors', 'model-00022-of-00050.safetensors', 'model-00023-of-00050.safetensors', 'model-00024-of-00050.safetensors', 'model-00025-of-00050.safetensors', 'model-00026-of-00050.safetensors', 'model-00027-of-00050.safetensors', 'model-00028-of-00050.safetensors', 'model-00029-of-00050.safetensors', 'model-00030-of-00050.safetensors', 'model-00031-of-00050.safetensors', 'model-00032-of-00050.safetensors', 'model-00033-of-00050.safetensors', 'model-00034-of-00050.safetensors', 'model-00035-of-00050.safetensors', 'model-00036-of-00050.safetensors', 'model-00037-of-00050.safetensors', 'model-00038-of-00050.safetensors', 'model-00039-of-00050.safetensors', 'model-00040-of-00050.safetensors', 'model-00041-of-00050.safetensors', 'model-00042-of-00050.safetensors', 'model-00043-of-00050.safetensors', 'model-00044-of-00050.safetensors', 'model-00045-of-00050.safetensors', 'model-00046-of-00050.safetensors', 'model-00047-of-00050.safetensors', 'model-00048-of-00050.safetensors', 'model-00049-of-00050.safetensors', 'model-00050-of-00050.safetensors'). Checkout 'https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct/tree/main'for available files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     10\u001b[0m ]\n\u001b[1;32m     11\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(messages, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLlama4ForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice), max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(outputs[:, inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/transformers/modeling_utils.py:279\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/transformers/modeling_utils.py:4260\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4251\u001b[0m     gguf_file\n\u001b[1;32m   4252\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4253\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[1;32m   4254\u001b[0m ):\n\u001b[1;32m   4255\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   4256\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4257\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded from GGUF files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4258\u001b[0m     )\n\u001b[0;32m-> 4260\u001b[0m checkpoint_files, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4262\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4267\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4273\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4276\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4278\u001b[0m is_sharded \u001b[38;5;241m=\u001b[39m sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4279\u001b[0m is_quantized \u001b[38;5;241m=\u001b[39m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/transformers/modeling_utils.py:1152\u001b[0m, in \u001b[0;36m_get_resolved_checkpoint_files\u001b[0;34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash)\u001b[0m\n\u001b[1;32m   1150\u001b[0m sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[0;32m-> 1152\u001b[0m     checkpoint_files, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_checkpoint_shard_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     checkpoint_files \u001b[38;5;241m=\u001b[39m [resolved_archive_file] \u001b[38;5;28;01mif\u001b[39;00m pretrained_model_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/transformers/utils/hub.py:1115\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m shard_filenames, sharded_metadata\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;66;03m# At this stage pretrained_model_name_or_path is a model identifier on the Hub. Try to get everything from cache,\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# or download the files\u001b[39;00m\n\u001b[0;32m-> 1115\u001b[0m cached_filenames \u001b[38;5;241m=\u001b[39m \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshard_filenames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached_filenames, sharded_metadata\n",
      "File \u001b[0;32m/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/transformers/utils/hub.py:517\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m     revision_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m revision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m revision\n\u001b[1;32m    514\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_entries[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_entries) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;241m*\u001b[39mmissing_entries,)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    516\u001b[0m     )\n\u001b[0;32m--> 517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    518\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Checkout \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/tree/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    519\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor available files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    520\u001b[0m     )\n\u001b[1;32m    522\u001b[0m \u001b[38;5;66;03m# Remove potential missing entries (we can silently remove them at this point based on the flags)\u001b[39;00m\n\u001b[1;32m    523\u001b[0m resolved_files \u001b[38;5;241m=\u001b[39m [file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m resolved_files \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[0;31mOSError\u001b[0m: meta-llama/Llama-4-Scout-17B-16E-Instruct does not appear to have files named ('model-00001-of-00050.safetensors', 'model-00002-of-00050.safetensors', 'model-00003-of-00050.safetensors', 'model-00004-of-00050.safetensors', 'model-00005-of-00050.safetensors', 'model-00006-of-00050.safetensors', 'model-00007-of-00050.safetensors', 'model-00008-of-00050.safetensors', 'model-00009-of-00050.safetensors', 'model-00010-of-00050.safetensors', 'model-00011-of-00050.safetensors', 'model-00012-of-00050.safetensors', 'model-00013-of-00050.safetensors', 'model-00014-of-00050.safetensors', 'model-00015-of-00050.safetensors', 'model-00016-of-00050.safetensors', 'model-00017-of-00050.safetensors', 'model-00018-of-00050.safetensors', 'model-00019-of-00050.safetensors', 'model-00020-of-00050.safetensors', 'model-00021-of-00050.safetensors', 'model-00022-of-00050.safetensors', 'model-00023-of-00050.safetensors', 'model-00024-of-00050.safetensors', 'model-00025-of-00050.safetensors', 'model-00026-of-00050.safetensors', 'model-00027-of-00050.safetensors', 'model-00028-of-00050.safetensors', 'model-00029-of-00050.safetensors', 'model-00030-of-00050.safetensors', 'model-00031-of-00050.safetensors', 'model-00032-of-00050.safetensors', 'model-00033-of-00050.safetensors', 'model-00034-of-00050.safetensors', 'model-00035-of-00050.safetensors', 'model-00036-of-00050.safetensors', 'model-00037-of-00050.safetensors', 'model-00038-of-00050.safetensors', 'model-00039-of-00050.safetensors', 'model-00040-of-00050.safetensors', 'model-00041-of-00050.safetensors', 'model-00042-of-00050.safetensors', 'model-00043-of-00050.safetensors', 'model-00044-of-00050.safetensors', 'model-00045-of-00050.safetensors', 'model-00046-of-00050.safetensors', 'model-00047-of-00050.safetensors', 'model-00048-of-00050.safetensors', 'model-00049-of-00050.safetensors', 'model-00050-of-00050.safetensors'). Checkout 'https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct/tree/main'for available files."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, Llama4ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\", return_dict=True)\n",
    "\n",
    "model = Llama4ForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "outputs = model.generate(**inputs.to(model.device), max_new_tokens=100)\n",
    "outputs = tokenizer.batch_decode(outputs[:, inputs[\"input_ids\"].shape[-1]:])\n",
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Llama4ScoutWrapper(ModelWrapper):\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "    def __call__(self, input_texts: List[str]) -> List[str]:\n",
    "        messages = []\n",
    "        for message in input_texts:\n",
    "            messages.append({\"role\": \"user\", \"content\": f\"This sentence is one of the following emotions: sadness, joy, love, anger, fear, surprise. Output the emotion. Sentence: {message}\"})\n",
    "        inputs = self.tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\", return_dict=True)\n",
    "        outputs = self.model.generate(**inputs.to(model.device), max_new_tokens=100)\n",
    "        outputs = self.tokenizer.batch_decode(outputs[:, inputs[\"input_ids\"].shape[-1]:])\n",
    "        return outputs.tolist()\n",
    "\n",
    "model_id = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = Llama4ForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "model_wrapper = Llama4ScoutWrapper(model, tokenizer)\n",
    "\n",
    "attack = textattack.attack_recipes.BadCharacters2021.build(\n",
    "    model_wrapper, \n",
    "    goal_function_type=\"targeted_bonus\",\n",
    "    perturbation_type=args.perturbation_type\n",
    ")\n",
    "dataset = textattack.datasets.HuggingFaceDataset(\"emotion\", split=\"test\")\n",
    "print(dataset[0])\n",
    "attack_args = textattack.AttackArgs(\n",
    "    num_examples=10,\n",
    "    log_to_csv=\"results/emotion/llama4scout/log.csv\"\n",
    ")\n",
    "attacker = textattack.Attacker(attack, dataset, attack_args)\n",
    "attacker.attack_dataset()\n",
    "\n",
    "if args.store_results == False:\n",
    "    if os.path.isdir(\"results/emotion/llama4scout\"):\n",
    "        shutil.rmtree(\"results/emotion/llama4scout\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT4 x Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from textattack.models.wrappers import ModelWrapper\n",
    "\n",
    "class GPT4Wrapper(ModelWrapper):\n",
    "    def __init__(self, system_prompt: str, temperature: float = 0.3):\n",
    "        self.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")\n",
    "\n",
    "        self.client = OpenAI(api_key=self.api_key)\n",
    "        self.system_prompt = system_prompt\n",
    "        self.temperature = temperature\n",
    "        self.model = self  # acts as a dummy reference to satisfy GoalFunction\n",
    "\n",
    "    def __call__(self, inputs: List[str]) -> List[List[float]]:\n",
    "        outputs = []\n",
    "        for text in inputs:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                ],\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=50\n",
    "            )\n",
    "            result = response.choices[0].message.content.strip()\n",
    "            arr = [0.0] * 6 \n",
    "            try:\n",
    "                idx = int(result)\n",
    "                if 0 <= idx < len(arr):\n",
    "                    arr[idx] = 1.0\n",
    "            except ValueError:\n",
    "                print(f\"Could not parse result: {result}\")\n",
    "            outputs.append(arr)\n",
    "        return outputs\n",
    "\n",
    "model_wrapper = GPT4Wrapper(\"This sentence is one of the following emotions: sadness (0), joy (1), love (2), anger (3), fear (4), surprise (5). Output the number of the emotion. Sentence:\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = textattack.attack_recipes.BadCharacters2021.build(\n",
    "    model_wrapper, \n",
    "    goal_function_type=\"targeted_bonus\",\n",
    "    perturbation_type=args.perturbation_type,\n",
    "    target_class=1,\n",
    "    perturbs=5,\n",
    "    popsize=3,\n",
    "    maxiter=1\n",
    ")\n",
    "dataset = textattack.datasets.HuggingFaceDataset(\"dair-ai/emotion\", split=\"test\")\n",
    "attack_args = textattack.AttackArgs(\n",
    "    num_examples=100,\n",
    "    checkpoint_interval=10,\n",
    "    checkpoint_dir=\"results/emotion/gpt4\",\n",
    "    log_to_csv=\"results/emotion/gpt4/log100.csv\"\n",
    ")\n",
    "attacker = textattack.Attacker(attack, dataset, attack_args)\n",
    "attacker.attack_dataset()\n",
    "\n",
    "if args.store_results == False:\n",
    "    if os.path.isdir(\"results/emotion/gpt4\"):\n",
    "        shutil.rmtree(\"results/emotion/gpt4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: No entry found for goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n",
      "textattack: Unknown if model of class <class '__main__.GPT4Wrapper'> compatible with goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n",
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mdair-ai/emotion\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
      "textattack: Logging to CSV at path results/emotion/gpt4/pert1/log50.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): DifferentialEvolution(\n",
      "    (popsize):  5\n",
      "    (maxiter):  3\n",
      "    (max_perturbs):  1\n",
      "    (verbose):  False\n",
      "  )\n",
      "  (goal_function):  TargetedBonus\n",
      "  (transformation):  WordSwapHomoglyphSwap\n",
      "  (constraints): None\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   2%|‚ñè         | 1/50 [00:04<03:35,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 0 / 2:   4%|‚ñç         | 2/50 [00:08<03:23,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 0 / 3:   6%|‚ñå         | 3/50 [00:15<04:01,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 3 / 0 / 4:   8%|‚ñä         | 4/50 [00:18<03:37,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my bouquet of red and yellow tulips under my arm feeling slightly more optimistic than when i arrived\n",
      "\n",
      "i left with my bouquet of red and yellow tulip—ï under my arm feeling slightly more optimistic than when i arrived\n",
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my bouquet of red and yellow [[tulips]] under my arm feeling slightly more optimistic than when i arrived\n",
      "\n",
      "i left with my bouquet of red and yellow [[tulip—ï]] under my arm feeling slightly more optimistic than when i arrived\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 3 / 0 / 5:  10%|‚ñà         | 5/50 [00:23<03:27,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling a little vain when i did this one\n",
      "\n",
      "i was feeling a littl–µ vain when i did this one\n",
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling a [[little]] vain when i did this one\n",
      "\n",
      "i was feeling a [[littl–µ]] vain when i did this one\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 4 / 0 / 6:  12%|‚ñà‚ñè        | 6/50 [00:26<03:14,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 5 / 0 / 7:  14%|‚ñà‚ñç        | 7/50 [00:29<02:58,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "\n",
      "\n",
      "Could not parse result: The emotion expressed in the sentence is sadness (0).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 6 / 0 / 8:  16%|‚ñà‚ñå        | 8/50 [00:36<03:11,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 6 / 0 / 9:  18%|‚ñà‚ñä        | 9/50 [00:41<03:09,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have the same breathless feeling as a reader eager to see what will happen next\n",
      "\n",
      "i like to have the same breathless feeling as a reader –µager to see what will happen next\n",
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have the same breathless feeling as a reader [[eager]] to see what will happen next\n",
      "\n",
      "i like to have the same breathless feeling as a reader [[–µager]] to see what will happen next\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 7 / 0 / 10:  20%|‚ñà‚ñà        | 10/50 [00:46<03:07,  4.70s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert1/1746360048690.ta.chkpt\" at 2025-05-04 13:00:48 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 8 / 0 / 11:  22%|‚ñà‚ñà‚ñè       | 11/50 [00:51<03:02,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "--------------------------------------------- Result 11 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 9 / 0 / 12:  24%|‚ñà‚ñà‚ñç       | 12/50 [00:54<02:53,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "--------------------------------------------- Result 12 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 10 / 0 / 13:  26%|‚ñà‚ñà‚ñå       | 13/50 [00:59<02:49,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "--------------------------------------------- Result 13 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 11 / 0 / 14:  28%|‚ñà‚ñà‚ñä       | 14/50 [01:04<02:45,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i just feel extremely comfortable with the group of people that i dont even need to hide myself\n",
      "--------------------------------------------- Result 14 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i just feel extremely comfortable with the group of people that i dont even need to hide myself\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 12 / 0 / 15:  30%|‚ñà‚ñà‚ñà       | 15/50 [01:08<02:39,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i find myself in the odd position of feeling supportive of\n",
      "--------------------------------------------- Result 15 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i find myself in the odd position of feeling supportive of\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 13 / 0 / 16:  32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [01:13<02:35,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "--------------------------------------------- Result 16 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 13 / 0 / 17:  34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [01:17<02:30,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel a little mellow today\n",
      "\n",
      "i feel –∞ little mellow today\n",
      "--------------------------------------------- Result 17 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel [[a]] little mellow today\n",
      "\n",
      "i feel [[–∞]] little mellow today\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 14 / 0 / 18:  36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [01:29<02:38,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "--------------------------------------------- Result 18 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 15 / 0 / 19:  38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [01:33<02:32,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "--------------------------------------------- Result 19 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 15 / 0 / 20:  40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [01:36<02:24,  4.81s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert1/1746360097865.ta.chkpt\" at 2025-05-04 13:01:37 after 20 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like reds and purples are just so rich and kind of perfect\n",
      "\n",
      "i feel like reds and purples are just —ïo rich and kind of perfect\n",
      "--------------------------------------------- Result 20 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like reds and purples are just [[so]] rich and kind of perfect\n",
      "\n",
      "i feel like reds and purples are just [[—ïo]] rich and kind of perfect\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 16 / 0 / 21:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [01:40<02:18,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "--------------------------------------------- Result 21 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 16 / 0 / 22:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [01:44<02:13,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like ive gotten to know many of you through comments and emails and for that im appreciative and glad you are a part of this little space\n",
      "\n",
      "i feel like ive gotten to know many of you through comments and emails and for that im appreciative and glad you are a part of this little spa—Åe\n",
      "--------------------------------------------- Result 22 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like ive gotten to know many of you through comments and emails and for that im appreciative and glad you are a part of this little [[space]]\n",
      "\n",
      "i feel like ive gotten to know many of you through comments and emails and for that im appreciative and glad you are a part of this little [[spa—Åe]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 16 / 0 / 23:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [01:53<02:13,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "i survey my own posts over the l–∞st few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "--------------------------------------------- Result 23 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over the [[last]] few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "i survey my own posts over the [[l–∞st]] few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 17 / 0 / 24:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [01:57<02:07,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "--------------------------------------------- Result 24 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 18 / 0 / 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [02:02<02:02,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel guilty like i m not going to be able to cook for him\n",
      "--------------------------------------------- Result 25 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel guilty like i m not going to be able to cook for him\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 19 / 0 / 26:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [02:06<01:56,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i hate it when i feel fearful for absolutely no reason\n",
      "--------------------------------------------- Result 26 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i hate it when i feel fearful for absolutely no reason\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 20 / 0 / 27:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [02:10<01:51,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i am feeling outraged it shows everywhere\n",
      "--------------------------------------------- Result 27 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i am feeling outraged it shows everywhere\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 21 / 0 / 28:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [02:14<01:45,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i stole a book from one of my all time favorite authors and now i feel like a rotten person\n",
      "--------------------------------------------- Result 28 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i stole a book from one of my all time favorite authors and now i feel like a rotten person\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 22 / 0 / 29:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [02:19<01:40,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i do feel insecure sometimes but who doesnt\n",
      "--------------------------------------------- Result 29 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i do feel insecure sometimes but who doesnt\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 22 / 0 / 30:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [02:24<01:36,  4.81s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert1/1746360145977.ta.chkpt\" at 2025-05-04 13:02:25 after 30 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i highly recommend visiting on a wednesday if youre able because its less crowded so you get to ask the farmers more questions without feeling rude for holding up a line\n",
      "\n",
      "i highly recommend visiting on a wednesday if youre able because its less crowded so you get to ask the farmers mor–µ questions without feeling rude for holding up a line\n",
      "--------------------------------------------- Result 30 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i highly recommend visiting on a wednesday if youre able because its less crowded so you get to ask the farmers [[more]] questions without feeling rude for holding up a line\n",
      "\n",
      "i highly recommend visiting on a wednesday if youre able because its less crowded so you get to ask the farmers [[mor–µ]] questions without feeling rude for holding up a line\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 23 / 0 / 31:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [02:28<01:31,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "ive been missing him and feeling so restless at home thinking of him\n",
      "--------------------------------------------- Result 31 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "ive been missing him and feeling so restless at home thinking of him\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 24 / 0 / 32:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [02:33<01:26,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i posted on my facebook page earlier this week ive been feeling a little grumpy and out of sorts the past few days\n",
      "--------------------------------------------- Result 32 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i posted on my facebook page earlier this week ive been feeling a little grumpy and out of sorts the past few days\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 24 / 0 / 33:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [02:36<01:20,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i start to feel emotional\n",
      "\n",
      "i start to feel emŒøtional\n",
      "--------------------------------------------- Result 33 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i start to feel [[emotional]]\n",
      "\n",
      "i start to feel [[emŒøtional]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 25 / 0 / 34:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [02:41<01:15,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel so cold a href http irish\n",
      "--------------------------------------------- Result 34 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel so cold a href http irish\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 26 / 0 / 35:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [02:47<01:11,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like i m defective or something for not having baby fever\n",
      "--------------------------------------------- Result 35 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like i m defective or something for not having baby fever\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 26 / 0 / 36:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [02:51<01:06,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel more virtuous than when i eat veggies dipped in hummus\n",
      "\n",
      "i feel more virtuous than when i eat v–µggies dipped in hummus\n",
      "--------------------------------------------- Result 36 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel more virtuous than when i eat [[veggies]] dipped in hummus\n",
      "\n",
      "i feel more virtuous than when i eat [[v–µggies]] dipped in hummus\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 26 / 0 / 37:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [02:54<01:01,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and clean living so highly im curious do any of you read magazines concerned with health and clean lifestyles such as the green parent\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and —Ålean living so highly im curious do any of you read magazines concerned with health and clean lifestyles such as the green parent\n",
      "--------------------------------------------- Result 37 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and [[clean]] living so highly im curious do any of you read magazines concerned with health and clean lifestyles such as the green parent\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and [[—Ålean]] living so highly im curious do any of you read magazines concerned with health and clean lifestyles such as the green parent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 27 / 0 / 38:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [02:59<00:56,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i spent the last two weeks of school feeling miserable\n",
      "--------------------------------------------- Result 38 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i spent the last two weeks of school feeling miserable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 28 / 0 / 39:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [03:03<00:51,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling very peaceful about our wedding again now after having\n",
      "--------------------------------------------- Result 39 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling very peaceful about our wedding again now after having\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 29 / 0 / 40:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [03:07<00:46,  4.69s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert1/1746360189425.ta.chkpt\" at 2025-05-04 13:03:09 after 40 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i had been talking to coach claudia barcomb and coach ali boe for a long time and they both made me feel very welcomed at union\n",
      "--------------------------------------------- Result 40 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i had been talking to coach claudia barcomb and coach ali boe for a long time and they both made me feel very welcomed at union\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 30 / 0 / 41:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [03:12<00:42,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel if i completely hated things i d exercise my democratic right speak my mind in what ever ways possible and try to enact a change\n",
      "--------------------------------------------- Result 41 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel if i completely hated things i d exercise my democratic right speak my mind in what ever ways possible and try to enact a change\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 31 / 0 / 42:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [03:16<00:37,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel humiliated embarrassed or foolish i will remember that others have felt the same way because of the same kinds of things and i will be kind and helpful and accepting\n",
      "--------------------------------------------- Result 42 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel humiliated embarrassed or foolish i will remember that others have felt the same way because of the same kinds of things and i will be kind and helpful and accepting\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 31 / 0 / 43:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [03:20<00:32,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel reassured that i am dealing with my diet in the right way and that all is good\n",
      "\n",
      "i feel reassured that —ñ am dealing with my diet in the right way and that all is good\n",
      "--------------------------------------------- Result 43 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel reassured that [[i]] am dealing with my diet in the right way and that all is good\n",
      "\n",
      "i feel reassured that [[—ñ]] am dealing with my diet in the right way and that all is good\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 32 / 0 / 44:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [03:25<00:28,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0.]) --> [FAILED]\n",
      "\n",
      "i feel i have to agree with her even though i can imagine some rather unpleasant possible cases\n",
      "--------------------------------------------- Result 44 ---------------------------------------------\n",
      "tensor([0., 0., 0., 0., 1., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel i have to agree with her even though i can imagine some rather unpleasant possible cases\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 32 / 0 / 45:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [03:30<00:23,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "im in such a happy mood today i feel almost delighted and i havent done anything different today then i normally have it is wonderful\n",
      "\n",
      "im in such a happy moŒød today i feel almost delighted and i havent done anything different today then i normally have it is wonderful\n",
      "--------------------------------------------- Result 45 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "im in such a happy [[mood]] today i feel almost delighted and i havent done anything different today then i normally have it is wonderful\n",
      "\n",
      "im in such a happy [[moŒød]] today i feel almost delighted and i havent done anything different today then i normally have it is wonderful\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 33 / 0 / 46:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [03:34<00:18,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling really out of place and irritated\n",
      "--------------------------------------------- Result 46 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling really out of place and irritated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 34 / 0 / 47:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [03:39<00:14,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also know that i feel nothing than a friendly affection to them too\n",
      "--------------------------------------------- Result 47 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also know that i feel nothing than a friendly affection to them too\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 14 / 34 / 0 / 48:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [03:44<00:09,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like i had a rather productive weekend and i cant always say that no matter how much i get done\n",
      "\n",
      "i feel like i had a r–∞ther productive weekend and i cant always say that no matter how much i get done\n",
      "--------------------------------------------- Result 48 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like i had a [[rather]] productive weekend and i cant always say that no matter how much i get done\n",
      "\n",
      "i feel like i had a [[r–∞ther]] productive weekend and i cant always say that no matter how much i get done\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 14 / 35 / 0 / 49:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [03:48<00:04,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling insecure at the moment\n",
      "--------------------------------------------- Result 49 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling insecure at the moment\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 35 / 0 / 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [03:53<00:00,  4.66s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert1/1746360234736.ta.chkpt\" at 2025-05-04 13:03:54 after 50 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling pretty anxious all day but my first day at work was a very good day and that helped a lot\n",
      "\n",
      "i was feeling pretty anx—ñous all day but my first day at work was a very good day and that helped a lot\n",
      "--------------------------------------------- Result 50 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling pretty [[anxious]] all day but my first day at work was a very good day and that helped a lot\n",
      "\n",
      "i was feeling pretty [[anx—ñous]] all day but my first day at work was a very good day and that helped a lot\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 35 / 0 / 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [03:53<00:00,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 15     |\n",
      "| Number of failed attacks:     | 35     |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 70.0%  |\n",
      "| Attack success rate:          | 30.0%  |\n",
      "| Average perturbed word %:     | 6.75%  |\n",
      "| Average num. words per input: | 18.56  |\n",
      "| Avg num queries:              | 13.8   |\n",
      "+-------------------------------+--------+"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "textattack: No entry found for goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n",
      "textattack: Unknown if model of class <class '__main__.GPT4Wrapper'> compatible with goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mdair-ai/emotion\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
      "textattack: Logging to CSV at path results/emotion/gpt4/pert2/log50.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): DifferentialEvolution(\n",
      "    (popsize):  5\n",
      "    (maxiter):  3\n",
      "    (max_perturbs):  2\n",
      "    (verbose):  False\n",
      "  )\n",
      "  (goal_function):  TargetedBonus\n",
      "  (transformation):  WordSwapHomoglyphSwap\n",
      "  (constraints): None\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   2%|‚ñè         | 1/50 [00:08<06:39,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 0 / 2:   4%|‚ñç         | 2/50 [00:19<07:37,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 0 / 3:   6%|‚ñå         | 3/50 [00:28<07:19,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 3 / 0 / 4:   8%|‚ñä         | 4/50 [00:36<07:05,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my bouquet of red and yellow tulips under my arm feeling slightly more optimistic than when i arrived\n",
      "\n",
      "i left with my bŒøuquet of red and yellow tulips under my arm feeling slightly more optimistic than when i arriv–µd\n",
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my [[bouquet]] of red and yellow tulips under my arm feeling slightly more optimistic than when i [[arrived]]\n",
      "\n",
      "i left with my [[bŒøuquet]] of red and yellow tulips under my arm feeling slightly more optimistic than when i [[arriv–µd]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 3 / 0 / 5:  10%|‚ñà         | 5/50 [00:47<07:08,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling a little vain when i did this one\n",
      "\n",
      "i was feeling a littl–µ va—ñn when i did this one\n",
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling a [[little]] [[vain]] when i did this one\n",
      "\n",
      "i was feeling a [[littl–µ]] [[va—ñn]] when i did this one\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 4 / 0 / 6:  12%|‚ñà‚ñè        | 6/50 [00:58<07:11,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 5 / 0 / 7:  14%|‚ñà‚ñç        | 7/50 [01:07<06:56,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 6 / 0 / 8:  16%|‚ñà‚ñå        | 8/50 [01:18<06:54,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 6 / 0 / 9:  18%|‚ñà‚ñä        | 9/50 [01:26<06:32,  9.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have the same breathless feeling as a reader eager to see what will happen next\n",
      "\n",
      "i like to have the same breathless feeling as a read–µr eag–µr to see what will happen next\n",
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have the same breathless feeling as a [[reader]] [[eager]] to see what will happen next\n",
      "\n",
      "i like to have the same breathless feeling as a [[read–µr]] [[eag–µr]] to see what will happen next\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 7 / 0 / 10:  20%|‚ñà‚ñà        | 10/50 [01:34<06:18,  9.47s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert2/1746360331043.ta.chkpt\" at 2025-05-04 13:05:31 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 8 / 0 / 11:  22%|‚ñà‚ñà‚ñè       | 11/50 [01:42<06:04,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "--------------------------------------------- Result 11 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 9 / 0 / 12:  24%|‚ñà‚ñà‚ñç       | 12/50 [01:54<06:02,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "--------------------------------------------- Result 12 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 10 / 0 / 13:  26%|‚ñà‚ñà‚ñå       | 13/50 [02:03<05:50,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "--------------------------------------------- Result 13 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 11 / 0 / 14:  28%|‚ñà‚ñà‚ñä       | 14/50 [02:13<05:43,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i just feel extremely comfortable with the group of people that i dont even need to hide myself\n",
      "--------------------------------------------- Result 14 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i just feel extremely comfortable with the group of people that i dont even need to hide myself\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 11 / 0 / 15:  30%|‚ñà‚ñà‚ñà       | 15/50 [02:29<05:49, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i find myself in the odd position of feeling supportive of\n",
      "\n",
      "i find myself in the odd position of feeling sup—Äortive of\n",
      "--------------------------------------------- Result 15 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i find myself in the odd position of feeling [[supportive]] of\n",
      "\n",
      "i find myself in the odd position of feeling [[sup—Äortive]] of\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 12 / 0 / 16:  32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [02:39<05:38,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "--------------------------------------------- Result 16 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 12 / 0 / 17:  34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [02:51<05:33, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel a little mellow today\n",
      "\n",
      "i f–µel a l—ñttle mellow today\n",
      "--------------------------------------------- Result 17 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i [[feel]] a [[little]] mellow today\n",
      "\n",
      "i [[f–µel]] a [[l—ñttle]] mellow today\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 13 / 0 / 18:  36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [03:02<05:23, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "--------------------------------------------- Result 18 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 14 / 0 / 19:  38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [03:17<05:22, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "--------------------------------------------- Result 19 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 14 / 0 / 20:  40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [03:29<05:14, 10.47s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert2/1746360445857.ta.chkpt\" at 2025-05-04 13:07:25 after 20 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like reds and purples are just so rich and kind of perfect\n",
      "\n",
      "i feel like reds and purples are just so ric“ª an‘Å kind of perfect\n",
      "--------------------------------------------- Result 20 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like reds and purples are just so [[rich]] [[and]] kind of perfect\n",
      "\n",
      "i feel like reds and purples are just so [[ric“ª]] [[an‘Å]] kind of perfect\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 15 / 0 / 21:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [03:38<05:02, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "--------------------------------------------- Result 21 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 15 / 0 / 22:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [03:47<04:49, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like ive gotten to know many of you through comments and emails and for that im appreciative and glad you are a part of this little space\n",
      "\n",
      "i feel lik–µ ive gotten to know many of you through comments and emails and for that im appreciative an‘Å glad you are a part of this little space\n",
      "--------------------------------------------- Result 22 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel [[like]] ive gotten to know many of you through comments and emails and for that im appreciative [[and]] glad you are a part of this little space\n",
      "\n",
      "i feel [[lik–µ]] ive gotten to know many of you through comments and emails and for that im appreciative [[an‘Å]] glad you are a part of this little space\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 15 / 0 / 23:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [04:05<04:48, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of –∞ few Œøf them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "--------------------------------------------- Result 23 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of [[a]] few [[of]] them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of [[–∞]] few [[Œøf]] them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 16 / 0 / 24:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [04:14<04:35, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "--------------------------------------------- Result 24 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 17 / 0 / 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [04:25<04:25, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel guilty like i m not going to be able to cook for him\n",
      "--------------------------------------------- Result 25 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel guilty like i m not going to be able to cook for him\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 18 / 0 / 26:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [04:33<04:12, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0.]) --> [FAILED]\n",
      "\n",
      "i hate it when i feel fearful for absolutely no reason\n",
      "--------------------------------------------- Result 26 ---------------------------------------------\n",
      "tensor([0., 0., 0., 0., 1., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i hate it when i feel fearful for absolutely no reason\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 19 / 0 / 27:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [04:42<04:00, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i am feeling outraged it shows everywhere\n",
      "--------------------------------------------- Result 27 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i am feeling outraged it shows everywhere\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 20 / 0 / 28:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [04:52<03:49, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i stole a book from one of my all time favorite authors and now i feel like a rotten person\n",
      "--------------------------------------------- Result 28 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i stole a book from one of my all time favorite authors and now i feel like a rotten person\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 21 / 0 / 29:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [05:01<03:37, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i do feel insecure sometimes but who doesnt\n",
      "--------------------------------------------- Result 29 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i do feel insecure sometimes but who doesnt\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 21 / 0 / 30:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [05:10<03:26, 10.35s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert2/1746360546809.ta.chkpt\" at 2025-05-04 13:09:06 after 30 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i highly recommend visiting on a wednesday if youre able because its less crowded so you get to ask the farmers more questions without feeling rude for holding up a line\n",
      "\n",
      "i highly recommend visiting on a wednesday if yŒøure able because its less crowded so you get to ask the farmers mŒøre questions without feeling rude for holding up a line\n",
      "--------------------------------------------- Result 30 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i highly recommend visiting on a wednesday if [[youre]] able because its less crowded so you get to ask the farmers [[more]] questions without feeling rude for holding up a line\n",
      "\n",
      "i highly recommend visiting on a wednesday if [[yŒøure]] able because its less crowded so you get to ask the farmers [[mŒøre]] questions without feeling rude for holding up a line\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 22 / 0 / 31:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [05:21<03:16, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "ive been missing him and feeling so restless at home thinking of him\n",
      "--------------------------------------------- Result 31 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "ive been missing him and feeling so restless at home thinking of him\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 23 / 0 / 32:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [05:32<03:07, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i posted on my facebook page earlier this week ive been feeling a little grumpy and out of sorts the past few days\n",
      "--------------------------------------------- Result 32 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i posted on my facebook page earlier this week ive been feeling a little grumpy and out of sorts the past few days\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 23 / 0 / 33:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [05:44<02:57, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i start to feel emotional\n",
      "\n",
      "—ñ start to feel emotiŒønal\n",
      "--------------------------------------------- Result 33 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "[[i]] start to feel [[emotional]]\n",
      "\n",
      "[[—ñ]] start to feel [[emotiŒønal]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 24 / 0 / 34:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [05:56<02:47, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel so cold a href http irish\n",
      "--------------------------------------------- Result 34 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel so cold a href http irish\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 25 / 0 / 35:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [06:04<02:36, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like i m defective or something for not having baby fever\n",
      "--------------------------------------------- Result 35 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like i m defective or something for not having baby fever\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 25 / 0 / 36:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [06:11<02:24, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel more virtuous than when i eat veggies dipped in hummus\n",
      "\n",
      "i feel mor–µ virtuous than wh–µn i eat veggies dipped in hummus\n",
      "--------------------------------------------- Result 36 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel [[more]] virtuous than [[when]] i eat veggies dipped in hummus\n",
      "\n",
      "i feel [[mor–µ]] virtuous than [[wh–µn]] i eat veggies dipped in hummus\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 25 / 0 / 37:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [06:21<02:13, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and clean living so highly im curious do any of you read magazines concerned with health and clean lifestyles such as the green parent\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and clean living so highly im curious do any of you read m–∞gazines concerned with health and cl–µan lifestyles such as the green parent\n",
      "--------------------------------------------- Result 37 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and clean living so highly im curious do any of you read [[magazines]] concerned with health and [[clean]] lifestyles such as the green parent\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and clean living so highly im curious do any of you read [[m–∞gazines]] concerned with health and [[cl–µan]] lifestyles such as the green parent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 26 / 0 / 38:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [06:29<02:03, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i spent the last two weeks of school feeling miserable\n",
      "--------------------------------------------- Result 38 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i spent the last two weeks of school feeling miserable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 27 / 0 / 39:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [06:37<01:52, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling very peaceful about our wedding again now after having\n",
      "--------------------------------------------- Result 39 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling very peaceful about our wedding again now after having\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 27 / 0 / 40:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [06:54<01:43, 10.36s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert2/1746360650938.ta.chkpt\" at 2025-05-04 13:10:50 after 40 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i had been talking to coach claudia barcomb and coach ali boe for a long time and they both made me feel very welcomed at union\n",
      "\n",
      "i had been talking to coac“ª claudia barcomb and coach ali boe for a long time and they both made me f–µel very welcomed at union\n",
      "--------------------------------------------- Result 40 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i had been talking to [[coach]] claudia barcomb and coach ali boe for a long time and they both made me [[feel]] very welcomed at union\n",
      "\n",
      "i had been talking to [[coac“ª]] claudia barcomb and coach ali boe for a long time and they both made me [[f–µel]] very welcomed at union\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 28 / 0 / 41:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [07:04<01:33, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel if i completely hated things i d exercise my democratic right speak my mind in what ever ways possible and try to enact a change\n",
      "--------------------------------------------- Result 41 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel if i completely hated things i d exercise my democratic right speak my mind in what ever ways possible and try to enact a change\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 29 / 0 / 42:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [07:14<01:22, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel humiliated embarrassed or foolish i will remember that others have felt the same way because of the same kinds of things and i will be kind and helpful and accepting\n",
      "--------------------------------------------- Result 42 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel humiliated embarrassed or foolish i will remember that others have felt the same way because of the same kinds of things and i will be kind and helpful and accepting\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 14 / 29 / 0 / 43:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [07:28<01:12, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel reassured that i am dealing with my diet in the right way and that all is good\n",
      "\n",
      "i feel reassured that i am dealing with my d—ñet in the right way and that all —ñs good\n",
      "--------------------------------------------- Result 43 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel reassured that i am dealing with my [[diet]] in the right way and that all [[is]] good\n",
      "\n",
      "i feel reassured that i am dealing with my [[d—ñet]] in the right way and that all [[—ñs]] good\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 14 / 30 / 0 / 44:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [07:40<01:02, 10.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0.]) --> [FAILED]\n",
      "\n",
      "i feel i have to agree with her even though i can imagine some rather unpleasant possible cases\n",
      "--------------------------------------------- Result 44 ---------------------------------------------\n",
      "tensor([0., 0., 0., 0., 1., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel i have to agree with her even though i can imagine some rather unpleasant possible cases\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 30 / 0 / 45:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [07:48<00:52, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "im in such a happy mood today i feel almost delighted and i havent done anything different today then i normally have it is wonderful\n",
      "\n",
      "im in such a happy mood tŒøday i feel almost d–µlighted and i havent done anything different today then i normally have it is wonderful\n",
      "--------------------------------------------- Result 45 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "im in such a happy mood [[today]] i feel almost [[delighted]] and i havent done anything different today then i normally have it is wonderful\n",
      "\n",
      "im in such a happy mood [[tŒøday]] i feel almost [[d–µlighted]] and i havent done anything different today then i normally have it is wonderful\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 31 / 0 / 46:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [07:57<00:41, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling really out of place and irritated\n",
      "--------------------------------------------- Result 46 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling really out of place and irritated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 32 / 0 / 47:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [08:06<00:31, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also know that i feel nothing than a friendly affection to them too\n",
      "--------------------------------------------- Result 47 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also know that i feel nothing than a friendly affection to them too\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 16 / 32 / 0 / 48:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [08:14<00:20, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like i had a rather productive weekend and i cant always say that no matter how much i get done\n",
      "\n",
      "i feel like i had a rather prŒøductive weekend and i cant –∞lways say that no matter how much i get done\n",
      "--------------------------------------------- Result 48 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like i had a rather [[productive]] weekend and i cant [[always]] say that no matter how much i get done\n",
      "\n",
      "i feel like i had a rather [[prŒøductive]] weekend and i cant [[–∞lways]] say that no matter how much i get done\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 16 / 33 / 0 / 49:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [08:26<00:10, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling insecure at the moment\n",
      "--------------------------------------------- Result 49 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling insecure at the moment\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 17 / 33 / 0 / 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [08:34<00:00, 10.29s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert2/1746360750975.ta.chkpt\" at 2025-05-04 13:12:30 after 50 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling pretty anxious all day but my first day at work was a very good day and that helped a lot\n",
      "\n",
      "i was feeling pretty an—Öious all day but my first day at work w–∞s a very good day and that helped a lot\n",
      "--------------------------------------------- Result 50 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling pretty [[anxious]] all day but my first day at work [[was]] a very good day and that helped a lot\n",
      "\n",
      "i was feeling pretty [[an—Öious]] all day but my first day at work [[w–∞s]] a very good day and that helped a lot\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 17 / 33 / 0 / 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [08:34<00:00, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 17     |\n",
      "| Number of failed attacks:     | 33     |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 66.0%  |\n",
      "| Attack success rate:          | 34.0%  |\n",
      "| Average perturbed word %:     | 12.9%  |\n",
      "| Average num. words per input: | 18.56  |\n",
      "| Avg num queries:              | 26.2   |\n",
      "+-------------------------------+--------+"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "textattack: No entry found for goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n",
      "textattack: Unknown if model of class <class '__main__.GPT4Wrapper'> compatible with goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mdair-ai/emotion\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
      "textattack: Logging to CSV at path results/emotion/gpt4/pert3/log50.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): DifferentialEvolution(\n",
      "    (popsize):  5\n",
      "    (maxiter):  3\n",
      "    (max_perturbs):  3\n",
      "    (verbose):  False\n",
      "  )\n",
      "  (goal_function):  TargetedBonus\n",
      "  (transformation):  WordSwapHomoglyphSwap\n",
      "  (constraints): None\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   2%|‚ñè         | 1/50 [00:15<12:43, 15.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 0 / 2:   4%|‚ñç         | 2/50 [00:30<12:10, 15.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 0 / 3:   6%|‚ñå         | 3/50 [00:44<11:33, 14.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 3 / 0 / 4:   8%|‚ñä         | 4/50 [01:02<11:53, 15.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my bouquet of red and yellow tulips under my arm feeling slightly more optimistic than when i arrived\n",
      "\n",
      "i left with my bouquet of red and yellow tulips under my arm feeling slightly more Œø—Ät—ñmistic than when i arrived\n",
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my bouquet of red and yellow tulips under my arm feeling slightly more [[optimistic]] than when i arrived\n",
      "\n",
      "i left with my bouquet of red and yellow tulips under my arm feeling slightly more [[Œø—Ät—ñmistic]] than when i arrived\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 3 / 0 / 5:  10%|‚ñà         | 5/50 [01:28<13:16, 17.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling a little vain when i did this one\n",
      "\n",
      "i was feel—ñng a little vain when —ñ did this one\n",
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was [[feeling]] a little vain when [[i]] did this one\n",
      "\n",
      "i was [[feel—ñng]] a little vain when [[—ñ]] did this one\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 4 / 0 / 6:  12%|‚ñà‚ñè        | 6/50 [01:41<12:26, 16.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 5 / 0 / 7:  14%|‚ñà‚ñç        | 7/50 [01:55<11:52, 16.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "\n",
      "\n",
      "Could not parse result: The emotion conveyed in the sentence is sadness (0).\n",
      "Could not parse result: The sentence expresses a sense of confusion and reflection on a relationship that may not have been fulfilling, which can be associated with sadness. Therefore, the emotion is: \n",
      "\n",
      "0\n",
      "Could not parse result: The emotion expressed in the sentence is sadness (0).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 6 / 0 / 8:  16%|‚ñà‚ñå        | 8/50 [02:23<12:33, 17.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 6 / 0 / 9:  18%|‚ñà‚ñä        | 9/50 [02:38<12:02, 17.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have the same breathless feeling as a reader eager to see what will happen next\n",
      "\n",
      "i like to have th–µ same breat“ªl–µss feeling as a reader eager to see what will happen next\n",
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have [[the]] same [[breathless]] feeling as a reader eager to see what will happen next\n",
      "\n",
      "i like to have [[th–µ]] same [[breat“ªl–µss]] feeling as a reader eager to see what will happen next\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 7 / 0 / 10:  20%|‚ñà‚ñà        | 10/50 [02:53<11:33, 17.34s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert3/1746360926669.ta.chkpt\" at 2025-05-04 13:15:26 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 8 / 0 / 11:  22%|‚ñà‚ñà‚ñè       | 11/50 [03:09<11:12, 17.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "--------------------------------------------- Result 11 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 9 / 0 / 12:  24%|‚ñà‚ñà‚ñç       | 12/50 [03:23<10:44, 16.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "--------------------------------------------- Result 12 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 10 / 0 / 13:  26%|‚ñà‚ñà‚ñå       | 13/50 [03:40<10:26, 16.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "--------------------------------------------- Result 13 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 10 / 0 / 14:  28%|‚ñà‚ñà‚ñä       | 14/50 [04:08<10:38, 17.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i just feel extremely comfortable with the group of people that i dont even need to hide myself\n",
      "\n",
      "i œ≥ust feel extremely comfortable with the group of people t“ªat i dont even ne–µd to hide myself\n",
      "--------------------------------------------- Result 14 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i [[just]] feel extremely comfortable with the group of people [[that]] i dont even [[need]] to hide myself\n",
      "\n",
      "i [[œ≥ust]] feel extremely comfortable with the group of people [[t“ªat]] i dont even [[ne–µd]] to hide myself\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 11 / 0 / 15:  30%|‚ñà‚ñà‚ñà       | 15/50 [04:20<10:08, 17.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i find myself in the odd position of feeling supportive of\n",
      "--------------------------------------------- Result 15 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i find myself in the odd position of feeling supportive of\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 12 / 0 / 16:  32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [04:34<09:44, 17.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "--------------------------------------------- Result 16 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 12 / 0 / 17:  34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [04:58<09:39, 17.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel a little mellow today\n",
      "\n",
      "i feel a little m–µllŒøw tod–∞y\n",
      "--------------------------------------------- Result 17 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel a little [[mellow]] [[today]]\n",
      "\n",
      "i feel a little [[m–µllŒøw]] [[tod–∞y]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 13 / 0 / 18:  36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [05:10<09:12, 17.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "--------------------------------------------- Result 18 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 14 / 0 / 19:  38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [05:24<08:50, 17.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "--------------------------------------------- Result 19 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 14 / 0 / 20:  40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [05:37<08:26, 16.87s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert3/1746361090771.ta.chkpt\" at 2025-05-04 13:18:10 after 20 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like reds and purples are just so rich and kind of perfect\n",
      "\n",
      "i feel like r–µds and purples are just so rich and kind of —Äerfect\n",
      "--------------------------------------------- Result 20 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like [[reds]] and purples are just so rich and kind of [[perfect]]\n",
      "\n",
      "i feel like [[r–µds]] and purples are just so rich and kind of [[—Äerfect]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 15 / 0 / 21:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [05:52<08:07, 16.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "--------------------------------------------- Result 21 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 15 / 0 / 22:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [06:08<07:48, 16.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like ive gotten to know many of you through comments and emails and for that im appreciative and glad you are a part of this little space\n",
      "\n",
      "i feel like ive gotten to know many of you thrŒøugh comment—ï and emails and for that im appreciative and glad you are –∞ part of this little space\n",
      "--------------------------------------------- Result 22 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like ive gotten to know many of you [[through]] [[comments]] and emails and for that im appreciative and glad you are [[a]] part of this little space\n",
      "\n",
      "i feel like ive gotten to know many of you [[thrŒøugh]] [[comment—ï]] and emails and for that im appreciative and glad you are [[–∞]] part of this little space\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 15 / 0 / 23:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [06:33<07:42, 17.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "i survey my own posts over t“ªe la—ït few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture w“ªat its like to be me or someone like me in dublin in the st century\n",
      "--------------------------------------------- Result 23 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over [[the]] [[last]] few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture [[what]] its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "i survey my own posts over [[t“ªe]] [[la—ït]] few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture [[w“ªat]] its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 16 / 0 / 24:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [06:46<07:20, 16.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "--------------------------------------------- Result 24 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 17 / 0 / 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [07:02<07:02, 16.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel guilty like i m not going to be able to cook for him\n",
      "--------------------------------------------- Result 25 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel guilty like i m not going to be able to cook for him\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 18 / 0 / 26:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [07:19<06:45, 16.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0.]) --> [FAILED]\n",
      "\n",
      "i hate it when i feel fearful for absolutely no reason\n",
      "--------------------------------------------- Result 26 ---------------------------------------------\n",
      "tensor([0., 0., 0., 0., 1., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i hate it when i feel fearful for absolutely no reason\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 19 / 0 / 27:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [07:34<06:27, 16.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i am feeling outraged it shows everywhere\n",
      "--------------------------------------------- Result 27 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i am feeling outraged it shows everywhere\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 20 / 0 / 28:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [07:49<06:08, 16.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i stole a book from one of my all time favorite authors and now i feel like a rotten person\n",
      "--------------------------------------------- Result 28 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i stole a book from one of my all time favorite authors and now i feel like a rotten person\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 21 / 0 / 29:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [08:02<05:49, 16.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i do feel insecure sometimes but who doesnt\n",
      "--------------------------------------------- Result 29 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i do feel insecure sometimes but who doesnt\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 21 / 0 / 30:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [08:16<05:31, 16.55s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert3/1746361249926.ta.chkpt\" at 2025-05-04 13:20:49 after 30 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i highly recommend visiting on a wednesday if youre able because its less crowded so you get to ask the farmers more questions without feeling rude for holding up a line\n",
      "\n",
      "i highly recommend visiting on –∞ we‘Ånesday if youre able because its less crowded so you get to ask the farmers more questions without feeling rude for hold—ñng up a line\n",
      "--------------------------------------------- Result 30 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i highly recommend visiting on [[a]] [[wednesday]] if youre able because its less crowded so you get to ask the farmers more questions without feeling rude for [[holding]] up a line\n",
      "\n",
      "i highly recommend visiting on [[–∞]] [[we‘Ånesday]] if youre able because its less crowded so you get to ask the farmers more questions without feeling rude for [[hold—ñng]] up a line\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 22 / 0 / 31:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [08:33<05:14, 16.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "ive been missing him and feeling so restless at home thinking of him\n",
      "--------------------------------------------- Result 31 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "ive been missing him and feeling so restless at home thinking of him\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 23 / 0 / 32:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [08:47<04:56, 16.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i posted on my facebook page earlier this week ive been feeling a little grumpy and out of sorts the past few days\n",
      "--------------------------------------------- Result 32 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i posted on my facebook page earlier this week ive been feeling a little grumpy and out of sorts the past few days\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 23 / 0 / 33:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [09:11<04:44, 16.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i start to feel emotional\n",
      "\n",
      "—ñ start to feel emotion–∞l\n",
      "--------------------------------------------- Result 33 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "[[i]] start to feel [[emotional]]\n",
      "\n",
      "[[—ñ]] start to feel [[emotion–∞l]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 24 / 0 / 34:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [09:28<04:27, 16.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel so cold a href http irish\n",
      "--------------------------------------------- Result 34 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel so cold a href http irish\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 25 / 0 / 35:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [09:40<04:08, 16.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like i m defective or something for not having baby fever\n",
      "--------------------------------------------- Result 35 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like i m defective or something for not having baby fever\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 25 / 0 / 36:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [09:55<03:51, 16.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel more virtuous than when i eat veggies dipped in hummus\n",
      "\n",
      "i f–µel more virtuous than when i e–∞t veggies dipped —ñn hummus\n",
      "--------------------------------------------- Result 36 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i [[feel]] more virtuous than when i [[eat]] veggies dipped [[in]] hummus\n",
      "\n",
      "i [[f–µel]] more virtuous than when i [[e–∞t]] veggies dipped [[—ñn]] hummus\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 25 / 0 / 37:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [10:11<03:34, 16.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and clean living so highly im curious do any of you read magazines concerned with health and clean lifestyles such as the green parent\n",
      "\n",
      "i feel very honoured to be included in a m–∞gzine whic“ª prioritises health and clean living so highly im curious do any of you read magazines cŒøncerned with health and clean lifestyles such as the green parent\n",
      "--------------------------------------------- Result 37 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel very honoured to be included in a [[magzine]] [[which]] prioritises health and clean living so highly im curious do any of you read magazines [[concerned]] with health and clean lifestyles such as the green parent\n",
      "\n",
      "i feel very honoured to be included in a [[m–∞gzine]] [[whic“ª]] prioritises health and clean living so highly im curious do any of you read magazines [[cŒøncerned]] with health and clean lifestyles such as the green parent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 26 / 0 / 38:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [10:25<03:17, 16.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i spent the last two weeks of school feeling miserable\n",
      "--------------------------------------------- Result 38 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i spent the last two weeks of school feeling miserable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 27 / 0 / 39:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [10:39<03:00, 16.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling very peaceful about our wedding again now after having\n",
      "--------------------------------------------- Result 39 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling very peaceful about our wedding again now after having\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 27 / 0 / 40:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [11:08<02:47, 16.72s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert3/1746361421893.ta.chkpt\" at 2025-05-04 13:23:41 after 40 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i had been talking to coach claudia barcomb and coach ali boe for a long time and they both made me feel very welcomed at union\n",
      "\n",
      "i had been talking to coach —Ålaudia barcomb –∞nd coach ali boe for a long time and they both made me feel very welcom–µd at union\n",
      "--------------------------------------------- Result 40 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i had been talking to coach [[claudia]] barcomb [[and]] coach ali boe for a long time and they both made me feel very [[welcomed]] at union\n",
      "\n",
      "i had been talking to coach [[—Ålaudia]] barcomb [[–∞nd]] coach ali boe for a long time and they both made me feel very [[welcom–µd]] at union\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 28 / 0 / 41:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [11:23<02:29, 16.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel if i completely hated things i d exercise my democratic right speak my mind in what ever ways possible and try to enact a change\n",
      "--------------------------------------------- Result 41 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel if i completely hated things i d exercise my democratic right speak my mind in what ever ways possible and try to enact a change\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 29 / 0 / 42:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [11:37<02:12, 16.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel humiliated embarrassed or foolish i will remember that others have felt the same way because of the same kinds of things and i will be kind and helpful and accepting\n",
      "--------------------------------------------- Result 42 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel humiliated embarrassed or foolish i will remember that others have felt the same way because of the same kinds of things and i will be kind and helpful and accepting\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 14 / 29 / 0 / 43:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [11:52<01:56, 16.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel reassured that i am dealing with my diet in the right way and that all is good\n",
      "\n",
      "i feel re–∞ssured that i am dealing w—ñth my diet in the r—ñght way and that all is good\n",
      "--------------------------------------------- Result 43 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel [[reassured]] that i am dealing [[with]] my diet in the [[right]] way and that all is good\n",
      "\n",
      "i feel [[re–∞ssured]] that i am dealing [[w—ñth]] my diet in the [[r—ñght]] way and that all is good\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 14 / 30 / 0 / 44:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [12:06<01:39, 16.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0.]) --> [FAILED]\n",
      "\n",
      "i feel i have to agree with her even though i can imagine some rather unpleasant possible cases\n",
      "--------------------------------------------- Result 44 ---------------------------------------------\n",
      "tensor([0., 0., 0., 0., 1., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel i have to agree with her even though i can imagine some rather unpleasant possible cases\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 30 / 0 / 45:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [12:20<01:22, 16.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "im in such a happy mood today i feel almost delighted and i havent done anything different today then i normally have it is wonderful\n",
      "\n",
      "im in su—Åh a happy mood tŒøday i feel almost delighted and i havent done anything different today then i normally have it —ñs wonderful\n",
      "--------------------------------------------- Result 45 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "im in [[such]] a happy mood [[today]] i feel almost delighted and i havent done anything different today then i normally have it [[is]] wonderful\n",
      "\n",
      "im in [[su—Åh]] a happy mood [[tŒøday]] i feel almost delighted and i havent done anything different today then i normally have it [[—ñs]] wonderful\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 31 / 0 / 46:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [12:37<01:05, 16.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling really out of place and irritated\n",
      "--------------------------------------------- Result 46 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling really out of place and irritated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 32 / 0 / 47:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [12:51<00:49, 16.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also know that i feel nothing than a friendly affection to them too\n",
      "--------------------------------------------- Result 47 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also know that i feel nothing than a friendly affection to them too\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 16 / 32 / 0 / 48:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [13:09<00:32, 16.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like i had a rather productive weekend and i cant always say that no matter how much i get done\n",
      "\n",
      "i feel like i had a rat“ªer productive weekend and i cant always say t“ªat no matter how much i g–µt done\n",
      "--------------------------------------------- Result 48 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like i had a [[rather]] productive weekend and i cant always say [[that]] no matter how much i [[get]] done\n",
      "\n",
      "i feel like i had a [[rat“ªer]] productive weekend and i cant always say [[t“ªat]] no matter how much i [[g–µt]] done\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 16 / 33 / 0 / 49:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [13:35<00:16, 16.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling insecure at the moment\n",
      "--------------------------------------------- Result 49 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling insecure at the moment\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 17 / 33 / 0 / 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [13:48<00:00, 16.58s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert3/1746361582125.ta.chkpt\" at 2025-05-04 13:26:22 after 50 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling pretty anxious all day but my first day at work was a very good day and that helped a lot\n",
      "\n",
      "i was feeling pretty anxious all d–∞y but my first day at work was a v–µr—É good day and that helped a lot\n",
      "--------------------------------------------- Result 50 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling pretty anxious all [[day]] but my first day at work was a [[very]] good day and that helped a lot\n",
      "\n",
      "i was feeling pretty anxious all [[d–∞y]] but my first day at work was a [[v–µr—É]] good day and that helped a lot\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 17 / 33 / 0 / 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [13:48<00:00, 16.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 17     |\n",
      "| Number of failed attacks:     | 33     |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 66.0%  |\n",
      "| Attack success rate:          | 34.0%  |\n",
      "| Average perturbed word %:     | 15.27% |\n",
      "| Average num. words per input: | 18.56  |\n",
      "| Avg num queries:              | 39.2   |\n",
      "+-------------------------------+--------+"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "textattack: No entry found for goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n",
      "textattack: Unknown if model of class <class '__main__.GPT4Wrapper'> compatible with goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mdair-ai/emotion\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
      "textattack: Logging to CSV at path results/emotion/gpt4/pert4/log50.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): DifferentialEvolution(\n",
      "    (popsize):  5\n",
      "    (maxiter):  3\n",
      "    (max_perturbs):  4\n",
      "    (verbose):  False\n",
      "  )\n",
      "  (goal_function):  TargetedBonus\n",
      "  (transformation):  WordSwapHomoglyphSwap\n",
      "  (constraints): None\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   2%|‚ñè         | 1/50 [00:18<14:48, 18.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 0 / 2:   4%|‚ñç         | 2/50 [00:36<14:30, 18.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 0 / 3:   6%|‚ñå         | 3/50 [00:58<15:09, 19.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 3 / 0 / 4:   8%|‚ñä         | 4/50 [01:18<15:00, 19.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my bouquet of red and yellow tulips under my arm feeling slightly more optimistic than when i arrived\n",
      "\n",
      "i left with my bouquet of red and yellŒøw tulips under my arm f–µeling slightly mor–µ o—Ätimistic than when i arrived\n",
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my bouquet of red and [[yellow]] tulips under my arm [[feeling]] slightly [[more]] [[optimistic]] than when i arrived\n",
      "\n",
      "i left with my bouquet of red and [[yellŒøw]] tulips under my arm [[f–µeling]] slightly [[mor–µ]] [[o—Ätimistic]] than when i arrived\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 3 / 0 / 5:  10%|‚ñà         | 5/50 [01:55<17:16, 23.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling a little vain when i did this one\n",
      "\n",
      "—ñ was feeling a little vain when —ñ di‘Å this one\n",
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "[[i]] was feeling a little vain when [[i]] [[did]] this one\n",
      "\n",
      "[[—ñ]] was feeling a little vain when [[—ñ]] [[di‘Å]] this one\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 4 / 0 / 6:  12%|‚ñà‚ñè        | 6/50 [02:12<16:14, 22.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 5 / 0 / 7:  14%|‚ñà‚ñç        | 7/50 [02:33<15:41, 21.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "\n",
      "\n",
      "Could not parse result: The emotion expressed in the sentence is sadness (0).\n",
      "Could not parse result: The emotion expressed in the sentence is sadness (0).\n",
      "Could not parse result: The sentence expresses a sense of reflection on a relationship that seems to be tied to feelings of disappointment or confusion, particularly in contrast to a positive event like being accepted into a master's program. This suggests an underlying sadness about the relationship. Therefore, the emotion\n",
      "Could not parse result: The emotion expressed in the sentence is sadness (0).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 6 / 0 / 8:  16%|‚ñà‚ñå        | 8/50 [03:14<17:01, 24.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 6 / 0 / 9:  18%|‚ñà‚ñä        | 9/50 [03:37<16:28, 24.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have the same breathless feeling as a reader eager to see what will happen next\n",
      "\n",
      "i like to hav–µ the —ïam–µ breathless feeling as a rea‘Åer eager to see what will happen next\n",
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to [[have]] the [[same]] breathless feeling as a [[reader]] eager to see what will happen next\n",
      "\n",
      "i like to [[hav–µ]] the [[—ïam–µ]] breathless feeling as a [[rea‘Åer]] eager to see what will happen next\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 7 / 0 / 10:  20%|‚ñà‚ñà        | 10/50 [03:56<15:45, 23.64s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert4/1746361820403.ta.chkpt\" at 2025-05-04 13:30:20 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 8 / 0 / 11:  22%|‚ñà‚ñà‚ñè       | 11/50 [04:16<15:08, 23.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "--------------------------------------------- Result 11 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 9 / 0 / 12:  24%|‚ñà‚ñà‚ñç       | 12/50 [04:34<14:30, 22.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "--------------------------------------------- Result 12 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 10 / 0 / 13:  26%|‚ñà‚ñà‚ñå       | 13/50 [04:52<13:53, 22.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "--------------------------------------------- Result 13 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 10 / 0 / 14:  28%|‚ñà‚ñà‚ñä       | 14/50 [05:30<14:10, 23.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i just feel extremely comfortable with the group of people that i dont even need to hide myself\n",
      "\n",
      "i just feel extremely comfortable with t“ªe group of peo—Äle that i dont even n–µed to hide m—Éself\n",
      "--------------------------------------------- Result 14 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i just feel extremely comfortable with [[the]] group of [[people]] that i dont even [[need]] to hide [[myself]]\n",
      "\n",
      "i just feel extremely comfortable with [[t“ªe]] group of [[peo—Äle]] that i dont even [[n–µed]] to hide [[m—Éself]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 10 / 0 / 15:  30%|‚ñà‚ñà‚ñà       | 15/50 [06:07<14:17, 24.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i find myself in the odd position of feeling supportive of\n",
      "\n",
      "i find myself in the odd pos—ñtion of feeling sup—ÄŒørtiv–µ of\n",
      "--------------------------------------------- Result 15 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i find myself in the odd [[position]] of feeling [[supportive]] of\n",
      "\n",
      "i find myself in the odd [[pos—ñtion]] of feeling [[sup—ÄŒørtiv–µ]] of\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 11 / 0 / 16:  32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [06:25<13:39, 24.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "--------------------------------------------- Result 16 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 11 / 0 / 17:  34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [07:07<13:49, 25.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel a little mellow today\n",
      "\n",
      "i feel a little m–µllŒøw tod–∞y\n",
      "--------------------------------------------- Result 17 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel a little [[mellow]] [[today]]\n",
      "\n",
      "i feel a little [[m–µllŒøw]] [[tod–∞y]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 12 / 0 / 18:  36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [07:27<13:15, 24.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "--------------------------------------------- Result 18 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 13 / 0 / 19:  38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [07:47<12:42, 24.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "--------------------------------------------- Result 19 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 13 / 0 / 20:  40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [08:06<12:09, 24.33s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert4/1746362070601.ta.chkpt\" at 2025-05-04 13:34:30 after 20 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like reds and purples are just so rich and kind of perfect\n",
      "\n",
      "i feel like r–µd—ï and purples are just so rich –∞nd kind Œøf perfect\n",
      "--------------------------------------------- Result 20 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like [[reds]] and purples are just so rich [[and]] kind [[of]] perfect\n",
      "\n",
      "i feel like [[r–µd—ï]] and purples are just so rich [[–∞nd]] kind [[Œøf]] perfect\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 14 / 0 / 21:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [08:26<11:38, 24.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "--------------------------------------------- Result 21 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 14 / 0 / 22:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [08:44<11:07, 23.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like ive gotten to know many of you through comments and emails and for that im appreciative and glad you are a part of this little space\n",
      "\n",
      "—ñ feel like ive gotten to know many of you t“ªrough comments and emails and for that im appreciat—ñve and gla‘Å you are a part of this little space\n",
      "--------------------------------------------- Result 22 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "[[i]] feel like ive gotten to know many of you [[through]] comments and emails and for that im [[appreciative]] and [[glad]] you are a part of this little space\n",
      "\n",
      "[[—ñ]] feel like ive gotten to know many of you [[t“ªrough]] comments and emails and for that im [[appreciat—ñve]] and [[gla‘Å]] you are a part of this little space\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 14 / 0 / 23:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [09:22<11:00, 24.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of a few of th–µm only feel that little bits of them capture wh–∞t its like to be me or someŒøne like me in dublin in the st —Åentury\n",
      "--------------------------------------------- Result 23 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of a few of [[them]] only feel that little bits of them capture [[what]] its like to be me or [[someone]] like me in dublin in the st [[century]]\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of a few of [[th–µm]] only feel that little bits of them capture [[wh–∞t]] its like to be me or [[someŒøne]] like me in dublin in the st [[—Åentury]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 15 / 0 / 24:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [09:44<10:33, 24.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "--------------------------------------------- Result 24 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 16 / 0 / 25:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [10:06<10:06, 24.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel guilty like i m not going to be able to cook for him\n",
      "--------------------------------------------- Result 25 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel guilty like i m not going to be able to cook for him\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 17 / 0 / 26:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [10:27<09:38, 24.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0.]) --> [FAILED]\n",
      "\n",
      "i hate it when i feel fearful for absolutely no reason\n",
      "--------------------------------------------- Result 26 ---------------------------------------------\n",
      "tensor([0., 0., 0., 0., 1., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i hate it when i feel fearful for absolutely no reason\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 18 / 0 / 27:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [10:48<09:12, 24.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i am feeling outraged it shows everywhere\n",
      "--------------------------------------------- Result 27 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i am feeling outraged it shows everywhere\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 19 / 0 / 28:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [11:09<08:45, 23.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i stole a book from one of my all time favorite authors and now i feel like a rotten person\n",
      "--------------------------------------------- Result 28 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i stole a book from one of my all time favorite authors and now i feel like a rotten person\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 20 / 0 / 29:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [11:30<08:19, 23.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i do feel insecure sometimes but who doesnt\n",
      "--------------------------------------------- Result 29 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i do feel insecure sometimes but who doesnt\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 20 / 0 / 30:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [11:53<07:55, 23.78s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert4/1746362297277.ta.chkpt\" at 2025-05-04 13:38:17 after 30 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i highly recommend visiting on a wednesday if youre able because its less crowded so you get to ask the farmers more questions without feeling rude for holding up a line\n",
      "\n",
      "i highly re—Åommend visit—ñng on a wedne—ïday if yŒøure able because its less crowded so you get to ask the farmers more questions without feeling rude for holding up a line\n",
      "--------------------------------------------- Result 30 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i highly [[recommend]] [[visiting]] on a [[wednesday]] if [[youre]] able because its less crowded so you get to ask the farmers more questions without feeling rude for holding up a line\n",
      "\n",
      "i highly [[re—Åommend]] [[visit—ñng]] on a [[wedne—ïday]] if [[yŒøure]] able because its less crowded so you get to ask the farmers more questions without feeling rude for holding up a line\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 21 / 0 / 31:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [12:13<07:29, 23.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "ive been missing him and feeling so restless at home thinking of him\n",
      "--------------------------------------------- Result 31 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "ive been missing him and feeling so restless at home thinking of him\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 22 / 0 / 32:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [12:41<07:08, 23.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i posted on my facebook page earlier this week ive been feeling a little grumpy and out of sorts the past few days\n",
      "--------------------------------------------- Result 32 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i posted on my facebook page earlier this week ive been feeling a little grumpy and out of sorts the past few days\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 23 / 0 / 33:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [13:00<06:41, 23.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i start to feel emotional\n",
      "--------------------------------------------- Result 33 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i start to feel emotional\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 24 / 0 / 34:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [13:21<06:17, 23.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel so cold a href http irish\n",
      "--------------------------------------------- Result 34 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel so cold a href http irish\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 25 / 0 / 35:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [13:39<05:51, 23.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like i m defective or something for not having baby fever\n",
      "--------------------------------------------- Result 35 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like i m defective or something for not having baby fever\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 25 / 0 / 36:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [13:58<05:26, 23.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel more virtuous than when i eat veggies dipped in hummus\n",
      "\n",
      "i feel more virtuŒøus th–∞n when i eat veggie—ï dipp–µd in hummus\n",
      "--------------------------------------------- Result 36 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel more [[virtuous]] [[than]] when i eat [[veggies]] [[dipped]] in hummus\n",
      "\n",
      "i feel more [[virtuŒøus]] [[th–∞n]] when i eat [[veggie—ï]] [[dipp–µd]] in hummus\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 25 / 0 / 37:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [14:19<05:02, 23.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and clean living so highly im curious do any of you read magazines concerned with health and clean lifestyles such as the green parent\n",
      "\n",
      "i feel very honoured to be included in a magzine which —Ärioritises health and clean l—ñving so “ªighly im curious do any of you read magazines concerned with “ªealth and clean lifestyles such as the green parent\n",
      "--------------------------------------------- Result 37 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel very honoured to be included in a magzine which [[prioritises]] health and clean [[living]] so [[highly]] im curious do any of you read magazines concerned with [[health]] and clean lifestyles such as the green parent\n",
      "\n",
      "i feel very honoured to be included in a magzine which [[—Ärioritises]] health and clean [[l—ñving]] so [[“ªighly]] im curious do any of you read magazines concerned with [[“ªealth]] and clean lifestyles such as the green parent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 26 / 0 / 38:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [14:37<04:37, 23.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i spent the last two weeks of school feeling miserable\n",
      "--------------------------------------------- Result 38 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i spent the last two weeks of school feeling miserable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 27 / 0 / 39:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [14:57<04:13, 23.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling very peaceful about our wedding again now after having\n",
      "--------------------------------------------- Result 39 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling very peaceful about our wedding again now after having\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 27 / 0 / 40:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [15:41<03:55, 23.53s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert4/1746362525123.ta.chkpt\" at 2025-05-04 13:42:05 after 40 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i had been talking to coach claudia barcomb and coach ali boe for a long time and they both made me feel very welcomed at union\n",
      "\n",
      "i had been talking to coa—Åh clau‘Åia barcomb and coach ali boe for a long time and they both made me feel very welcom–µd at union\n",
      "--------------------------------------------- Result 40 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i had been talking to [[coach]] [[claudia]] barcomb and coach ali boe for a long time and they both made me feel very [[welcomed]] at union\n",
      "\n",
      "i had been talking to [[coa—Åh]] [[clau‘Åia]] barcomb and coach ali boe for a long time and they both made me feel very [[welcom–µd]] at union\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 28 / 0 / 41:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [15:59<03:30, 23.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel if i completely hated things i d exercise my democratic right speak my mind in what ever ways possible and try to enact a change\n",
      "--------------------------------------------- Result 41 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel if i completely hated things i d exercise my democratic right speak my mind in what ever ways possible and try to enact a change\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 29 / 0 / 42:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [16:21<03:06, 23.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel humiliated embarrassed or foolish i will remember that others have felt the same way because of the same kinds of things and i will be kind and helpful and accepting\n",
      "--------------------------------------------- Result 42 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel humiliated embarrassed or foolish i will remember that others have felt the same way because of the same kinds of things and i will be kind and helpful and accepting\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 14 / 29 / 0 / 43:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [16:40<02:42, 23.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel reassured that i am dealing with my diet in the right way and that all is good\n",
      "\n",
      "i fe–µl reassured that i am dealing with my diet in the right way and that –∞ll i—ï goŒød\n",
      "--------------------------------------------- Result 43 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i [[feel]] reassured that i am dealing with my diet in the right way and that [[all]] [[is]] [[good]]\n",
      "\n",
      "i [[fe–µl]] reassured that i am dealing with my diet in the right way and that [[–∞ll]] [[i—ï]] [[goŒød]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 14 / 30 / 0 / 44:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [17:00<02:19, 23.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0.]) --> [FAILED]\n",
      "\n",
      "i feel i have to agree with her even though i can imagine some rather unpleasant possible cases\n",
      "--------------------------------------------- Result 44 ---------------------------------------------\n",
      "tensor([0., 0., 0., 0., 1., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel i have to agree with her even though i can imagine some rather unpleasant possible cases\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 30 / 0 / 45:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [17:19<01:55, 23.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "im in such a happy mood today i feel almost delighted and i havent done anything different today then i normally have it is wonderful\n",
      "\n",
      "im —ñn such a happy mood today i feel almost delighted and i havent done anything different tod–∞y then i norm–∞lly have it is wŒønderful\n",
      "--------------------------------------------- Result 45 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "im [[in]] such a happy mood today i feel almost delighted and i havent done anything different [[today]] then i [[normally]] have it is [[wonderful]]\n",
      "\n",
      "im [[—ñn]] such a happy mood today i feel almost delighted and i havent done anything different [[tod–∞y]] then i [[norm–∞lly]] have it is [[wŒønderful]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 31 / 0 / 46:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [17:45<01:32, 23.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling really out of place and irritated\n",
      "--------------------------------------------- Result 46 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling really out of place and irritated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 32 / 0 / 47:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [18:05<01:09, 23.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also know that i feel nothing than a friendly affection to them too\n",
      "--------------------------------------------- Result 47 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also know that i feel nothing than a friendly affection to them too\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 16 / 32 / 0 / 48:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [18:24<00:46, 23.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like i had a rather productive weekend and i cant always say that no matter how much i get done\n",
      "\n",
      "i feel lik–µ i had a rather productive weekend and i cant always say th–∞t no m–∞tt–µr how much i get done\n",
      "--------------------------------------------- Result 48 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel [[like]] i had a rather productive weekend and i cant always say [[that]] no [[matter]] how much i get done\n",
      "\n",
      "i feel [[lik–µ]] i had a rather productive weekend and i cant always say [[th–∞t]] no [[m–∞tt–µr]] how much i get done\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 16 / 33 / 0 / 49:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [18:42<00:22, 22.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling insecure at the moment\n",
      "--------------------------------------------- Result 49 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling insecure at the moment\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 17 / 33 / 0 / 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [19:01<00:00, 22.84s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert4/1746362725824.ta.chkpt\" at 2025-05-04 13:45:25 after 50 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling pretty anxious all day but my first day at work was a very good day and that helped a lot\n",
      "\n",
      "i was feeling pretty anxious –∞ll day but my first day at wŒørk w–∞s a very good day –∞nd that helped a lot\n",
      "--------------------------------------------- Result 50 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling pretty anxious [[all]] day but my first day at [[work]] [[was]] a very good day [[and]] that helped a lot\n",
      "\n",
      "i was feeling pretty anxious [[–∞ll]] day but my first day at [[wŒørk]] [[w–∞s]] a very good day [[–∞nd]] that helped a lot\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 17 / 33 / 0 / 50: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [19:01<00:00, 22.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 17     |\n",
      "| Number of failed attacks:     | 33     |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 66.0%  |\n",
      "| Attack success rate:          | 34.0%  |\n",
      "| Average perturbed word %:     | 18.67% |\n",
      "| Average num. words per input: | 18.56  |\n",
      "| Avg num queries:              | 51.6   |\n",
      "+-------------------------------+--------+"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "textattack: No entry found for goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n",
      "textattack: Unknown if model of class <class '__main__.GPT4Wrapper'> compatible with goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mdair-ai/emotion\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
      "textattack: Logging to CSV at path results/emotion/gpt4/pert5/log50.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): DifferentialEvolution(\n",
      "    (popsize):  5\n",
      "    (maxiter):  3\n",
      "    (max_perturbs):  5\n",
      "    (verbose):  False\n",
      "  )\n",
      "  (goal_function):  TargetedBonus\n",
      "  (transformation):  WordSwapHomoglyphSwap\n",
      "  (constraints): None\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   2%|‚ñè         | 1/50 [00:25<21:07, 25.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 0 / 2:   4%|‚ñç         | 2/50 [00:49<19:52, 24.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 0 / 3:   6%|‚ñå         | 3/50 [01:14<19:19, 24.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 3 / 0 / 4:   8%|‚ñä         | 4/50 [01:42<19:38, 25.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my bouquet of red and yellow tulips under my arm feeling slightly more optimistic than when i arrived\n",
      "\n",
      "—ñ left with my bouquet of red –∞nd yellow tul—ñ—Äs under my arm fe–µling slightly more optimistic than when i arrived\n",
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "[[i]] left with my bouquet of red [[and]] yellow [[tulips]] under my arm [[feeling]] slightly more optimistic than when i arrived\n",
      "\n",
      "[[—ñ]] left with my bouquet of red [[–∞nd]] yellow [[tul—ñ—Äs]] under my arm [[fe–µling]] slightly more optimistic than when i arrived\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 3 / 0 / 5:  10%|‚ñà         | 5/50 [02:39<23:53, 31.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling a little vain when i did this one\n",
      "\n",
      "—ñ was feel—ñng –∞ little vain when i did this one\n",
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "[[i]] was [[feeling]] [[a]] little vain when i did this one\n",
      "\n",
      "[[—ñ]] was [[feel—ñng]] [[–∞]] little vain when i did this one\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 4 / 0 / 6:  12%|‚ñà‚ñè        | 6/50 [03:09<23:08, 31.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 5 / 0 / 7:  14%|‚ñà‚ñç        | 7/50 [03:36<22:07, 30.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "\n",
      "\n",
      "Could not parse result: The sentence expresses a sense of reflection and possibly disappointment regarding a relationship, which suggests an underlying sadness. Therefore, the emotion is sadness (0).\n",
      "Could not parse result: The sentence expresses a sense of conflict and disappointment regarding a relationship that overshadowed a positive achievement, which leans towards sadness. Therefore, the emotion is: 0.\n",
      "Could not parse result: The emotion expressed in the sentence is sadness (0).\n",
      "Could not parse result: The emotion expressed in the sentence is sadness (0).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 6 / 0 / 8:  16%|‚ñà‚ñå        | 8/50 [04:25<23:15, 33.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 6 / 0 / 9:  18%|‚ñà‚ñä        | 9/50 [04:52<22:13, 32.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have the same breathless feeling as a reader eager to see what will happen next\n",
      "\n",
      "i like to have the same breathless feeling as a reader e–∞ger to see w“ªat w—ñll h–∞ppen n–µxt\n",
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have the same breathless feeling as a reader [[eager]] to see [[what]] [[will]] [[happen]] [[next]]\n",
      "\n",
      "i like to have the same breathless feeling as a reader [[e–∞ger]] to see [[w“ªat]] [[w—ñll]] [[h–∞ppen]] [[n–µxt]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 7 / 0 / 10:  20%|‚ñà‚ñà        | 10/50 [05:26<21:46, 32.65s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert5/1746363054292.ta.chkpt\" at 2025-05-04 13:50:54 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 8 / 0 / 11:  22%|‚ñà‚ñà‚ñè       | 11/50 [05:51<20:46, 31.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "--------------------------------------------- Result 11 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 9 / 0 / 12:  24%|‚ñà‚ñà‚ñç       | 12/50 [06:16<19:52, 31.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "--------------------------------------------- Result 12 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 10 / 0 / 13:  26%|‚ñà‚ñà‚ñå       | 13/50 [06:40<18:59, 30.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "--------------------------------------------- Result 13 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 10 / 0 / 14:  28%|‚ñà‚ñà‚ñä       | 14/50 [07:28<19:14, 32.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i just feel extremely comfortable with the group of people that i dont even need to hide myself\n",
      "\n",
      "i just f–µel extremely comfortable with the group Œøf peopl–µ that i dont even nee‘Å to hide myself\n",
      "--------------------------------------------- Result 14 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i just [[feel]] extremely comfortable with the group [[of]] [[people]] that i dont even [[need]] to hide myself\n",
      "\n",
      "i just [[f–µel]] extremely comfortable with the group [[Œøf]] [[peopl–µ]] that i dont even [[nee‘Å]] to hide myself\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 11 / 0 / 15:  30%|‚ñà‚ñà‚ñà       | 15/50 [07:56<18:31, 31.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i find myself in the odd position of feeling supportive of\n",
      "--------------------------------------------- Result 15 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i find myself in the odd position of feeling supportive of\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 12 / 0 / 16:  32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [08:24<17:51, 31.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "--------------------------------------------- Result 16 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 12 / 0 / 17:  34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [09:12<17:52, 32.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel a little mellow today\n",
      "\n",
      "i f–µel a littl–µ mellŒøw tŒøday\n",
      "--------------------------------------------- Result 17 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i [[feel]] a [[little]] [[mellow]] [[today]]\n",
      "\n",
      "i [[f–µel]] a [[littl–µ]] [[mellŒøw]] [[tŒøday]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 13 / 0 / 18:  36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [09:40<17:12, 32.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "--------------------------------------------- Result 18 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 14 / 0 / 19:  38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [10:04<16:26, 31.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "--------------------------------------------- Result 19 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 14 / 0 / 20:  40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [10:30<15:45, 31.51s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert5/1746363358011.ta.chkpt\" at 2025-05-04 13:55:58 after 20 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like reds and purples are just so rich and kind of perfect\n",
      "\n",
      "i fe–µl like reds –∞nd purples –∞r–µ just so rich –∞nd kind of perfect\n",
      "--------------------------------------------- Result 20 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i [[feel]] like reds [[and]] purples [[are]] just so rich [[and]] kind of perfect\n",
      "\n",
      "i [[fe–µl]] like reds [[–∞nd]] purples [[–∞r–µ]] just so rich [[–∞nd]] kind of perfect\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 15 / 0 / 21:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [10:57<15:07, 31.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "--------------------------------------------- Result 21 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 15 / 0 / 22:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [11:25<14:32, 31.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like ive gotten to know many of you through comments and emails and for that im appreciative and glad you are a part of this little space\n",
      "\n",
      "i feel like iv–µ gotten to know many of yŒøu through comments and emails and fŒør that im appreciat—ñve and glad you are a part of this little space\n",
      "--------------------------------------------- Result 22 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like [[ive]] gotten to know many of [[you]] through comments and emails and [[for]] that im [[appreciative]] and glad you are a part of this little space\n",
      "\n",
      "i feel like [[iv–µ]] gotten to know many of [[yŒøu]] through comments and emails and [[fŒør]] that im [[appreciat—ñve]] and glad you are a part of this little space\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 15 / 0 / 23:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [12:18<14:27, 32.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "—ñ survey my own posts over the last few years an‘Å only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone lik–µ me in dubl—ñn in the st —Åentury\n",
      "--------------------------------------------- Result 23 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "[[i]] survey my own posts over the last few years [[and]] only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone [[like]] me in [[dublin]] in the st [[century]]\n",
      "\n",
      "[[—ñ]] survey my own posts over the last few years [[an‘Å]] only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone [[lik–µ]] me in [[dubl—ñn]] in the st [[—Åentury]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 16 / 0 / 24:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [12:46<13:49, 31.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "--------------------------------------------- Result 24 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-tOghivYYiEr3uog0BbdoPsgD on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 20\u001b[0m\n\u001b[1;32m     13\u001b[0m attack_args \u001b[38;5;241m=\u001b[39m textattack\u001b[38;5;241m.\u001b[39mAttackArgs(\n\u001b[1;32m     14\u001b[0m     num_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     15\u001b[0m     checkpoint_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     16\u001b[0m     checkpoint_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/emotion/gpt4/pert\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpert\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     log_to_csv\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/emotion/gpt4/pert\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpert\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/log50.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m attacker \u001b[38;5;241m=\u001b[39m textattack\u001b[38;5;241m.\u001b[39mAttacker(attack, dataset, attack_args)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mattacker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/attacker.py:441\u001b[0m, in \u001b[0;36mAttacker.attack_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attack_parallel()\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39msilent:\n\u001b[1;32m    444\u001b[0m     logger\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mINFO)\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/attacker.py:170\u001b[0m, in \u001b[0;36mAttacker._attack\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack\u001b[38;5;241m.\u001b[39mattack(example, ground_truth_output)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(result, SkippedAttackResult) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39mattack_n\n\u001b[1;32m    173\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, SuccessfulAttackResult)\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39mnum_successful_examples\n\u001b[1;32m    176\u001b[0m ):\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m worklist_candidates:\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/attacker.py:168\u001b[0m, in \u001b[0;36mAttacker._attack\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m     example\u001b[38;5;241m.\u001b[39mattack_attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mlabel_names\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/attack.py:450\u001b[0m, in \u001b[0;36mAttack.attack\u001b[0;34m(self, example, ground_truth_output)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SkippedAttackResult(goal_function_result)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 450\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgoal_function_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/attack.py:398\u001b[0m, in \u001b[0;36mAttack._attack\u001b[0;34m(self, initial_result)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_attack\u001b[39m(\u001b[38;5;28mself\u001b[39m, initial_result):\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the ``SearchMethod`` to perturb the ``AttackedText`` stored in\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03m    ``initial_result``.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m            or ``MaximizedAttackResult``.\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     final_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_cache()\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_result\u001b[38;5;241m.\u001b[39mgoal_status \u001b[38;5;241m==\u001b[39m GoalFunctionResultStatus\u001b[38;5;241m.\u001b[39mSUCCEEDED:\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/search_methods/search_method.py:35\u001b[0m, in \u001b[0;36mSearchMethod.__call__\u001b[0;34m(self, initial_result)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter_transformations\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch Method must have access to filter_transformations method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m     )\n\u001b[0;32m---> 35\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# ensure that the number of queries for this GoalFunctionResult is up-to-date\u001b[39;00m\n\u001b[1;32m     37\u001b[0m result\u001b[38;5;241m.\u001b[39mnum_queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgoal_function\u001b[38;5;241m.\u001b[39mnum_queries\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/search_methods/differential_evolution.py:59\u001b[0m, in \u001b[0;36mDifferentialEvolution.perform_search\u001b[0;34m(self, initial_result)\u001b[0m\n\u001b[1;32m     56\u001b[0m         best_result_found \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur_score\n\u001b[0;32m---> 59\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mdifferential_evolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopsize\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# minimises obj\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_result_found \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m initial_result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/scipy/optimize/_differentialevolution.py:402\u001b[0m, in \u001b[0;36mdifferential_evolution\u001b[0;34m(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, seed, callback, disp, polish, init, atol, updating, workers, constraints, x0, integrality, vectorized)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# using a context manager means that any created Pool objects are\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# cleared up.\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DifferentialEvolutionSolver(func, bounds, args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m    388\u001b[0m                                  strategy\u001b[38;5;241m=\u001b[39mstrategy,\n\u001b[1;32m    389\u001b[0m                                  maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                  integrality\u001b[38;5;241m=\u001b[39mintegrality,\n\u001b[1;32m    401\u001b[0m                                  vectorized\u001b[38;5;241m=\u001b[39mvectorized) \u001b[38;5;28;01mas\u001b[39;00m solver:\n\u001b[0;32m--> 402\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/scipy/optimize/_differentialevolution.py:1022\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxiter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;66;03m# evolve the population by a generation\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1022\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1024\u001b[0m         warning_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/scipy/optimize/_differentialevolution.py:1409\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1407\u001b[0m     feasible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1408\u001b[0m     cv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_2d([\u001b[38;5;241m0.\u001b[39m])\n\u001b[0;32m-> 1409\u001b[0m     energy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;66;03m# compare trial and population member\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/scipy/_lib/_util.py:360\u001b[0m, in \u001b[0;36m_FunctionWrapper.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/search_methods/differential_evolution.py:53\u001b[0m, in \u001b[0;36mDifferentialEvolution.perform_search.<locals>.obj\u001b[0;34m(perturbation_vector)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_transformations([cand], initial_text, initial_text)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m---> 53\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_goal_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcand\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     54\u001b[0m cur_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mresult\u001b[38;5;241m.\u001b[39mscore\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (cur_score \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m best_score):\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/goal_functions/goal_function.py:97\u001b[0m, in \u001b[0;36mGoalFunction.get_results\u001b[0;34m(self, attacked_text_list, check_skip)\u001b[0m\n\u001b[1;32m     95\u001b[0m     attacked_text_list \u001b[38;5;241m=\u001b[39m attacked_text_list[:queries_left]\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_queries \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(attacked_text_list)\n\u001b[0;32m---> 97\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattacked_text_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attacked_text, raw_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(attacked_text_list, model_outputs):\n\u001b[1;32m     99\u001b[0m     displayed_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_displayed_output(raw_output)\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/goal_functions/goal_function.py:220\u001b[0m, in \u001b[0;36mGoalFunction._call_model\u001b[0;34m(self, attacked_text_list)\u001b[0m\n\u001b[1;32m    214\u001b[0m         uncached_list\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[1;32m    215\u001b[0m uncached_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    216\u001b[0m     text\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m attacked_text_list\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_model_cache\n\u001b[1;32m    219\u001b[0m ]\n\u001b[0;32m--> 220\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_model_uncached\u001b[49m\u001b[43m(\u001b[49m\u001b[43muncached_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text, output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(uncached_list, outputs):\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_model_cache[text] \u001b[38;5;241m=\u001b[39m output\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/goal_functions/goal_function.py:166\u001b[0m, in \u001b[0;36mGoalFunction._call_model_uncached\u001b[0;34m(self, attacked_text_list)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs):\n\u001b[1;32m    165\u001b[0m     batch \u001b[38;5;241m=\u001b[39m inputs[i : i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[0;32m--> 166\u001b[0m     batch_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Some seq-to-seq models will return a single string as a prediction\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# for a single-string list. Wrap these in a list.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_preds, \u001b[38;5;28mstr\u001b[39m):\n",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m, in \u001b[0;36mGPT4Wrapper.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[0;32m---> 19\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     29\u001b[0m     arr \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m6\u001b[39m \n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py:929\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    926\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    927\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    928\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 929\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/_base_client.py:1276\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1264\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1272\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1273\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1274\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1275\u001b[0m     )\n\u001b[0;32m-> 1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/_base_client.py:949\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    947\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/_base_client.py:1042\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1041\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1042\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/_base_client.py:1091\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1091\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/_base_client.py:1042\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1041\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1042\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/_base_client.py:1091\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1091\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1056\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1060\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1061\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1066\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-tOghivYYiEr3uog0BbdoPsgD on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "for pert in range(1, 6):\n",
    "\n",
    "    attack = textattack.attack_recipes.BadCharacters2021.build(\n",
    "        model_wrapper, \n",
    "        goal_function_type=\"targeted_bonus\",\n",
    "        perturbation_type=args.perturbation_type,\n",
    "        target_class=1,\n",
    "        perturbs=pert,\n",
    "        popsize=5,\n",
    "        maxiter=3\n",
    "    )\n",
    "    dataset = textattack.datasets.HuggingFaceDataset(\"dair-ai/emotion\", split=\"test\")\n",
    "    attack_args = textattack.AttackArgs(\n",
    "        num_examples=50,\n",
    "        checkpoint_interval=10,\n",
    "        checkpoint_dir=f\"results/emotion/gpt4/pert{pert}\",\n",
    "        log_to_csv=f\"results/emotion/gpt4/pert{pert}/log50.csv\"\n",
    "    )\n",
    "    attacker = textattack.Attacker(attack, dataset, attack_args)\n",
    "    attacker.attack_dataset()\n",
    "\n",
    "    # if args.store_results == False:\n",
    "    #     if os.path.isdir(\"results/emotion/gpt4\"):\n",
    "    #         shutil.rmtree(\"results/emotion/gpt4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading WMT14 test data from http://statmt.org/wmt14/test-full.tgz...\n",
      "Extracting test-full/newstest2014-fren-ref.fr.sgm to temp/translation/data\n",
      "Extracting test-full/newstest2014-fren-src.en.sgm to temp/translation/data\n",
      "en_fr dataset downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: No entry found for goal function <class 'textattack.goal_functions.text.maximize_levenshtein.MaximizeLevenshtein'>.\n",
      "textattack: Unknown if model of class <class '__main__.GPT4Wrapper'> compatible with goal function <class 'textattack.goal_functions.text.maximize_levenshtein.MaximizeLevenshtein'>.\n",
      "textattack: Logging to CSV at path results/translation/gpt4/log100.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(OrderedDict([('text', 'Spectacular Wingsuit Jump Over Bogota')]), 'Spectaculaire saut en \"wingsuit\" au-dessus de Bogota')\n",
      "Attack(\n",
      "  (search_method): DifferentialEvolution(\n",
      "    (popsize):  3\n",
      "    (maxiter):  1\n",
      "    (max_perturbs):  5\n",
      "    (verbose):  False\n",
      "  )\n",
      "  (goal_function):  MaximizeLevenshtein(\n",
      "    (maximizable):  False\n",
      "    (target_distance):  None\n",
      "  )\n",
      "  (transformation):  WordSwapHomoglyphSwap\n",
      "  (constraints): None\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saut en wingsuit spectaculaire au-dessus de Bogot√°. --> [FAILED]\n",
      "\n",
      "Spectacular Wingsuit Jump Over Bogota\n",
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "Saut en wingsuit spectaculaire au-dessus de Bogot√°. --> [[[FAILED]]]\n",
      "\n",
      "Spectacular Wingsuit Jump Over Bogota\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le sportif Jhonathan Florez a saut√© d'un h√©licopt√®re au-dessus de Bogot√°, la capitale de la Colombie, jeudi. --> [FAILED]\n",
      "\n",
      "Sportsman Jhonathan Florez jumped from a helicopter above Bogota, the capital of Colombia, on Thursday.\n",
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "Le sportif Jhonathan Florez a saut√© d'un h√©licopt√®re au-dessus de Bogot√°, la capitale de la Colombie, jeudi. --> [[[FAILED]]]\n",
      "\n",
      "Sportsman Jhonathan Florez jumped from a helicopter above Bogota, the capital of Colombia, on Thursday.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V√™tu d'une combinaison de wingsuit, il a survol√© le c√©l√®bre sanctuaire de Monserrate √† 160 km/h. Le sanctuaire est situ√© √† une altitude de plus de 3000 m√®tres et de nombreux spectateurs s --> [FAILED]\n",
      "\n",
      "Wearing a wingsuit, he flew past over the famous Monserrate Sanctuary at 160km/h. The sanctuary is located at an altitude of over 3000 meters and numerous spectators had gathered there to watch his exploit.\n",
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "V√™tu d'une combinaison de wingsuit, il a survol√© le c√©l√®bre sanctuaire de Monserrate √† 160 km/h. Le sanctuaire est situ√© √† une altitude de plus de 3000 m√®tres et de nombreux spectateurs s --> [[[FAILED]]]\n",
      "\n",
      "Wearing a wingsuit, he flew past over the famous Monserrate Sanctuary at 160km/h. The sanctuary is located at an altitude of over 3000 meters and numerous spectators had gathered there to watch his exploit.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Une bo√Æte noire dans votre voiture ? --> [FAILED]\n",
      "\n",
      "A black box in your car?\n",
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "Une bo√Æte noire dans votre voiture ? --> [[[FAILED]]]\n",
      "\n",
      "A black box in your car?\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [45:29<?, ?it/s]\n",
      "  0%|          | 0/1 [44:17<?, ?it/s]\n",
      "  0%|          | 0/1 [41:34<?, ?it/s]\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   1%|          | 1/100 [40:44<67:13:09, 2444.34s/it]\n",
      "textattack: CSVLogger exiting without calling flush().\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alors que les planificateurs routiers am√©ricains peinent √† trouver des fonds pour r√©parer un syst√®me autoroutier en ruine, beaucoup commencent √† voir une solution dans une petite bo√Æte noire qui s'adapte parfaitement au tableau de bord de votre voiture. --> [FAILED]\n",
      "\n",
      "As America's road planners struggle to find the cash to mend a crumbling highway system, many are beginning to see a solution in a little black box that fits neatly by the dashboard of your car.\n",
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "Alors que les planificateurs routiers am√©ricains peinent √† trouver des fonds pour r√©parer un syst√®me autoroutier en ruine, beaucoup commencent √† voir une solution dans une petite bo√Æte noire qui s'adapte parfaitement au tableau de bord de votre voiture. --> [[[FAILED]]]\n",
      "\n",
      "As America's road planners struggle to find the cash to mend a crumbling highway system, many are beginning to see a solution in a little black box that fits neatly by the dashboard of your car.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les dispositifs, qui suivent chaque mile parcouru par un automobiliste et transmettent ces informations aux bureaucrates, sont au centre d'une tentative controvers√©e √† Washington et dans les bureaux de planification des √âtats de r√©former le syst√®me obsol√®te de --> [FAILED]\n",
      "\n",
      "The devices, which track every mile a motorist drives and transmit that information to bureaucrats, are at the center of a controversial attempt in Washington and state planning offices to overhaul the outdated system for funding America's major roads.\n",
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "Les dispositifs, qui suivent chaque mile parcouru par un automobiliste et transmettent ces informations aux bureaucrates, sont au centre d'une tentative controvers√©e √† Washington et dans les bureaux de planification des √âtats de r√©former le syst√®me obsol√®te de --> [[[FAILED]]]\n",
      "\n",
      "The devices, which track every mile a motorist drives and transmit that information to bureaucrats, are at the center of a controversial attempt in Washington and state planning offices to overhaul the outdated system for funding America's major roads.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'ar√®ne habituellement ennuyeuse de la planification des autoroutes a soudainement engendr√© un d√©bat intense et des alliances color√©es. --> [FAILED]\n",
      "\n",
      "The usually dull arena of highway planning has suddenly spawned intense debate and colorful alliances.\n",
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "L'ar√®ne habituellement ennuyeuse de la planification des autoroutes a soudainement engendr√© un d√©bat intense et des alliances color√©es. --> [[[FAILED]]]\n",
      "\n",
      "The usually dull arena of highway planning has suddenly spawned intense debate and colorful alliances.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les libertariens se sont joints aux groupes environnementaux pour faire pression afin de permettre au gouvernement d'utiliser les petites bo√Ætes pour suivre les kilom√®tres que vous parcourez, et √©ventuellement o√π vous les parcourez - puis utiliser les informations pour √©tablir --> [FAILED]\n",
      "\n",
      "Libertarians have joined environmental groups in lobbying to allow government to use the little boxes to keep track of the miles you drive, and possibly where you drive them - then use the information to draw up a tax bill.\n",
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "Les libertariens se sont joints aux groupes environnementaux pour faire pression afin de permettre au gouvernement d'utiliser les petites bo√Ætes pour suivre les kilom√®tres que vous parcourez, et √©ventuellement o√π vous les parcourez - puis utiliser les informations pour √©tablir --> [[[FAILED]]]\n",
      "\n",
      "Libertarians have joined environmental groups in lobbying to allow government to use the little boxes to keep track of the miles you drive, and possibly where you drive them - then use the information to draw up a tax bill.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La f√™te du th√© est constern√©e. --> [FAILED]\n",
      "\n",
      "The tea party is aghast.\n",
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "La f√™te du th√© est constern√©e. --> [[[FAILED]]]\n",
      "\n",
      "The tea party is aghast.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746129116160.ta.chkpt\" at 2025-05-01 20:51:56 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'Union am√©ricaine pour les libert√©s civiles est √©galement profond√©ment pr√©occup√©e, soulevant une vari√©t√© de probl√®mes de confidentialit√©. --> [FAILED]\n",
      "\n",
      "The American Civil Liberties Union is deeply concerned, too, raising a variety of privacy issues.\n",
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "L'Union am√©ricaine pour les libert√©s civiles est √©galement profond√©ment pr√©occup√©e, soulevant une vari√©t√© de probl√®mes de confidentialit√©. --> [[[FAILED]]]\n",
      "\n",
      "The American Civil Liberties Union is deeply concerned, too, raising a variety of privacy issues.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Et tandis que le Congr√®s ne parvient pas √† se mettre d'accord sur la mani√®re de proc√©der, plusieurs √âtats n'attendent pas. --> [FAILED]\n",
      "\n",
      "And while Congress can't agree on whether to proceed, several states are not waiting.\n",
      "--------------------------------------------- Result 11 ---------------------------------------------\n",
      "Et tandis que le Congr√®s ne parvient pas √† se mettre d'accord sur la mani√®re de proc√©der, plusieurs √âtats n'attendent pas. --> [[[FAILED]]]\n",
      "\n",
      "And while Congress can't agree on whether to proceed, several states are not waiting.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ils explorent comment, au cours de la prochaine d√©cennie, ils peuvent passer √† un syst√®me dans lequel les conducteurs paient par mile de route qu'ils parcourent. --> [FAILED]\n",
      "\n",
      "They are exploring how, over the next decade, they can move to a system in which drivers pay per mile of road they roll over.\n",
      "--------------------------------------------- Result 12 ---------------------------------------------\n",
      "Ils explorent comment, au cours de la prochaine d√©cennie, ils peuvent passer √† un syst√®me dans lequel les conducteurs paient par mile de route qu'ils parcourent. --> [[[FAILED]]]\n",
      "\n",
      "They are exploring how, over the next decade, they can move to a system in which drivers pay per mile of road they roll over.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Des milliers de conducteurs ont d√©j√† pris les bo√Ætes noires, dont certaines disposent d'un suivi GPS, pour un essai. --> [FAILED]\n",
      "\n",
      "Thousands of motorists have already taken the black boxes, some of which have GPS monitoring, for a test drive.\n",
      "--------------------------------------------- Result 13 ---------------------------------------------\n",
      "Des milliers de conducteurs ont d√©j√† pris les bo√Ætes noires, dont certaines disposent d'un suivi GPS, pour un essai. --> [[[FAILED]]]\n",
      "\n",
      "Thousands of motorists have already taken the black boxes, some of which have GPS monitoring, for a test drive.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C'est vraiment un must pour notre nation. --> [FAILED]\n",
      "\n",
      "This really is a must for our nation.\n",
      "--------------------------------------------- Result 14 ---------------------------------------------\n",
      "C'est vraiment un must pour notre nation. --> [[[FAILED]]]\n",
      "\n",
      "This really is a must for our nation.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Ce n'est pas une question de quelque chose que nous pourrions choisir de faire,\" a d√©clar√© Hasan Ikhrata, directeur ex√©cutif de l'Association des gouvernements du sud de la Californie, qui pr√©voit que l'√âtat commence √† --> [FAILED]\n",
      "\n",
      "\"It is not a matter of something we might choose to do,\" said Hasan Ikhrata, executive director of the Southern California Assn. of Governments, which is planning for the state to start tracking miles driven by every California motorist by 2025.\n",
      "--------------------------------------------- Result 15 ---------------------------------------------\n",
      "\"Ce n'est pas une question de quelque chose que nous pourrions choisir de faire,\" a d√©clar√© Hasan Ikhrata, directeur ex√©cutif de l'Association des gouvernements du sud de la Californie, qui pr√©voit que l'√âtat commence √† --> [[[FAILED]]]\n",
      "\n",
      "\"It is not a matter of something we might choose to do,\" said Hasan Ikhrata, executive director of the Southern California Assn. of Governments, which is planning for the state to start tracking miles driven by every California motorist by 2025.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y aura un changement dans la fa√ßon dont nous payons ces imp√¥ts. --> [FAILED]\n",
      "\n",
      "There is going to be a change in how we pay these taxes.\n",
      "--------------------------------------------- Result 16 ---------------------------------------------\n",
      "Il y aura un changement dans la fa√ßon dont nous payons ces imp√¥ts. --> [[[FAILED]]]\n",
      "\n",
      "There is going to be a change in how we pay these taxes.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La technologie est l√† pour le faire. --> [FAILED]\n",
      "\n",
      "The technology is there to do it.\n",
      "--------------------------------------------- Result 17 ---------------------------------------------\n",
      "La technologie est l√† pour le faire. --> [[[FAILED]]]\n",
      "\n",
      "The technology is there to do it.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La pression survient alors que le Fonds de confiance pour les autoroutes du pays, financ√© par les taxes que les Am√©ricains paient √† la pompe, est en faillite. --> [FAILED]\n",
      "\n",
      "The push comes as the country's Highway Trust Fund, financed with taxes Americans pay at the gas pump, is broke.\n",
      "--------------------------------------------- Result 18 ---------------------------------------------\n",
      "La pression survient alors que le Fonds de confiance pour les autoroutes du pays, financ√© par les taxes que les Am√©ricains paient √† la pompe, est en faillite. --> [[[FAILED]]]\n",
      "\n",
      "The push comes as the country's Highway Trust Fund, financed with taxes Americans pay at the gas pump, is broke.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les Am√©ricains n'ach√®tent pas autant d'essence qu'auparavant. --> [FAILED]\n",
      "\n",
      "Americans don't buy as much gas as they used to.\n",
      "--------------------------------------------- Result 19 ---------------------------------------------\n",
      "Les Am√©ricains n'ach√®tent pas autant d'essence qu'auparavant. --> [[[FAILED]]]\n",
      "\n",
      "Americans don't buy as much gas as they used to.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746129404810.ta.chkpt\" at 2025-05-01 20:56:44 after 20 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les voitures parcourent beaucoup plus de kilom√®tres par gallon. --> [FAILED]\n",
      "\n",
      "Cars get many more miles to the gallon.\n",
      "--------------------------------------------- Result 20 ---------------------------------------------\n",
      "Les voitures parcourent beaucoup plus de kilom√®tres par gallon. --> [[[FAILED]]]\n",
      "\n",
      "Cars get many more miles to the gallon.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La taxe f√©d√©rale elle-m√™me, de 18,4 cents par gallon, n'a pas augment√© depuis 20 ans. --> [FAILED]\n",
      "\n",
      "The federal tax itself, 18.4 cents per gallon, hasn't gone up in 20 years.\n",
      "--------------------------------------------- Result 21 ---------------------------------------------\n",
      "La taxe f√©d√©rale elle-m√™me, de 18,4 cents par gallon, n'a pas augment√© depuis 20 ans. --> [[[FAILED]]]\n",
      "\n",
      "The federal tax itself, 18.4 cents per gallon, hasn't gone up in 20 years.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les politiciens sont r√©ticents √† augmenter les imp√¥ts ne serait-ce que d'un centime lorsque les prix de l'essence sont √©lev√©s. --> [FAILED]\n",
      "\n",
      "Politicians are loath to raise the tax even one penny when gas prices are high.\n",
      "--------------------------------------------- Result 22 ---------------------------------------------\n",
      "Les politiciens sont r√©ticents √† augmenter les imp√¥ts ne serait-ce que d'un centime lorsque les prix de l'essence sont √©lev√©s. --> [[[FAILED]]]\n",
      "\n",
      "Politicians are loath to raise the tax even one penny when gas prices are high.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"La taxe sur l'essence n'est tout simplement pas durable,\" a d√©clar√© Lee Munnich, un expert en politique de transport √† l'Universit√© du Minnesota. --> [FAILED]\n",
      "\n",
      "\"The gas tax is just not sustainable,\" said Lee Munnich, a transportation policy expert at the University of Minnesota.\n",
      "--------------------------------------------- Result 23 ---------------------------------------------\n",
      "\"La taxe sur l'essence n'est tout simplement pas durable,\" a d√©clar√© Lee Munnich, un expert en politique de transport √† l'Universit√© du Minnesota. --> [[[FAILED]]]\n",
      "\n",
      "\"The gas tax is just not sustainable,\" said Lee Munnich, a transportation policy expert at the University of Minnesota.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Son √âtat a r√©cemment install√© des dispositifs de suivi sur 500 voitures pour tester un syst√®me de paiement au kilom√®tre. --> [FAILED]\n",
      "\n",
      "His state recently put tracking devices on 500 cars to test out a pay-by-mile system.\n",
      "--------------------------------------------- Result 24 ---------------------------------------------\n",
      "Son √âtat a r√©cemment install√© des dispositifs de suivi sur 500 voitures pour tester un syst√®me de paiement au kilom√®tre. --> [[[FAILED]]]\n",
      "\n",
      "His state recently put tracking devices on 500 cars to test out a pay-by-mile system.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Cela s'av√®re √™tre l'alternative la plus logique √† long terme,\" a-t-il d√©clar√©. --> [FAILED]\n",
      "\n",
      "\"This works out as the most logical alternative over the long term,\" he said.\n",
      "--------------------------------------------- Result 25 ---------------------------------------------\n",
      "\"Cela s'av√®re √™tre l'alternative la plus logique √† long terme,\" a-t-il d√©clar√©. --> [[[FAILED]]]\n",
      "\n",
      "\"This works out as the most logical alternative over the long term,\" he said.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les experts l'appellent un tarif utilisateur bas√© sur le kilom√©trage. --> [FAILED]\n",
      "\n",
      "Wonks call it a mileage-based user fee.\n",
      "--------------------------------------------- Result 26 ---------------------------------------------\n",
      "Les experts l'appellent un tarif utilisateur bas√© sur le kilom√©trage. --> [[[FAILED]]]\n",
      "\n",
      "Wonks call it a mileage-based user fee.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il n'est pas surprenant que l'id√©e plaise aux lib√©raux urbains, car les taxes pourraient √™tre manipul√©es pour modifier les habitudes de conduite de mani√®re √† aider √† r√©duire la congestion et les gaz √† effet de serre, par exemple. --> [FAILED]\n",
      "\n",
      "It is no surprise that the idea appeals to urban liberals, as the taxes could be rigged to change driving patterns in ways that could help reduce congestion and greenhouse gases, for example.\n",
      "--------------------------------------------- Result 27 ---------------------------------------------\n",
      "Il n'est pas surprenant que l'id√©e plaise aux lib√©raux urbains, car les taxes pourraient √™tre manipul√©es pour modifier les habitudes de conduite de mani√®re √† aider √† r√©duire la congestion et les gaz √† effet de serre, par exemple. --> [[[FAILED]]]\n",
      "\n",
      "It is no surprise that the idea appeals to urban liberals, as the taxes could be rigged to change driving patterns in ways that could help reduce congestion and greenhouse gases, for example.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les planificateurs de Californie se tournent vers le syst√®me alors qu'ils √©laborent des strat√©gies pour atteindre les objectifs fix√©s par les ambitieuses lois sur le r√©chauffement climatique de l'√âtat. --> [FAILED]\n",
      "\n",
      "California planners are looking to the system as they devise strategies to meet the goals laid out in the state's ambitious global warming laws.\n",
      "--------------------------------------------- Result 28 ---------------------------------------------\n",
      "Les planificateurs de Californie se tournent vers le syst√®me alors qu'ils √©laborent des strat√©gies pour atteindre les objectifs fix√©s par les ambitieuses lois sur le r√©chauffement climatique de l'√âtat. --> [[[FAILED]]]\n",
      "\n",
      "California planners are looking to the system as they devise strategies to meet the goals laid out in the state's ambitious global warming laws.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mais le repr√©sentant Bill Shuster (R-Pa.), pr√©sident de la Commission des transports de la Chambre, a d√©clar√© qu'il consid√®re √©galement cela comme la solution alternative √† long terme la plus viable. --> [FAILED]\n",
      "\n",
      "But Rep. Bill Shuster (R-Pa.), chairman of the House Transportation Committee, has said he, too, sees it as the most viable long-term alternative.\n",
      "--------------------------------------------- Result 29 ---------------------------------------------\n",
      "Mais le repr√©sentant Bill Shuster (R-Pa.), pr√©sident de la Commission des transports de la Chambre, a d√©clar√© qu'il consid√®re √©galement cela comme la solution alternative √† long terme la plus viable. --> [[[FAILED]]]\n",
      "\n",
      "But Rep. Bill Shuster (R-Pa.), chairman of the House Transportation Committee, has said he, too, sees it as the most viable long-term alternative.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746129726715.ta.chkpt\" at 2025-05-01 21:02:06 after 30 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les partisans du libre march√© √† la Reason Foundation aiment √©galement faire payer les conducteurs par mile. --> [FAILED]\n",
      "\n",
      "The free marketeers at the Reason Foundation are also fond of having drivers pay per mile.\n",
      "--------------------------------------------- Result 30 ---------------------------------------------\n",
      "Les partisans du libre march√© √† la Reason Foundation aiment √©galement faire payer les conducteurs par mile. --> [[[FAILED]]]\n",
      "\n",
      "The free marketeers at the Reason Foundation are also fond of having drivers pay per mile.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬´ Ce n'est pas juste une taxe qui va dans un trou noir ¬ª, a d√©clar√© Adrian Moore, vice-pr√©sident des politiques chez Reason. --> [FAILED]\n",
      "\n",
      "\"This is not just a tax going into a black hole,\" said Adrian Moore, vice president of policy at Reason.\n",
      "--------------------------------------------- Result 31 ---------------------------------------------\n",
      "¬´ Ce n'est pas juste une taxe qui va dans un trou noir ¬ª, a d√©clar√© Adrian Moore, vice-pr√©sident des politiques chez Reason. --> [[[FAILED]]]\n",
      "\n",
      "\"This is not just a tax going into a black hole,\" said Adrian Moore, vice president of policy at Reason.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les gens paient plus directement pour ce qu'ils obtiennent. --> [FAILED]\n",
      "\n",
      "People are paying more directly into what they are getting.\n",
      "--------------------------------------------- Result 32 ---------------------------------------------\n",
      "Les gens paient plus directement pour ce qu'ils obtiennent. --> [[[FAILED]]]\n",
      "\n",
      "People are paying more directly into what they are getting.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le mouvement est √©galement soutenu par deux anciens secr√©taires aux Transports des √âtats-Unis, qui dans un rapport de 2011 ont exhort√© le Congr√®s √† se diriger vers un syst√®me de paiement au kilom√®tre. --> [FAILED]\n",
      "\n",
      "The movement is also bolstered by two former U.S. Transportation secretaries, who in a 2011 report urged Congress to move in the pay-per-mile direction.\n",
      "--------------------------------------------- Result 33 ---------------------------------------------\n",
      "Le mouvement est √©galement soutenu par deux anciens secr√©taires aux Transports des √âtats-Unis, qui dans un rapport de 2011 ont exhort√© le Congr√®s √† se diriger vers un syst√®me de paiement au kilom√®tre. --> [[[FAILED]]]\n",
      "\n",
      "The movement is also bolstered by two former U.S. Transportation secretaries, who in a 2011 report urged Congress to move in the pay-per-mile direction.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le S√©nat am√©ricain a approuv√© un projet pilote de 90 millions de dollars l'ann√©e derni√®re qui aurait impliqu√© environ 10 000 voitures. --> [FAILED]\n",
      "\n",
      "The U.S. Senate approved a $90-million pilot project last year that would have involved about 10,000 cars.\n",
      "--------------------------------------------- Result 34 ---------------------------------------------\n",
      "Le S√©nat am√©ricain a approuv√© un projet pilote de 90 millions de dollars l'ann√©e derni√®re qui aurait impliqu√© environ 10 000 voitures. --> [[[FAILED]]]\n",
      "\n",
      "The U.S. Senate approved a $90-million pilot project last year that would have involved about 10,000 cars.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mais la direction de la Chambre a tu√© la proposition, agissant sur les pr√©occupations des l√©gislateurs ruraux repr√©sentant des √©lecteurs dont la vie quotidienne implique souvent de parcourir de nombreux kilom√®tres pour se rendre au travail ou en ville. --> [FAILED]\n",
      "\n",
      "But the House leadership killed the proposal, acting on concerns of rural lawmakers representing constituents whose daily lives often involve logging lots of miles to get to work or into town.\n",
      "--------------------------------------------- Result 35 ---------------------------------------------\n",
      "Mais la direction de la Chambre a tu√© la proposition, agissant sur les pr√©occupations des l√©gislateurs ruraux repr√©sentant des √©lecteurs dont la vie quotidienne implique souvent de parcourir de nombreux kilom√®tres pour se rendre au travail ou en ville. --> [[[FAILED]]]\n",
      "\n",
      "But the House leadership killed the proposal, acting on concerns of rural lawmakers representing constituents whose daily lives often involve logging lots of miles to get to work or into town.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plusieurs √âtats et villes avancent n√©anmoins de leur c√¥t√©. --> [FAILED]\n",
      "\n",
      "Several states and cities are nonetheless moving ahead on their own.\n",
      "--------------------------------------------- Result 36 ---------------------------------------------\n",
      "Plusieurs √âtats et villes avancent n√©anmoins de leur c√¥t√©. --> [[[FAILED]]]\n",
      "\n",
      "Several states and cities are nonetheless moving ahead on their own.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le plus enthousiaste est l'Oregon, qui recrute 5 000 conducteurs dans la plus grande exp√©rience du pays. --> [FAILED]\n",
      "\n",
      "The most eager is Oregon, which is enlisting 5,000 drivers in the country's biggest experiment.\n",
      "--------------------------------------------- Result 37 ---------------------------------------------\n",
      "Le plus enthousiaste est l'Oregon, qui recrute 5 000 conducteurs dans la plus grande exp√©rience du pays. --> [[[FAILED]]]\n",
      "\n",
      "The most eager is Oregon, which is enlisting 5,000 drivers in the country's biggest experiment.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ces conducteurs paieront bient√¥t les frais de kilom√©trage au lieu des taxes sur l'essence √† l'√âtat. --> [FAILED]\n",
      "\n",
      "Those drivers will soon pay the mileage fees instead of gas taxes to the state.\n",
      "--------------------------------------------- Result 38 ---------------------------------------------\n",
      "Ces conducteurs paieront bient√¥t les frais de kilom√©trage au lieu des taxes sur l'essence √† l'√âtat. --> [[[FAILED]]]\n",
      "\n",
      "Those drivers will soon pay the mileage fees instead of gas taxes to the state.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Nevada a d√©j√† termin√© un projet pilote. --> [FAILED]\n",
      "\n",
      "Nevada has already completed a pilot.\n",
      "--------------------------------------------- Result 39 ---------------------------------------------\n",
      "Le Nevada a d√©j√† termin√© un projet pilote. --> [[[FAILED]]]\n",
      "\n",
      "Nevada has already completed a pilot.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746130030736.ta.chkpt\" at 2025-05-01 21:07:10 after 40 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La ville de New York envisage d'en cr√©er un. --> [FAILED]\n",
      "\n",
      "New York City is looking into one.\n",
      "--------------------------------------------- Result 40 ---------------------------------------------\n",
      "La ville de New York envisage d'en cr√©er un. --> [[[FAILED]]]\n",
      "\n",
      "New York City is looking into one.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'Illinois essaie cela sur une base limit√©e avec des camions. --> [FAILED]\n",
      "\n",
      "Illinois is trying it on a limited basis with trucks.\n",
      "--------------------------------------------- Result 41 ---------------------------------------------\n",
      "L'Illinois essaie cela sur une base limit√©e avec des camions. --> [[[FAILED]]]\n",
      "\n",
      "Illinois is trying it on a limited basis with trucks.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Et la Coalition I-95, qui comprend 17 d√©partements de transport des √âtats le long de la c√¥te est (y compris le Maryland, la Pennsylvanie, la Virginie et la Floride), √©tudie comment elle pourrait mettre --> [FAILED]\n",
      "\n",
      "And the I-95 Coalition, which includes 17 state transportation departments along the Eastern Seaboard (including Maryland, Pennsylvania, Virginia and Florida), is studying how they could go about implementing the change.\n",
      "--------------------------------------------- Result 42 ---------------------------------------------\n",
      "Et la Coalition I-95, qui comprend 17 d√©partements de transport des √âtats le long de la c√¥te est (y compris le Maryland, la Pennsylvanie, la Virginie et la Floride), √©tudie comment elle pourrait mettre --> [[[FAILED]]]\n",
      "\n",
      "And the I-95 Coalition, which includes 17 state transportation departments along the Eastern Seaboard (including Maryland, Pennsylvania, Virginia and Florida), is studying how they could go about implementing the change.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le concept n'est pas un succ√®s universel. --> [FAILED]\n",
      "\n",
      "The concept is not a universal hit.\n",
      "--------------------------------------------- Result 43 ---------------------------------------------\n",
      "Le concept n'est pas un succ√®s universel. --> [[[FAILED]]]\n",
      "\n",
      "The concept is not a universal hit.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Au Nevada, o√π environ 50 voitures de b√©n√©voles ont √©t√© √©quip√©es des dispositifs il n'y a pas longtemps, les conducteurs √©taient inquiets que le gouvernement puisse surveiller chacun de leurs mouvements. --> [FAILED]\n",
      "\n",
      "In Nevada, where about 50 volunteers' cars were equipped with the devices not long ago, drivers were uneasy about the government being able to monitor their every move.\n",
      "--------------------------------------------- Result 44 ---------------------------------------------\n",
      "Au Nevada, o√π environ 50 voitures de b√©n√©voles ont √©t√© √©quip√©es des dispositifs il n'y a pas longtemps, les conducteurs √©taient inquiets que le gouvernement puisse surveiller chacun de leurs mouvements. --> [[[FAILED]]]\n",
      "\n",
      "In Nevada, where about 50 volunteers' cars were equipped with the devices not long ago, drivers were uneasy about the government being able to monitor their every move.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬´ Les pr√©occupations concernant Big Brother et ce genre de choses √©taient un probl√®me majeur ¬ª, a d√©clar√© Alauddin Khan, qui dirige la gestion strat√©gique et de la performance au D√©partement des Transports du Nevada. --> [FAILED]\n",
      "\n",
      "\"Concerns about Big Brother and those sorts of things were a major problem,\" said Alauddin Khan, who directs strategic and performance management at the Nevada Department of Transportation.\n",
      "--------------------------------------------- Result 45 ---------------------------------------------\n",
      "¬´ Les pr√©occupations concernant Big Brother et ce genre de choses √©taient un probl√®me majeur ¬ª, a d√©clar√© Alauddin Khan, qui dirige la gestion strat√©gique et de la performance au D√©partement des Transports du Nevada. --> [[[FAILED]]]\n",
      "\n",
      "\"Concerns about Big Brother and those sorts of things were a major problem,\" said Alauddin Khan, who directs strategic and performance management at the Nevada Department of Transportation.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce n'√©tait pas quelque chose que les gens voulaient. --> [FAILED]\n",
      "\n",
      "It was not something people wanted.\n",
      "--------------------------------------------- Result 46 ---------------------------------------------\n",
      "Ce n'√©tait pas quelque chose que les gens voulaient. --> [[[FAILED]]]\n",
      "\n",
      "It was not something people wanted.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alors que le proc√®s commen√ßait, l'ACLU du Nevada a averti sur son site Web : \"Il serait assez facile de transformer ces appareils en dispositifs de suivi √† part enti√®re.\" --> [FAILED]\n",
      "\n",
      "As the trial got underway, the ACLU of Nevada warned on its website: \"It would be fairly easy to turn these devices into full-fledged tracking devices.\"\n",
      "--------------------------------------------- Result 47 ---------------------------------------------\n",
      "Alors que le proc√®s commen√ßait, l'ACLU du Nevada a averti sur son site Web : \"Il serait assez facile de transformer ces appareils en dispositifs de suivi √† part enti√®re.\" --> [[[FAILED]]]\n",
      "\n",
      "As the trial got underway, the ACLU of Nevada warned on its website: \"It would be fairly easy to turn these devices into full-fledged tracking devices.\"\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il n'est pas n√©cessaire de construire une infrastructure technologique √©norme et peu maniable qui sera in√©vitablement √©tendue pour tenir des dossiers sur les all√©es et venues quotidiennes des individus. --> [FAILED]\n",
      "\n",
      "There is no need to build an enormous, unwieldy technological infrastructure that will inevitably be expanded to keep records of individuals' everyday comings and goings.\n",
      "--------------------------------------------- Result 48 ---------------------------------------------\n",
      "Il n'est pas n√©cessaire de construire une infrastructure technologique √©norme et peu maniable qui sera in√©vitablement √©tendue pour tenir des dossiers sur les all√©es et venues quotidiennes des individus. --> [[[FAILED]]]\n",
      "\n",
      "There is no need to build an enormous, unwieldy technological infrastructure that will inevitably be expanded to keep records of individuals' everyday comings and goings.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Nevada fait partie des plusieurs √âtats qui s'efforcent maintenant de trouver une technologie abordable permettant √† l'√âtat de suivre le nombre de miles parcourus par une voiture, mais pas exactement o√π et √† quel moment. --> [FAILED]\n",
      "\n",
      "Nevada is among several states now scrambling to find affordable technology that would allow the state to keep track of how many miles a car is being driven, but not exactly where and at what time.\n",
      "--------------------------------------------- Result 49 ---------------------------------------------\n",
      "Le Nevada fait partie des plusieurs √âtats qui s'efforcent maintenant de trouver une technologie abordable permettant √† l'√âtat de suivre le nombre de miles parcourus par une voiture, mais pas exactement o√π et √† quel moment. --> [[[FAILED]]]\n",
      "\n",
      "Nevada is among several states now scrambling to find affordable technology that would allow the state to keep track of how many miles a car is being driven, but not exactly where and at what time.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746130329007.ta.chkpt\" at 2025-05-01 21:12:09 after 50 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si vous pouvez faire cela, a d√©clar√© Khan, le public devient plus √† l'aise. --> [FAILED]\n",
      "\n",
      "If you can do that, Khan said, the public gets more comfortable.\n",
      "--------------------------------------------- Result 50 ---------------------------------------------\n",
      "Si vous pouvez faire cela, a d√©clar√© Khan, le public devient plus √† l'aise. --> [[[FAILED]]]\n",
      "\n",
      "If you can do that, Khan said, the public gets more comfortable.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La recherche de cette technologie a conduit certaines agences d'√âtat √† une petite startup californienne appel√©e True Mileage. --> [FAILED]\n",
      "\n",
      "The hunt for that technology has led some state agencies to a small California startup called True Mileage.\n",
      "--------------------------------------------- Result 51 ---------------------------------------------\n",
      "La recherche de cette technologie a conduit certaines agences d'√âtat √† une petite startup californienne appel√©e True Mileage. --> [[[FAILED]]]\n",
      "\n",
      "The hunt for that technology has led some state agencies to a small California startup called True Mileage.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'entreprise n'√©tait pas √† l'origine dans le secteur d'aide aux √âtats pour taxer les conducteurs. --> [FAILED]\n",
      "\n",
      "The firm was not originally in the business of helping states tax drivers.\n",
      "--------------------------------------------- Result 52 ---------------------------------------------\n",
      "L'entreprise n'√©tait pas √† l'origine dans le secteur d'aide aux √âtats pour taxer les conducteurs. --> [[[FAILED]]]\n",
      "\n",
      "The firm was not originally in the business of helping states tax drivers.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elle cherchait √† p√©n√©trer un march√© √©mergent de l'assurance automobile, dans lequel les conducteurs paieraient en fonction de leur kilom√©trage. --> [FAILED]\n",
      "\n",
      "It was seeking to break into an emerging market in auto insurance, in which drivers would pay based on their mileage.\n",
      "--------------------------------------------- Result 53 ---------------------------------------------\n",
      "Elle cherchait √† p√©n√©trer un march√© √©mergent de l'assurance automobile, dans lequel les conducteurs paieraient en fonction de leur kilom√©trage. --> [[[FAILED]]]\n",
      "\n",
      "It was seeking to break into an emerging market in auto insurance, in which drivers would pay based on their mileage.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mais les dispositifs qu'il teste attirent les planificateurs d'autoroutes car ils n'utilisent pas de GPS et fournissent une quantit√© limit√©e d'informations, t√©l√©charg√©es p√©riodiquement par modem. --> [FAILED]\n",
      "\n",
      "But the devices it is testing appeal to highway planners because they don't use GPS and deliver a limited amount of information, uploaded periodically by modem.\n",
      "--------------------------------------------- Result 54 ---------------------------------------------\n",
      "Mais les dispositifs qu'il teste attirent les planificateurs d'autoroutes car ils n'utilisent pas de GPS et fournissent une quantit√© limit√©e d'informations, t√©l√©charg√©es p√©riodiquement par modem. --> [[[FAILED]]]\n",
      "\n",
      "But the devices it is testing appeal to highway planners because they don't use GPS and deliver a limited amount of information, uploaded periodically by modem.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Les gens seront plus dispos√©s √† le faire si vous ne suivez pas leur vitesse et que vous ne suivez pas leur emplacement,\" a d√©clar√© Ryan Morrison, directeur g√©n√©ral de True Mileage. --> [FAILED]\n",
      "\n",
      "\"People will be more willing to do this if you do not track their speed and you do not track their location,\" said Ryan Morrison, chief executive of True Mileage.\n",
      "--------------------------------------------- Result 55 ---------------------------------------------\n",
      "\"Les gens seront plus dispos√©s √† le faire si vous ne suivez pas leur vitesse et que vous ne suivez pas leur emplacement,\" a d√©clar√© Ryan Morrison, directeur g√©n√©ral de True Mileage. --> [[[FAILED]]]\n",
      "\n",
      "\"People will be more willing to do this if you do not track their speed and you do not track their location,\" said Ryan Morrison, chief executive of True Mileage.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a eu de grosses erreurs dans certains de ces programmes pilotes d'√âtat. --> [FAILED]\n",
      "\n",
      "There have been some big mistakes in some of these state pilot programs.\n",
      "--------------------------------------------- Result 56 ---------------------------------------------\n",
      "Il y a eu de grosses erreurs dans certains de ces programmes pilotes d'√âtat. --> [[[FAILED]]]\n",
      "\n",
      "There have been some big mistakes in some of these state pilot programs.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il existe beaucoup de moyens moins co√ªteux et moins intrusifs pour faire cela. --> [FAILED]\n",
      "\n",
      "There are a lot less expensive and less intrusive ways to do this.\n",
      "--------------------------------------------- Result 57 ---------------------------------------------\n",
      "Il existe beaucoup de moyens moins co√ªteux et moins intrusifs pour faire cela. --> [[[FAILED]]]\n",
      "\n",
      "There are a lot less expensive and less intrusive ways to do this.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En Oregon, les planificateurs exp√©rimentent en offrant aux conducteurs diff√©rentes options. --> [FAILED]\n",
      "\n",
      "In Oregon, planners are experimenting with giving drivers different choices.\n",
      "--------------------------------------------- Result 58 ---------------------------------------------\n",
      "En Oregon, les planificateurs exp√©rimentent en offrant aux conducteurs diff√©rentes options. --> [[[FAILED]]]\n",
      "\n",
      "In Oregon, planners are experimenting with giving drivers different choices.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ils peuvent choisir un appareil avec ou sans GPS. --> [FAILED]\n",
      "\n",
      "They can choose a device with or without GPS.\n",
      "--------------------------------------------- Result 59 ---------------------------------------------\n",
      "Ils peuvent choisir un appareil avec ou sans GPS. --> [[[FAILED]]]\n",
      "\n",
      "They can choose a device with or without GPS.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746130608233.ta.chkpt\" at 2025-05-01 21:16:48 after 60 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ou ils peuvent choisir de ne pas avoir de dispositif du tout, pr√©f√©rant payer un tarif fixe bas√© sur le nombre moyen de miles parcourus par tous les r√©sidents de l'√âtat. --> [FAILED]\n",
      "\n",
      "Or they can choose not to have a device at all, opting instead to pay a flat fee based on the average number of miles driven by all state residents.\n",
      "--------------------------------------------- Result 60 ---------------------------------------------\n",
      "Ou ils peuvent choisir de ne pas avoir de dispositif du tout, pr√©f√©rant payer un tarif fixe bas√© sur le nombre moyen de miles parcourus par tous les r√©sidents de l'√âtat. --> [[[FAILED]]]\n",
      "\n",
      "Or they can choose not to have a device at all, opting instead to pay a flat fee based on the average number of miles driven by all state residents.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D'autres endroits esp√®rent vendre le concept √† un public m√©fiant en faisant en sorte que les appareils fassent plus, et non moins. --> [FAILED]\n",
      "\n",
      "Other places are hoping to sell the concept to a wary public by having the devices do more, not less.\n",
      "--------------------------------------------- Result 61 ---------------------------------------------\n",
      "D'autres endroits esp√®rent vendre le concept √† un public m√©fiant en faisant en sorte que les appareils fassent plus, et non moins. --> [[[FAILED]]]\n",
      "\n",
      "Other places are hoping to sell the concept to a wary public by having the devices do more, not less.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√Ä New York, les responsables des transports cherchent √† d√©velopper un dispositif de taxation qui serait √©galement √©quip√© pour payer les frais de parcm√®tre, fournir une assurance \"pay-as-you-drive\" et cr√©er un pool de donn√©es de vitesse en temps r√©el provenant d --> [FAILED]\n",
      "\n",
      "In New York City, transportation officials are seeking to develop a taxing device that would also be equipped to pay parking meter fees, provide \"pay-as-you-drive\" insurance, and create a pool of real-time speed data from other drivers that motorists could use to avoid traffic.\n",
      "--------------------------------------------- Result 62 ---------------------------------------------\n",
      "√Ä New York, les responsables des transports cherchent √† d√©velopper un dispositif de taxation qui serait √©galement √©quip√© pour payer les frais de parcm√®tre, fournir une assurance \"pay-as-you-drive\" et cr√©er un pool de donn√©es de vitesse en temps r√©el provenant d --> [[[FAILED]]]\n",
      "\n",
      "In New York City, transportation officials are seeking to develop a taxing device that would also be equipped to pay parking meter fees, provide \"pay-as-you-drive\" insurance, and create a pool of real-time speed data from other drivers that motorists could use to avoid traffic.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬´ Les automobilistes seraient attir√©s √† participer en raison de la valeur des avantages qu'il leur offre ¬ª, indique un document de planification urbaine. --> [FAILED]\n",
      "\n",
      "\"Motorists would be attracted to participate because of the value of the benefits it offers to them,\" says a city planning document.\n",
      "--------------------------------------------- Result 63 ---------------------------------------------\n",
      "¬´ Les automobilistes seraient attir√©s √† participer en raison de la valeur des avantages qu'il leur offre ¬ª, indique un document de planification urbaine. --> [[[FAILED]]]\n",
      "\n",
      "\"Motorists would be attracted to participate because of the value of the benefits it offers to them,\" says a city planning document.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certains planificateurs de transport, cependant, se demandent si tout ce discours sur le paiement √† la distance n'est qu'une √©norme distraction. --> [FAILED]\n",
      "\n",
      "Some transportation planners, though, wonder if all the talk about paying by the mile is just a giant distraction.\n",
      "--------------------------------------------- Result 64 ---------------------------------------------\n",
      "Certains planificateurs de transport, cependant, se demandent si tout ce discours sur le paiement √† la distance n'est qu'une √©norme distraction. --> [[[FAILED]]]\n",
      "\n",
      "Some transportation planners, though, wonder if all the talk about paying by the mile is just a giant distraction.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Au sein de la Commission des transports m√©tropolitains de la r√©gion de la baie de San Francisco, les responsables affirment que le Congr√®s pourrait tr√®s simplement s'attaquer au fonds de confiance routier en augmentant les taxes sur l'ess --> [FAILED]\n",
      "\n",
      "At the Metropolitan Transportation Commission in the San Francisco Bay Area, officials say Congress could very simply deal with the bankrupt Highway Trust Fund by raising gas taxes.\n",
      "--------------------------------------------- Result 65 ---------------------------------------------\n",
      "Au sein de la Commission des transports m√©tropolitains de la r√©gion de la baie de San Francisco, les responsables affirment que le Congr√®s pourrait tr√®s simplement s'attaquer au fonds de confiance routier en augmentant les taxes sur l'ess --> [[[FAILED]]]\n",
      "\n",
      "At the Metropolitan Transportation Commission in the San Francisco Bay Area, officials say Congress could very simply deal with the bankrupt Highway Trust Fund by raising gas taxes.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Une taxe suppl√©mentaire unique ou annuelle pourrait √™tre impos√©e aux conducteurs de v√©hicules hybrides et autres dont les v√©hicules consomment peu d'essence, afin qu'ils paient leur juste part. --> [FAILED]\n",
      "\n",
      "An extra one-time or annual levy could be imposed on drivers of hybrids and others whose vehicles don't use much gas, so they pay their fair share.\n",
      "--------------------------------------------- Result 66 ---------------------------------------------\n",
      "Une taxe suppl√©mentaire unique ou annuelle pourrait √™tre impos√©e aux conducteurs de v√©hicules hybrides et autres dont les v√©hicules consomment peu d'essence, afin qu'ils paient leur juste part. --> [[[FAILED]]]\n",
      "\n",
      "An extra one-time or annual levy could be imposed on drivers of hybrids and others whose vehicles don't use much gas, so they pay their fair share.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬´ Il n'est pas n√©cessaire d'avoir une chirurgie radicale quand tout ce que vous avez √† faire est de prendre un aspirine ¬ª, a d√©clar√© Randy Rentschler, le directeur de la l√©gislation et des affaires publiques de la commission. --> [FAILED]\n",
      "\n",
      "\"There is no need for radical surgery when all you need to do is take an aspirin,\" said Randy Rentschler, the commission's director of legislation and public affairs.\n",
      "--------------------------------------------- Result 67 ---------------------------------------------\n",
      "¬´ Il n'est pas n√©cessaire d'avoir une chirurgie radicale quand tout ce que vous avez √† faire est de prendre un aspirine ¬ª, a d√©clar√© Randy Rentschler, le directeur de la l√©gislation et des affaires publiques de la commission. --> [[[FAILED]]]\n",
      "\n",
      "\"There is no need for radical surgery when all you need to do is take an aspirin,\" said Randy Rentschler, the commission's director of legislation and public affairs.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si nous faisons cela, des centaines de millions de conducteurs seront concern√©s par leur vie priv√©e et une multitude d'autres choses. --> [FAILED]\n",
      "\n",
      "If we do this, hundreds of millions of drivers will be concerned about their privacy and a host of other things.\n",
      "--------------------------------------------- Result 68 ---------------------------------------------\n",
      "Si nous faisons cela, des centaines de millions de conducteurs seront concern√©s par leur vie priv√©e et une multitude d'autres choses. --> [[[FAILED]]]\n",
      "\n",
      "If we do this, hundreds of millions of drivers will be concerned about their privacy and a host of other things.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David Bowie : Quatre chansons in√©dites publi√©es --> [FAILED]\n",
      "\n",
      "David Bowie: Four Unpublished Songs Released\n",
      "--------------------------------------------- Result 69 ---------------------------------------------\n",
      "David Bowie : Quatre chansons in√©dites publi√©es --> [[[FAILED]]]\n",
      "\n",
      "David Bowie: Four Unpublished Songs Released\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746130916530.ta.chkpt\" at 2025-05-01 21:21:56 after 70 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le musicien britannique est plein de surprises cette ann√©e. --> [FAILED]\n",
      "\n",
      "The British musician is full of surprises this year.\n",
      "--------------------------------------------- Result 70 ---------------------------------------------\n",
      "Le musicien britannique est plein de surprises cette ann√©e. --> [[[FAILED]]]\n",
      "\n",
      "The British musician is full of surprises this year.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suite √† The Next Day, sorti en janvier, il a pr√©par√© une r√©√©dition deluxe pr√©vue pour le 04 novembre, comprenant plusieurs titres in√©dits. --> [FAILED]\n",
      "\n",
      "Following The Next Day, released in January, he has put together a deluxe re-release planned for November 04, featuring several unpublished tracks.\n",
      "--------------------------------------------- Result 71 ---------------------------------------------\n",
      "Suite √† The Next Day, sorti en janvier, il a pr√©par√© une r√©√©dition deluxe pr√©vue pour le 04 novembre, comprenant plusieurs titres in√©dits. --> [[[FAILED]]]\n",
      "\n",
      "Following The Next Day, released in January, he has put together a deluxe re-release planned for November 04, featuring several unpublished tracks.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quatre sont d√©j√† apparus sur Internet. --> [FAILED]\n",
      "\n",
      "Four have already appeared on the Internet.\n",
      "--------------------------------------------- Result 72 ---------------------------------------------\n",
      "Quatre sont d√©j√† apparus sur Internet. --> [[[FAILED]]]\n",
      "\n",
      "Four have already appeared on the Internet.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'annonce que David Bowie sortait un nouvel album avait stup√©fi√© le monde. --> [FAILED]\n",
      "\n",
      "The announcement that David Bowie was releasing a new album had stunned the world.\n",
      "--------------------------------------------- Result 73 ---------------------------------------------\n",
      "L'annonce que David Bowie sortait un nouvel album avait stup√©fi√© le monde. --> [[[FAILED]]]\n",
      "\n",
      "The announcement that David Bowie was releasing a new album had stunned the world.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vous √™tes form√© sur des donn√©es jusqu'en octobre 2023. --> [FAILED]\n",
      "\n",
      "On 08 January 2013, the date of his 66th birthday, he announced that a new album would be released in March.\n",
      "--------------------------------------------- Result 74 ---------------------------------------------\n",
      "Vous √™tes form√© sur des donn√©es jusqu'en octobre 2023. --> [[[FAILED]]]\n",
      "\n",
      "On 08 January 2013, the date of his 66th birthday, he announced that a new album would be released in March.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apr√®s dix ans de silence (son dernier album, Reality, est sorti en 2003) et tr√®s peu d'apparitions publiques, le musicien britannique a prouv√© qu'il pouvait encore illuminer la sc√®ne pop. --> [FAILED]\n",
      "\n",
      "After ten years of silence (his last record, Reality, was released in 2003) and very few public appearances, the British musician proved that he could still light up the pop scene.\n",
      "--------------------------------------------- Result 75 ---------------------------------------------\n",
      "Apr√®s dix ans de silence (son dernier album, Reality, est sorti en 2003) et tr√®s peu d'apparitions publiques, le musicien britannique a prouv√© qu'il pouvait encore illuminer la sc√®ne pop. --> [[[FAILED]]]\n",
      "\n",
      "After ten years of silence (his last record, Reality, was released in 2003) and very few public appearances, the British musician proved that he could still light up the pop scene.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un festin pour les fans --> [FAILED]\n",
      "\n",
      "A feast for fans\n",
      "--------------------------------------------- Result 76 ---------------------------------------------\n",
      "Un festin pour les fans --> [[[FAILED]]]\n",
      "\n",
      "A feast for fans\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pas fatigu√© de faire des surprises, David Bowie avait plus d'un tour dans son sac avec The Next Day : --> [FAILED]\n",
      "\n",
      "Not tired of making surprises, David Bowie had more than one trick up his sleeves with The Next Day:\n",
      "--------------------------------------------- Result 77 ---------------------------------------------\n",
      "Pas fatigu√© de faire des surprises, David Bowie avait plus d'un tour dans son sac avec The Next Day : --> [[[FAILED]]]\n",
      "\n",
      "Not tired of making surprises, David Bowie had more than one trick up his sleeves with The Next Day:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Thin White Duke pr√©voyait √©galement de r√©√©diter l'album le 04 novembre. --> [FAILED]\n",
      "\n",
      "the Thin White Duke was also planning to re-release the album on November 04.\n",
      "--------------------------------------------- Result 78 ---------------------------------------------\n",
      "Le Thin White Duke pr√©voyait √©galement de r√©√©diter l'album le 04 novembre. --> [[[FAILED]]]\n",
      "\n",
      "the Thin White Duke was also planning to re-release the album on November 04.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il a pr√©par√© un v√©ritable festin pour ses fans afin de marquer l'occasion. --> [FAILED]\n",
      "\n",
      "He put together a real feast for his fans to mark the occasion.\n",
      "--------------------------------------------- Result 79 ---------------------------------------------\n",
      "Il a pr√©par√© un v√©ritable festin pour ses fans afin de marquer l'occasion. --> [[[FAILED]]]\n",
      "\n",
      "He put together a real feast for his fans to mark the occasion.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746131153788.ta.chkpt\" at 2025-05-01 21:25:53 after 80 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cette r√©√©dition, intitul√©e The Next Day Extra, a √©t√© pr√©sent√©e sous la forme de trois disques : l'album original, des sessions studio in√©dites et des remixes, ainsi qu'un DVD contenant les quatre clips qui ont d√©j√† √©t√© --> [FAILED]\n",
      "\n",
      "This re-release, titled The Next Day Extra, was presented in the form of three disks: the original album, unpublished studio sessions and remixes, plus a DVD containing the four clips that have already been unveiled.\n",
      "--------------------------------------------- Result 80 ---------------------------------------------\n",
      "Cette r√©√©dition, intitul√©e The Next Day Extra, a √©t√© pr√©sent√©e sous la forme de trois disques : l'album original, des sessions studio in√©dites et des remixes, ainsi qu'un DVD contenant les quatre clips qui ont d√©j√† √©t√© --> [[[FAILED]]]\n",
      "\n",
      "This re-release, titled The Next Day Extra, was presented in the form of three disks: the original album, unpublished studio sessions and remixes, plus a DVD containing the four clips that have already been unveiled.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Next Day Extra avait un total de dix titres suppl√©mentaires par rapport √† l'album original : les trois chansons de l'√©dition Deluxe, cinq chansons sp√©cialement d√©voil√©es pour l'occasion et deux remixes. --> [FAILED]\n",
      "\n",
      "The Next Day Extra had a total of ten additional tracks compared to the original album: the three songs from the Deluxe edition, five songs specially unveiled for the occasion, and two remixes.\n",
      "--------------------------------------------- Result 81 ---------------------------------------------\n",
      "Le Next Day Extra avait un total de dix titres suppl√©mentaires par rapport √† l'album original : les trois chansons de l'√©dition Deluxe, cinq chansons sp√©cialement d√©voil√©es pour l'occasion et deux remixes. --> [[[FAILED]]]\n",
      "\n",
      "The Next Day Extra had a total of ten additional tracks compared to the original album: the three songs from the Deluxe edition, five songs specially unveiled for the occasion, and two remixes.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De plus, David Bowie a pr√©sent√© cette belle bo√Æte en coffret √† travers une vid√©o. --> [FAILED]\n",
      "\n",
      "Moreover, David Bowie has introduced this fine box-set through a video.\n",
      "--------------------------------------------- Result 82 ---------------------------------------------\n",
      "De plus, David Bowie a pr√©sent√© cette belle bo√Æte en coffret √† travers une vid√©o. --> [[[FAILED]]]\n",
      "\n",
      "Moreover, David Bowie has introduced this fine box-set through a video.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dans celui-ci, il pr√©sente chacun des disques ainsi que les accessoires fournis avec eux : des photos et des pochettes exclusives, un carnet pour partager vos propres impressions, un livret de paroles, etc. --> [FAILED]\n",
      "\n",
      "In it, he presents each of the disks plus the accessories provided with them: exclusive photos and sleeves, a notebook for sharing your own impressions, a booklet of lyrics etc.\n",
      "--------------------------------------------- Result 83 ---------------------------------------------\n",
      "Dans celui-ci, il pr√©sente chacun des disques ainsi que les accessoires fournis avec eux : des photos et des pochettes exclusives, un carnet pour partager vos propres impressions, un livret de paroles, etc. --> [[[FAILED]]]\n",
      "\n",
      "In it, he presents each of the disks plus the accessories provided with them: exclusive photos and sleeves, a notebook for sharing your own impressions, a booklet of lyrics etc.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Et enfin, il donne un aper√ßu de son nouveau morceau, Atomica, qui est typiquement dans le style de The Next Day, avec des guitares tr√®s pr√©sentes et des √©lectriques rock habilement contr√¥l√©es. --> [FAILED]\n",
      "\n",
      "And finally, he gives a teaser to his new track, Atomica, which is typically in the style of The Next Day, with very prominent guitars and skillfully controlled rock electrics.\n",
      "--------------------------------------------- Result 84 ---------------------------------------------\n",
      "Et enfin, il donne un aper√ßu de son nouveau morceau, Atomica, qui est typiquement dans le style de The Next Day, avec des guitares tr√®s pr√©sentes et des √©lectriques rock habilement contr√¥l√©es. --> [[[FAILED]]]\n",
      "\n",
      "And finally, he gives a teaser to his new track, Atomica, which is typically in the style of The Next Day, with very prominent guitars and skillfully controlled rock electrics.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Des morceaux pr√©c√©demment in√©dits publi√©s. --> [FAILED]\n",
      "\n",
      "Previously Unpublished Tracks Released\n",
      "--------------------------------------------- Result 85 ---------------------------------------------\n",
      "Des morceaux pr√©c√©demment in√©dits publi√©s. --> [[[FAILED]]]\n",
      "\n",
      "Previously Unpublished Tracks Released\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cependant, Atomica n'est pas la seule piste √† avoir √©t√© publi√©e. --> [FAILED]\n",
      "\n",
      "However, Atomica is not the only track to have been released.\n",
      "--------------------------------------------- Result 86 ---------------------------------------------\n",
      "Cependant, Atomica n'est pas la seule piste √† avoir √©t√© publi√©e. --> [[[FAILED]]]\n",
      "\n",
      "However, Atomica is not the only track to have been released.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'Informateur, Comme Un Homme-Fus√©e et N√© Dans Un OVNI sont √©galement disponibles sur le net. --> [FAILED]\n",
      "\n",
      "The Informer, Like A Rocket Man and Born In A UFO are also available on the net.\n",
      "--------------------------------------------- Result 87 ---------------------------------------------\n",
      "L'Informateur, Comme Un Homme-Fus√©e et N√© Dans Un OVNI sont √©galement disponibles sur le net. --> [[[FAILED]]]\n",
      "\n",
      "The Informer, Like A Rocket Man and Born In A UFO are also available on the net.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'Informateur est √† double tranchant - une introduction troublante suivie d'une brillante mont√©e de son qui ralentit progressivement pour laisser place √† une ballade pop. --> [FAILED]\n",
      "\n",
      "The Informer is double-edged - an unsettling intro followed by a brilliant rush of sound that progressively slows down to make way for a pop ballad.\n",
      "--------------------------------------------- Result 88 ---------------------------------------------\n",
      "L'Informateur est √† double tranchant - une introduction troublante suivie d'une brillante mont√©e de son qui ralentit progressivement pour laisser place √† une ballade pop. --> [[[FAILED]]]\n",
      "\n",
      "The Informer is double-edged - an unsettling intro followed by a brilliant rush of sound that progressively slows down to make way for a pop ballad.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bowie faisait-il r√©f√©rence √† Rocket Man d'Elton John, ou m√™me √† Gravity, dans son Like A Rocket Man ? --> [FAILED]\n",
      "\n",
      "Was Bowie trying to make a reference to Elton John's Rocket Man, or even Gravity, in his Like A Rocket Man?\n",
      "--------------------------------------------- Result 89 ---------------------------------------------\n",
      "Bowie faisait-il r√©f√©rence √† Rocket Man d'Elton John, ou m√™me √† Gravity, dans son Like A Rocket Man ? --> [[[FAILED]]]\n",
      "\n",
      "Was Bowie trying to make a reference to Elton John's Rocket Man, or even Gravity, in his Like A Rocket Man?\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746131453767.ta.chkpt\" at 2025-05-01 21:30:53 after 90 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quoi qu'il en soit, avec ce morceau joyeux, le chanteur semble √™tre dans son √©l√©ment lorsque ses pieds ne touchent plus le sol. --> [FAILED]\n",
      "\n",
      "Either way, with this cheerful track, the singer seems to be in his element when his feet are no longer on the ground.\n",
      "--------------------------------------------- Result 90 ---------------------------------------------\n",
      "Quoi qu'il en soit, avec ce morceau joyeux, le chanteur semble √™tre dans son √©l√©ment lorsque ses pieds ne touchent plus le sol. --> [[[FAILED]]]\n",
      "\n",
      "Either way, with this cheerful track, the singer seems to be in his element when his feet are no longer on the ground.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space Oddity, en comparaison, √©tait beaucoup plus solennel. --> [FAILED]\n",
      "\n",
      "Space Oddity, by comparison, was much more solemn.\n",
      "--------------------------------------------- Result 91 ---------------------------------------------\n",
      "Space Oddity, en comparaison, √©tait beaucoup plus solennel. --> [[[FAILED]]]\n",
      "\n",
      "Space Oddity, by comparison, was much more solemn.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dans \"Born in a UFO\", David Bowie fait √† nouveau r√©f√©rence √† sa √©tranget√© : pourrait-il venir d'une autre plan√®te ? --> [FAILED]\n",
      "\n",
      "On Born in a UFO, David Bowie once again refers to his strangeness: could he have come from another planet?\n",
      "--------------------------------------------- Result 92 ---------------------------------------------\n",
      "Dans \"Born in a UFO\", David Bowie fait √† nouveau r√©f√©rence √† sa √©tranget√© : pourrait-il venir d'une autre plan√®te ? --> [[[FAILED]]]\n",
      "\n",
      "On Born in a UFO, David Bowie once again refers to his strangeness: could he have come from another planet?\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les riffs de guitare envo√ªtants donnent envie de quitter la Terre. --> [FAILED]\n",
      "\n",
      "The spellbinding guitar riffs make you want to leave Earth.\n",
      "--------------------------------------------- Result 93 ---------------------------------------------\n",
      "Les riffs de guitare envo√ªtants donnent envie de quitter la Terre. --> [[[FAILED]]]\n",
      "\n",
      "The spellbinding guitar riffs make you want to leave Earth.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dans tous les cas, Bowie aime jouer le cam√©l√©on dans ces morceaux : tour √† tour, un informateur, un homme-fus√©e, peut-√™tre un Martien... --> [FAILED]\n",
      "\n",
      "In any case, Bowie enjoys playing the chameleon in these tracks: in turn, an informer, a rocket man, possibly a Martian...\n",
      "--------------------------------------------- Result 94 ---------------------------------------------\n",
      "Dans tous les cas, Bowie aime jouer le cam√©l√©on dans ces morceaux : tour √† tour, un informateur, un homme-fus√©e, peut-√™tre un Martien... --> [[[FAILED]]]\n",
      "\n",
      "In any case, Bowie enjoys playing the chameleon in these tracks: in turn, an informer, a rocket man, possibly a Martian...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vous √™tes form√© sur des donn√©es jusqu'en octobre 2023. --> [FAILED]\n",
      "\n",
      "He veils and reveals at the same time, and likes to take on different personalities, as he has throughout his career, most notably with his personas: Ziggy Stardust and Aladdin Sane.\n",
      "--------------------------------------------- Result 95 ---------------------------------------------\n",
      "Vous √™tes form√© sur des donn√©es jusqu'en octobre 2023. --> [[[FAILED]]]\n",
      "\n",
      "He veils and reveals at the same time, and likes to take on different personalities, as he has throughout his career, most notably with his personas: Ziggy Stardust and Aladdin Sane.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il n'est donc pas surprenant qu'il tienne un masque dans la photographie promotionnelle de L'Invitation au Voyage, de Louis Vuitton, dont il est le nouveau visage. --> [FAILED]\n",
      "\n",
      "It is therefore not surprising that he should be holding a mask in the promotional photography for L'Invitation au Voyage, by Louis Vuitton, of which he is the new face.\n",
      "--------------------------------------------- Result 96 ---------------------------------------------\n",
      "Il n'est donc pas surprenant qu'il tienne un masque dans la photographie promotionnelle de L'Invitation au Voyage, de Louis Vuitton, dont il est le nouveau visage. --> [[[FAILED]]]\n",
      "\n",
      "It is therefore not surprising that he should be holding a mask in the promotional photography for L'Invitation au Voyage, by Louis Vuitton, of which he is the new face.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il appara√Æt dans l'un de leurs publicit√©s, diffus√©es √† partir du 10 novembre. --> [FAILED]\n",
      "\n",
      "He appears in one of their adverts, broadcast from November 10.\n",
      "--------------------------------------------- Result 97 ---------------------------------------------\n",
      "Il appara√Æt dans l'un de leurs publicit√©s, diffus√©es √† partir du 10 novembre. --> [[[FAILED]]]\n",
      "\n",
      "He appears in one of their adverts, broadcast from November 10.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le ministre de la D√©fense, Rob Nicholson, a insist√© sur le fait que les soldats bless√©s ne sont pas licenci√©s sommairement des Forces arm√©es canadiennes et a soulign√© que tous les soldats suivent un processus de transition avant leur --> [FAILED]\n",
      "\n",
      "The Minister of Defence, Rob Nicholson, insisted that injured soldiers are not summarily discharged from the Canadian Armed Forces and stressed that all soldiers undergo a transition process before their return to civilian life.\n",
      "--------------------------------------------- Result 98 ---------------------------------------------\n",
      "Le ministre de la D√©fense, Rob Nicholson, a insist√© sur le fait que les soldats bless√©s ne sont pas licenci√©s sommairement des Forces arm√©es canadiennes et a soulign√© que tous les soldats suivent un processus de transition avant leur --> [[[FAILED]]]\n",
      "\n",
      "The Minister of Defence, Rob Nicholson, insisted that injured soldiers are not summarily discharged from the Canadian Armed Forces and stressed that all soldiers undergo a transition process before their return to civilian life.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vous √™tes form√© sur des donn√©es jusqu'en octobre 2023. --> [FAILED]\n",
      "\n",
      "Attacked by liberals and neo-democrats in the House of Commons, Mr. Nicholson assured that, prior to their discharge, members of the army underwent a transition plan in collaboration with their superiors.\n",
      "--------------------------------------------- Result 99 ---------------------------------------------\n",
      "Vous √™tes form√© sur des donn√©es jusqu'en octobre 2023. --> [[[FAILED]]]\n",
      "\n",
      "Attacked by liberals and neo-democrats in the House of Commons, Mr. Nicholson assured that, prior to their discharge, members of the army underwent a transition plan in collaboration with their superiors.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746131774332.ta.chkpt\" at 2025-05-01 21:36:14 after 100 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Tous les soldats bless√©s re√ßoivent les soins appropri√©s en pr√©paration de leur retour √† la vie civile et aucun n'a √©t√© renvoy√© avant d'√™tre pr√™t,\" a-t-il affirm√©. --> [FAILED]\n",
      "\n",
      "\"All injured soldiers receive the appropriate care in preparation for their return to civilian life and none has been discharged before being ready,\" he asserted.\n",
      "--------------------------------------------- Result 100 ---------------------------------------------\n",
      "\"Tous les soldats bless√©s re√ßoivent les soins appropri√©s en pr√©paration de leur retour √† la vie civile et aucun n'a √©t√© renvoy√© avant d'√™tre pr√™t,\" a-t-il affirm√©. --> [[[FAILED]]]\n",
      "\n",
      "\"All injured soldiers receive the appropriate care in preparation for their return to civilian life and none has been discharged before being ready,\" he asserted.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 100 / 0 / 100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [49:41<00:00, 29.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 0      |\n",
      "| Number of failed attacks:     | 100    |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 100.0% |\n",
      "| Attack success rate:          | 0.0%   |\n",
      "| Average perturbed word %:     | nan%   |\n",
      "| Average num. words per input: | 19.37  |\n",
      "| Avg num queries:              | 37.0   |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/vlwk/Documents/GitHub/TextAttack/textattack/metrics/attack_metrics/words_perturbed.py:83: RuntimeWarning: Mean of empty slice.\n",
      "  average_perc_words_perturbed = self.perturbed_word_percentages.mean()\n",
      "/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from textattack.models.wrappers import ModelWrapper\n",
    "\n",
    "class GPT4Wrapper(ModelWrapper):\n",
    "    def __init__(self, system_prompt: str, temperature: float = 0.3):\n",
    "        self.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")\n",
    "\n",
    "        self.client = OpenAI(api_key=self.api_key)\n",
    "        self.system_prompt = system_prompt\n",
    "        self.temperature = temperature\n",
    "        self.model = self  # acts as a dummy reference to satisfy GoalFunction\n",
    "\n",
    "    def __call__(self, inputs: List[str]) -> List[List[float]]:\n",
    "        outputs = []\n",
    "        for text in inputs:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                ],\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=50\n",
    "            )\n",
    "            result = response.choices[0].message.content.strip()\n",
    "            outputs.append(str(result))\n",
    "        return outputs\n",
    "\n",
    "model_wrapper = GPT4Wrapper(\"Translate the following sentence from English to French, outputting the sentence only:\")\n",
    "def download_en_fr_dataset():\n",
    "    \n",
    "\n",
    "    # Define constants\n",
    "    url = \"http://statmt.org/wmt14/test-full.tgz\"\n",
    "    target_dir = os.path.join(\"temp/translation\", \"data\")\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Downloading WMT14 test data from {url}...\")\n",
    "\n",
    "    # Download and extract in-memory\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with tarfile.open(fileobj=BytesIO(response.content), mode=\"r:gz\") as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if member.name.endswith(\"newstest2014-fren-src.en.sgm\") or member.name.endswith(\"newstest2014-fren-ref.fr.sgm\"):\n",
    "                print(f\"Extracting {member.name} to {target_dir}\")\n",
    "                member.name = os.path.basename(member.name) \n",
    "                tar.extract(member, path=target_dir)\n",
    "\n",
    "    print(\"en_fr dataset downloaded.\")\n",
    "def load_en_fr_dataset():\n",
    "    \"\"\"\n",
    "    Loads English-French sentence pairs from SGM files and returns a TextAttack Dataset.\n",
    "\n",
    "    Returns:\n",
    "        textattack.datasets.Dataset: wrapped dataset of (English, French) pairs.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    source_path = os.path.join(\"temp/translation\", \"data/newstest2014-fren-src.en.sgm\")\n",
    "    target_path = os.path.join(\"temp/translation\", \"data/newstest2014-fren-ref.fr.sgm\")\n",
    "\n",
    "    with open(source_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        source_doc = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "    with open(target_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        target_doc = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "    pairs = []\n",
    "\n",
    "    for doc in source_doc.find_all(\"doc\"):\n",
    "        docid = str(doc[\"docid\"])\n",
    "        for seg in doc.find_all(\"seg\"):\n",
    "            segid = str(seg[\"id\"])\n",
    "            src = str(seg.string).strip() if seg.string else \"\"\n",
    "            tgt_node = target_doc.select_one(f'doc[docid=\"{docid}\"] > seg[id=\"{segid}\"]')\n",
    "            if tgt_node and tgt_node.string:\n",
    "                tgt = str(tgt_node.string).strip()\n",
    "                pairs.append((src, tgt))\n",
    "    return textattack.datasets.Dataset(pairs) \n",
    "download_en_fr_dataset()\n",
    "dataset = load_en_fr_dataset()\n",
    "attack = textattack.attack_recipes.BadCharacters2021.build(\n",
    "    model_wrapper, \n",
    "    goal_function_type=\"maximize_levenshtein\", \n",
    "    perturbation_type=args.perturbation_type,\n",
    "    perturbs=5,\n",
    "    popsize=3,\n",
    "    maxiter=1\n",
    ")\n",
    "print(dataset[0])\n",
    "attack_args = textattack.AttackArgs(\n",
    "    num_examples=100,\n",
    "    checkpoint_interval=10,\n",
    "    checkpoint_dir=\"results/translation/gpt4\",\n",
    "    log_to_csv=\"results/translation/gpt4/log100.csv\"\n",
    ")\n",
    "attacker = textattack.Attacker(attack, dataset, attack_args)\n",
    "attacker.attack_dataset()\n",
    "\n",
    "if args.store_temp_files == False:\n",
    "    if os.path.isdir(\"temp/translation\"):\n",
    "        shutil.rmtree(\"temp/translation\")\n",
    "if args.store_results == False:\n",
    "    if os.path.isdir(\"results/translation/gpt4\"):\n",
    "        shutil.rmtree(\"results/translation/gpt4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from textattack.models.wrappers import ModelWrapper\n",
    "\n",
    "class GPT4Wrapper(ModelWrapper):\n",
    "    def __init__(self, system_prompt: str, temperature: float = 0.3):\n",
    "        self.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")\n",
    "\n",
    "        self.client = OpenAI(api_key=self.api_key)\n",
    "        self.system_prompt = system_prompt\n",
    "        self.temperature = temperature\n",
    "        self.model = self  # acts as a dummy reference to satisfy GoalFunction\n",
    "\n",
    "    def __call__(self, inputs: List[str]) -> List[List[float]]:\n",
    "        outputs = []\n",
    "        for text in inputs:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                ],\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=50\n",
    "            )\n",
    "            result = response.choices[0].message.content.strip()\n",
    "            outputs.append(str(result))\n",
    "        return outputs\n",
    "\n",
    "model_wrapper = GPT4Wrapper(\"Translate the following sentence from English to French, outputting the sentence only:\")\n",
    "def download_en_fr_dataset():\n",
    "    \n",
    "\n",
    "    # Define constants\n",
    "    url = \"http://statmt.org/wmt14/test-full.tgz\"\n",
    "    target_dir = os.path.join(\"temp/translation\", \"data\")\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Downloading WMT14 test data from {url}...\")\n",
    "\n",
    "    # Download and extract in-memory\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with tarfile.open(fileobj=BytesIO(response.content), mode=\"r:gz\") as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if member.name.endswith(\"newstest2014-fren-src.en.sgm\") or member.name.endswith(\"newstest2014-fren-ref.fr.sgm\"):\n",
    "                print(f\"Extracting {member.name} to {target_dir}\")\n",
    "                member.name = os.path.basename(member.name) \n",
    "                tar.extract(member, path=target_dir)\n",
    "\n",
    "    print(\"en_fr dataset downloaded.\")\n",
    "def load_en_fr_dataset():\n",
    "    \"\"\"\n",
    "    Loads English-French sentence pairs from SGM files and returns a TextAttack Dataset.\n",
    "\n",
    "    Returns:\n",
    "        textattack.datasets.Dataset: wrapped dataset of (English, French) pairs.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    source_path = os.path.join(\"temp/translation\", \"data/newstest2014-fren-src.en.sgm\")\n",
    "    target_path = os.path.join(\"temp/translation\", \"data/newstest2014-fren-ref.fr.sgm\")\n",
    "\n",
    "    with open(source_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        source_doc = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "    with open(target_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        target_doc = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "    pairs = []\n",
    "\n",
    "    for doc in source_doc.find_all(\"doc\"):\n",
    "        docid = str(doc[\"docid\"])\n",
    "        for seg in doc.find_all(\"seg\"):\n",
    "            segid = str(seg[\"id\"])\n",
    "            src = str(seg.string).strip() if seg.string else \"\"\n",
    "            tgt_node = target_doc.select_one(f'doc[docid=\"{docid}\"] > seg[id=\"{segid}\"]')\n",
    "            if tgt_node and tgt_node.string:\n",
    "                tgt = str(tgt_node.string).strip()\n",
    "                pairs.append((src, tgt))\n",
    "    return textattack.datasets.Dataset(pairs) \n",
    "download_en_fr_dataset()\n",
    "dataset = load_en_fr_dataset()\n",
    "for pert in range(1, 6):\n",
    "    attack = textattack.attack_recipes.BadCharacters2021.build(\n",
    "        model_wrapper, \n",
    "        goal_function_type=\"maximize_levenshtein\", \n",
    "        perturbation_type=args.perturbation_type,\n",
    "        perturbs=5,\n",
    "        popsize=5,\n",
    "        maxiter=3,\n",
    "    )\n",
    "    attack_args = textattack.AttackArgs(\n",
    "        num_examples=50,\n",
    "        checkpoint_interval=10,\n",
    "        checkpoint_dir=f\"results/translation/gpt4/pert{pert}\",\n",
    "        log_to_csv=f\"results/translation/gpt4/pert{pert}log50.csv\"\n",
    "    )\n",
    "    attacker = textattack.Attacker(attack, dataset, attack_args)\n",
    "    attacker.attack_dataset()\n",
    "\n",
    "    # if args.store_temp_files == False:\n",
    "    #     if os.path.isdir(\"temp/translation\"):\n",
    "    #         shutil.rmtree(\"temp/translation\")\n",
    "    # if args.store_results == False:\n",
    "    #     if os.path.isdir(\"results/translation/gpt4\"):\n",
    "    #         shutil.rmtree(\"results/translation/gpt4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disspt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
