{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import textattack\n",
    "from textattack.models.wrappers import ModelWrapper\n",
    "from typing import List, Tuple\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from string import punctuation\n",
    "import argparse\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "import os\n",
    "import tarfile\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from bs4 import BeautifulSoup\n",
    "import torch\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import subprocess\n",
    "import zipfile\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure experiment\n",
    "perturbation_type = 'homoglyphs'  # options: 'homoglyphs', 'invisible', 'deletions', 'reorderings'\n",
    "store_temp_files = False\n",
    "store_results = True\n",
    "class Args:\n",
    "    pass\n",
    "args = Args()\n",
    "args.perturbation_type = perturbation_type\n",
    "args.store_temp_files = store_temp_files\n",
    "args.store_results = store_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(46313) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /opt/anaconda3/envs/disspt2/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (0.0.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/disspt2/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/envs/disspt2/lib/python3.9/site-packages (from bs4->-r requirements.txt (line 1)) (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/disspt2/lib/python3.9/site-packages (from requests->-r requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/disspt2/lib/python3.9/site-packages (from requests->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/disspt2/lib/python3.9/site-packages (from requests->-r requirements.txt (line 2)) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/disspt2/lib/python3.9/site-packages (from requests->-r requirements.txt (line 2)) (2025.4.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/disspt2/lib/python3.9/site-packages (from beautifulsoup4->bs4->-r requirements.txt (line 1)) (2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.51.3\n",
      "Uninstalling transformers-4.51.3:\n",
      "  Would remove:\n",
      "    /opt/anaconda3/envs/projenvconda39/bin/transformers-cli\n",
      "    /opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/transformers-4.51.3.dist-info/*\n",
      "    /opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/transformers/*\n",
      "Proceed (Y/n)? ^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e89d301f7b4b2d9fbb99777d2dd597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 50 files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f6ad096ac848b1a2cd26f54f02cd71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00050.safetensors:   5%|5         | 231M/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a9c700fd4e461ea10a285db2f706ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00050.safetensors:   5%|5         | 231M/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6021df7620774145a38188160faa9c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00050.safetensors:   5%|4         | 220M/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbe61c21aae4505a199be78fc1c993b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00050.safetensors:   5%|5         | 231M/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b240aaa8dc97433c835b75400e5a0a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00050.safetensors:   5%|4         | 199M/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c420a073d54401298caadc601730e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00050.safetensors:   5%|5         | 231M/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128ab8d02bbb43dfbcf2735e644bdedb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00050.safetensors:   6%|5         | 220M/3.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc8e14019e744db86e4449c807727ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00050.safetensors:   5%|5         | 231M/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/huggingface_hub/file_download.py:752: UserWarning: Not enough free disk space to download the file. The expected file size is: 4404.21 MB. The target location /Users/vlwk/.cache/huggingface/hub/models--meta-llama--Llama-4-Scout-17B-16E-Instruct/blobs only has 85.49 MB free disk space.\n",
      "  warnings.warn(\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f52299dabc048469b085d677e9a1060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00010-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d5a8081c0f4ba6830cf4c14c7fdb7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7c431367534a8796c778644404ad22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00011-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/huggingface_hub/file_download.py:752: UserWarning: Not enough free disk space to download the file. The expected file size is: 4404.21 MB. The target location /Users/vlwk/.cache/huggingface/hub/models--meta-llama--Llama-4-Scout-17B-16E-Instruct/blobs only has 84.80 MB free disk space.\n",
      "  warnings.warn(\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc919b2424694b5cacb3065df6d77153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00013-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0971e7ab166f4788ac2fef475af756a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00012-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/huggingface_hub/file_download.py:752: UserWarning: Not enough free disk space to download the file. The expected file size is: 4404.21 MB. The target location /Users/vlwk/.cache/huggingface/hub/models--meta-llama--Llama-4-Scout-17B-16E-Instruct/blobs only has 85.18 MB free disk space.\n",
      "  warnings.warn(\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d134f79a1cd44727ad5a4458b990e539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00014-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/huggingface_hub/file_download.py:752: UserWarning: Not enough free disk space to download the file. The expected file size is: 4404.21 MB. The target location /Users/vlwk/.cache/huggingface/hub/models--meta-llama--Llama-4-Scout-17B-16E-Instruct/blobs only has 85.15 MB free disk space.\n",
      "  warnings.warn(\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31444c20e244ab0a11ea06a3f25be07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00015-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6ecf423f034dc08bc7f1a35ffff50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00016-of-00050.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "meta-llama/Llama-4-Scout-17B-16E-Instruct does not appear to have files named ('model-00001-of-00050.safetensors', 'model-00002-of-00050.safetensors', 'model-00003-of-00050.safetensors', 'model-00004-of-00050.safetensors', 'model-00005-of-00050.safetensors', 'model-00006-of-00050.safetensors', 'model-00007-of-00050.safetensors', 'model-00008-of-00050.safetensors', 'model-00009-of-00050.safetensors', 'model-00010-of-00050.safetensors', 'model-00011-of-00050.safetensors', 'model-00012-of-00050.safetensors', 'model-00013-of-00050.safetensors', 'model-00014-of-00050.safetensors', 'model-00015-of-00050.safetensors', 'model-00016-of-00050.safetensors', 'model-00017-of-00050.safetensors', 'model-00018-of-00050.safetensors', 'model-00019-of-00050.safetensors', 'model-00020-of-00050.safetensors', 'model-00021-of-00050.safetensors', 'model-00022-of-00050.safetensors', 'model-00023-of-00050.safetensors', 'model-00024-of-00050.safetensors', 'model-00025-of-00050.safetensors', 'model-00026-of-00050.safetensors', 'model-00027-of-00050.safetensors', 'model-00028-of-00050.safetensors', 'model-00029-of-00050.safetensors', 'model-00030-of-00050.safetensors', 'model-00031-of-00050.safetensors', 'model-00032-of-00050.safetensors', 'model-00033-of-00050.safetensors', 'model-00034-of-00050.safetensors', 'model-00035-of-00050.safetensors', 'model-00036-of-00050.safetensors', 'model-00037-of-00050.safetensors', 'model-00038-of-00050.safetensors', 'model-00039-of-00050.safetensors', 'model-00040-of-00050.safetensors', 'model-00041-of-00050.safetensors', 'model-00042-of-00050.safetensors', 'model-00043-of-00050.safetensors', 'model-00044-of-00050.safetensors', 'model-00045-of-00050.safetensors', 'model-00046-of-00050.safetensors', 'model-00047-of-00050.safetensors', 'model-00048-of-00050.safetensors', 'model-00049-of-00050.safetensors', 'model-00050-of-00050.safetensors'). Checkout 'https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct/tree/main'for available files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     10\u001b[0m ]\n\u001b[1;32m     11\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(messages, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLlama4ForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice), max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(outputs[:, inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/transformers/modeling_utils.py:279\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/transformers/modeling_utils.py:4260\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4251\u001b[0m     gguf_file\n\u001b[1;32m   4252\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4253\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[1;32m   4254\u001b[0m ):\n\u001b[1;32m   4255\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   4256\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4257\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded from GGUF files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4258\u001b[0m     )\n\u001b[0;32m-> 4260\u001b[0m checkpoint_files, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4262\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4267\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4273\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4276\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4278\u001b[0m is_sharded \u001b[38;5;241m=\u001b[39m sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4279\u001b[0m is_quantized \u001b[38;5;241m=\u001b[39m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/transformers/modeling_utils.py:1152\u001b[0m, in \u001b[0;36m_get_resolved_checkpoint_files\u001b[0;34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash)\u001b[0m\n\u001b[1;32m   1150\u001b[0m sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[0;32m-> 1152\u001b[0m     checkpoint_files, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_checkpoint_shard_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     checkpoint_files \u001b[38;5;241m=\u001b[39m [resolved_archive_file] \u001b[38;5;28;01mif\u001b[39;00m pretrained_model_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/transformers/utils/hub.py:1115\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m shard_filenames, sharded_metadata\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;66;03m# At this stage pretrained_model_name_or_path is a model identifier on the Hub. Try to get everything from cache,\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# or download the files\u001b[39;00m\n\u001b[0;32m-> 1115\u001b[0m cached_filenames \u001b[38;5;241m=\u001b[39m \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshard_filenames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached_filenames, sharded_metadata\n",
      "File \u001b[0;32m/opt/anaconda3/envs/projenvconda39/lib/python3.9/site-packages/transformers/utils/hub.py:517\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m     revision_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m revision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m revision\n\u001b[1;32m    514\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_entries[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_entries) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;241m*\u001b[39mmissing_entries,)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    516\u001b[0m     )\n\u001b[0;32m--> 517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    518\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Checkout \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/tree/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    519\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor available files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    520\u001b[0m     )\n\u001b[1;32m    522\u001b[0m \u001b[38;5;66;03m# Remove potential missing entries (we can silently remove them at this point based on the flags)\u001b[39;00m\n\u001b[1;32m    523\u001b[0m resolved_files \u001b[38;5;241m=\u001b[39m [file \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m resolved_files \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[0;31mOSError\u001b[0m: meta-llama/Llama-4-Scout-17B-16E-Instruct does not appear to have files named ('model-00001-of-00050.safetensors', 'model-00002-of-00050.safetensors', 'model-00003-of-00050.safetensors', 'model-00004-of-00050.safetensors', 'model-00005-of-00050.safetensors', 'model-00006-of-00050.safetensors', 'model-00007-of-00050.safetensors', 'model-00008-of-00050.safetensors', 'model-00009-of-00050.safetensors', 'model-00010-of-00050.safetensors', 'model-00011-of-00050.safetensors', 'model-00012-of-00050.safetensors', 'model-00013-of-00050.safetensors', 'model-00014-of-00050.safetensors', 'model-00015-of-00050.safetensors', 'model-00016-of-00050.safetensors', 'model-00017-of-00050.safetensors', 'model-00018-of-00050.safetensors', 'model-00019-of-00050.safetensors', 'model-00020-of-00050.safetensors', 'model-00021-of-00050.safetensors', 'model-00022-of-00050.safetensors', 'model-00023-of-00050.safetensors', 'model-00024-of-00050.safetensors', 'model-00025-of-00050.safetensors', 'model-00026-of-00050.safetensors', 'model-00027-of-00050.safetensors', 'model-00028-of-00050.safetensors', 'model-00029-of-00050.safetensors', 'model-00030-of-00050.safetensors', 'model-00031-of-00050.safetensors', 'model-00032-of-00050.safetensors', 'model-00033-of-00050.safetensors', 'model-00034-of-00050.safetensors', 'model-00035-of-00050.safetensors', 'model-00036-of-00050.safetensors', 'model-00037-of-00050.safetensors', 'model-00038-of-00050.safetensors', 'model-00039-of-00050.safetensors', 'model-00040-of-00050.safetensors', 'model-00041-of-00050.safetensors', 'model-00042-of-00050.safetensors', 'model-00043-of-00050.safetensors', 'model-00044-of-00050.safetensors', 'model-00045-of-00050.safetensors', 'model-00046-of-00050.safetensors', 'model-00047-of-00050.safetensors', 'model-00048-of-00050.safetensors', 'model-00049-of-00050.safetensors', 'model-00050-of-00050.safetensors'). Checkout 'https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct/tree/main'for available files."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, Llama4ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\", return_dict=True)\n",
    "\n",
    "model = Llama4ForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "outputs = model.generate(**inputs.to(model.device), max_new_tokens=100)\n",
    "outputs = tokenizer.batch_decode(outputs[:, inputs[\"input_ids\"].shape[-1]:])\n",
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Llama4ScoutWrapper(ModelWrapper):\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "    def __call__(self, input_texts: List[str]) -> List[str]:\n",
    "        messages = []\n",
    "        for message in input_texts:\n",
    "            messages.append({\"role\": \"user\", \"content\": f\"This sentence is one of the following emotions: sadness, joy, love, anger, fear, surprise. Output the emotion. Sentence: {message}\"})\n",
    "        inputs = self.tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\", return_dict=True)\n",
    "        outputs = self.model.generate(**inputs.to(model.device), max_new_tokens=100)\n",
    "        outputs = self.tokenizer.batch_decode(outputs[:, inputs[\"input_ids\"].shape[-1]:])\n",
    "        return outputs.tolist()\n",
    "\n",
    "model_id = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = Llama4ForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "model_wrapper = Llama4ScoutWrapper(model, tokenizer)\n",
    "\n",
    "attack = textattack.attack_recipes.BadCharacters2021.build(\n",
    "    model_wrapper, \n",
    "    goal_function_type=\"targeted_bonus\",\n",
    "    perturbation_type=args.perturbation_type\n",
    ")\n",
    "dataset = textattack.datasets.HuggingFaceDataset(\"emotion\", split=\"test\")\n",
    "print(dataset[0])\n",
    "attack_args = textattack.AttackArgs(\n",
    "    num_examples=10,\n",
    "    log_to_csv=\"results/emotion/llama4scout/log.csv\"\n",
    ")\n",
    "attacker = textattack.Attacker(attack, dataset, attack_args)\n",
    "attacker.attack_dataset()\n",
    "\n",
    "if args.store_results == False:\n",
    "    if os.path.isdir(\"results/emotion/llama4scout\"):\n",
    "        shutil.rmtree(\"results/emotion/llama4scout\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT4 x Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from textattack.models.wrappers import ModelWrapper\n",
    "\n",
    "class GPT4Wrapper(ModelWrapper):\n",
    "    def __init__(self, system_prompt: str, temperature: float = 0.3):\n",
    "        self.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")\n",
    "\n",
    "        self.client = OpenAI(api_key=self.api_key)\n",
    "        self.system_prompt = system_prompt\n",
    "        self.temperature = temperature\n",
    "        self.model = self  # acts as a dummy reference to satisfy GoalFunction\n",
    "\n",
    "    def __call__(self, inputs: List[str]) -> List[List[float]]:\n",
    "        outputs = []\n",
    "        for text in inputs:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                ],\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=50\n",
    "            )\n",
    "            result = response.choices[0].message.content.strip()\n",
    "            arr = [0.0] * 6 \n",
    "            try:\n",
    "                idx = int(result)\n",
    "                if 0 <= idx < len(arr):\n",
    "                    arr[idx] = 1.0\n",
    "            except ValueError:\n",
    "                print(f\"Could not parse result: {result}\")\n",
    "            outputs.append(arr)\n",
    "        return outputs\n",
    "\n",
    "model_wrapper = GPT4Wrapper(\"This sentence is one of the following emotions: sadness (0), joy (1), love (2), anger (3), fear (4), surprise (5). Output the number of the emotion. Sentence:\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = textattack.attack_recipes.BadCharacters2021.build(\n",
    "    model_wrapper, \n",
    "    goal_function_type=\"targeted_bonus\",\n",
    "    perturbation_type=args.perturbation_type,\n",
    "    target_class=1,\n",
    "    perturbs=5,\n",
    "    popsize=3,\n",
    "    maxiter=1\n",
    ")\n",
    "dataset = textattack.datasets.HuggingFaceDataset(\"dair-ai/emotion\", split=\"test\")\n",
    "attack_args = textattack.AttackArgs(\n",
    "    num_examples=100,\n",
    "    checkpoint_interval=10,\n",
    "    checkpoint_dir=\"results/emotion/gpt4\",\n",
    "    log_to_csv=\"results/emotion/gpt4/log100.csv\"\n",
    ")\n",
    "attacker = textattack.Attacker(attack, dataset, attack_args)\n",
    "attacker.attack_dataset()\n",
    "\n",
    "if args.store_results == False:\n",
    "    if os.path.isdir(\"results/emotion/gpt4\"):\n",
    "        shutil.rmtree(\"results/emotion/gpt4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: No entry found for goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n",
      "textattack: Unknown if model of class <class '__main__.GPT4Wrapper'> compatible with goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n",
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mdair-ai/emotion\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
      "textattack: Logging to CSV at path results/emotion/gpt4/pert1/log50.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): DifferentialEvolution(\n",
      "    (popsize):  5\n",
      "    (maxiter):  3\n",
      "    (max_perturbs):  1\n",
      "    (verbose):  False\n",
      "  )\n",
      "  (goal_function):  TargetedBonus\n",
      "  (transformation):  WordSwapHomoglyphSwap\n",
      "  (constraints): None\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   2%|▏         | 1/50 [00:04<03:35,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 0 / 2:   4%|▍         | 2/50 [00:08<03:23,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 0 / 3:   6%|▌         | 3/50 [00:15<04:01,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 3 / 0 / 4:   8%|▊         | 4/50 [00:18<03:37,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my bouquet of red and yellow tulips under my arm feeling slightly more optimistic than when i arrived\n",
      "\n",
      "i left with my bouquet of red and yellow tulipѕ under my arm feeling slightly more optimistic than when i arrived\n",
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my bouquet of red and yellow [[tulips]] under my arm feeling slightly more optimistic than when i arrived\n",
      "\n",
      "i left with my bouquet of red and yellow [[tulipѕ]] under my arm feeling slightly more optimistic than when i arrived\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 3 / 0 / 5:  10%|█         | 5/50 [00:23<03:27,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling a little vain when i did this one\n",
      "\n",
      "i was feeling a littlе vain when i did this one\n",
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling a [[little]] vain when i did this one\n",
      "\n",
      "i was feeling a [[littlе]] vain when i did this one\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 4 / 0 / 6:  12%|█▏        | 6/50 [00:26<03:14,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 5 / 0 / 7:  14%|█▍        | 7/50 [00:29<02:58,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "\n",
      "\n",
      "Could not parse result: The emotion expressed in the sentence is sadness (0).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 6 / 0 / 8:  16%|█▌        | 8/50 [00:36<03:11,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 6 / 0 / 9:  18%|█▊        | 9/50 [00:41<03:09,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have the same breathless feeling as a reader eager to see what will happen next\n",
      "\n",
      "i like to have the same breathless feeling as a reader еager to see what will happen next\n",
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have the same breathless feeling as a reader [[eager]] to see what will happen next\n",
      "\n",
      "i like to have the same breathless feeling as a reader [[еager]] to see what will happen next\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 7 / 0 / 10:  20%|██        | 10/50 [00:46<03:07,  4.70s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert1/1746360048690.ta.chkpt\" at 2025-05-04 13:00:48 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 8 / 0 / 11:  22%|██▏       | 11/50 [00:51<03:02,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "--------------------------------------------- Result 11 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 9 / 0 / 12:  24%|██▍       | 12/50 [00:54<02:53,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "--------------------------------------------- Result 12 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 10 / 0 / 13:  26%|██▌       | 13/50 [00:59<02:49,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "--------------------------------------------- Result 13 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 11 / 0 / 14:  28%|██▊       | 14/50 [01:04<02:45,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i just feel extremely comfortable with the group of people that i dont even need to hide myself\n",
      "--------------------------------------------- Result 14 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i just feel extremely comfortable with the group of people that i dont even need to hide myself\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 12 / 0 / 15:  30%|███       | 15/50 [01:08<02:39,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i find myself in the odd position of feeling supportive of\n",
      "--------------------------------------------- Result 15 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i find myself in the odd position of feeling supportive of\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 13 / 0 / 16:  32%|███▏      | 16/50 [01:13<02:35,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "--------------------------------------------- Result 16 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 13 / 0 / 17:  34%|███▍      | 17/50 [01:17<02:30,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel a little mellow today\n",
      "\n",
      "i feel а little mellow today\n",
      "--------------------------------------------- Result 17 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel [[a]] little mellow today\n",
      "\n",
      "i feel [[а]] little mellow today\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 14 / 0 / 18:  36%|███▌      | 18/50 [01:29<02:38,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "--------------------------------------------- Result 18 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 15 / 0 / 19:  38%|███▊      | 19/50 [01:33<02:32,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "--------------------------------------------- Result 19 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 15 / 0 / 20:  40%|████      | 20/50 [01:36<02:24,  4.81s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert1/1746360097865.ta.chkpt\" at 2025-05-04 13:01:37 after 20 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like reds and purples are just so rich and kind of perfect\n",
      "\n",
      "i feel like reds and purples are just ѕo rich and kind of perfect\n",
      "--------------------------------------------- Result 20 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like reds and purples are just [[so]] rich and kind of perfect\n",
      "\n",
      "i feel like reds and purples are just [[ѕo]] rich and kind of perfect\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 16 / 0 / 21:  42%|████▏     | 21/50 [01:40<02:18,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "--------------------------------------------- Result 21 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 16 / 0 / 22:  44%|████▍     | 22/50 [01:44<02:13,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like ive gotten to know many of you through comments and emails and for that im appreciative and glad you are a part of this little space\n",
      "\n",
      "i feel like ive gotten to know many of you through comments and emails and for that im appreciative and glad you are a part of this little spaсe\n",
      "--------------------------------------------- Result 22 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like ive gotten to know many of you through comments and emails and for that im appreciative and glad you are a part of this little [[space]]\n",
      "\n",
      "i feel like ive gotten to know many of you through comments and emails and for that im appreciative and glad you are a part of this little [[spaсe]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 16 / 0 / 23:  46%|████▌     | 23/50 [01:53<02:13,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "i survey my own posts over the lаst few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "--------------------------------------------- Result 23 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over the [[last]] few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "i survey my own posts over the [[lаst]] few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 17 / 0 / 24:  48%|████▊     | 24/50 [01:57<02:07,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "--------------------------------------------- Result 24 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 18 / 0 / 25:  50%|█████     | 25/50 [02:02<02:02,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel guilty like i m not going to be able to cook for him\n",
      "--------------------------------------------- Result 25 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel guilty like i m not going to be able to cook for him\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 19 / 0 / 26:  52%|█████▏    | 26/50 [02:06<01:56,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i hate it when i feel fearful for absolutely no reason\n",
      "--------------------------------------------- Result 26 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i hate it when i feel fearful for absolutely no reason\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 20 / 0 / 27:  54%|█████▍    | 27/50 [02:10<01:51,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i am feeling outraged it shows everywhere\n",
      "--------------------------------------------- Result 27 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i am feeling outraged it shows everywhere\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 21 / 0 / 28:  56%|█████▌    | 28/50 [02:14<01:45,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i stole a book from one of my all time favorite authors and now i feel like a rotten person\n",
      "--------------------------------------------- Result 28 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i stole a book from one of my all time favorite authors and now i feel like a rotten person\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 22 / 0 / 29:  58%|█████▊    | 29/50 [02:19<01:40,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i do feel insecure sometimes but who doesnt\n",
      "--------------------------------------------- Result 29 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i do feel insecure sometimes but who doesnt\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 22 / 0 / 30:  60%|██████    | 30/50 [02:24<01:36,  4.81s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert1/1746360145977.ta.chkpt\" at 2025-05-04 13:02:25 after 30 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i highly recommend visiting on a wednesday if youre able because its less crowded so you get to ask the farmers more questions without feeling rude for holding up a line\n",
      "\n",
      "i highly recommend visiting on a wednesday if youre able because its less crowded so you get to ask the farmers morе questions without feeling rude for holding up a line\n",
      "--------------------------------------------- Result 30 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i highly recommend visiting on a wednesday if youre able because its less crowded so you get to ask the farmers [[more]] questions without feeling rude for holding up a line\n",
      "\n",
      "i highly recommend visiting on a wednesday if youre able because its less crowded so you get to ask the farmers [[morе]] questions without feeling rude for holding up a line\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 23 / 0 / 31:  62%|██████▏   | 31/50 [02:28<01:31,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "ive been missing him and feeling so restless at home thinking of him\n",
      "--------------------------------------------- Result 31 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "ive been missing him and feeling so restless at home thinking of him\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 24 / 0 / 32:  64%|██████▍   | 32/50 [02:33<01:26,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i posted on my facebook page earlier this week ive been feeling a little grumpy and out of sorts the past few days\n",
      "--------------------------------------------- Result 32 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i posted on my facebook page earlier this week ive been feeling a little grumpy and out of sorts the past few days\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 24 / 0 / 33:  66%|██████▌   | 33/50 [02:36<01:20,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i start to feel emotional\n",
      "\n",
      "i start to feel emοtional\n",
      "--------------------------------------------- Result 33 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i start to feel [[emotional]]\n",
      "\n",
      "i start to feel [[emοtional]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 25 / 0 / 34:  68%|██████▊   | 34/50 [02:41<01:15,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel so cold a href http irish\n",
      "--------------------------------------------- Result 34 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel so cold a href http irish\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 26 / 0 / 35:  70%|███████   | 35/50 [02:47<01:11,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like i m defective or something for not having baby fever\n",
      "--------------------------------------------- Result 35 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like i m defective or something for not having baby fever\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 26 / 0 / 36:  72%|███████▏  | 36/50 [02:51<01:06,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel more virtuous than when i eat veggies dipped in hummus\n",
      "\n",
      "i feel more virtuous than when i eat vеggies dipped in hummus\n",
      "--------------------------------------------- Result 36 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel more virtuous than when i eat [[veggies]] dipped in hummus\n",
      "\n",
      "i feel more virtuous than when i eat [[vеggies]] dipped in hummus\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 26 / 0 / 37:  74%|███████▍  | 37/50 [02:54<01:01,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and clean living so highly im curious do any of you read magazines concerned with health and clean lifestyles such as the green parent\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and сlean living so highly im curious do any of you read magazines concerned with health and clean lifestyles such as the green parent\n",
      "--------------------------------------------- Result 37 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and [[clean]] living so highly im curious do any of you read magazines concerned with health and clean lifestyles such as the green parent\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and [[сlean]] living so highly im curious do any of you read magazines concerned with health and clean lifestyles such as the green parent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 27 / 0 / 38:  76%|███████▌  | 38/50 [02:59<00:56,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i spent the last two weeks of school feeling miserable\n",
      "--------------------------------------------- Result 38 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i spent the last two weeks of school feeling miserable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 28 / 0 / 39:  78%|███████▊  | 39/50 [03:03<00:51,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling very peaceful about our wedding again now after having\n",
      "--------------------------------------------- Result 39 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling very peaceful about our wedding again now after having\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 29 / 0 / 40:  80%|████████  | 40/50 [03:07<00:46,  4.69s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert1/1746360189425.ta.chkpt\" at 2025-05-04 13:03:09 after 40 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i had been talking to coach claudia barcomb and coach ali boe for a long time and they both made me feel very welcomed at union\n",
      "--------------------------------------------- Result 40 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i had been talking to coach claudia barcomb and coach ali boe for a long time and they both made me feel very welcomed at union\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 30 / 0 / 41:  82%|████████▏ | 41/50 [03:12<00:42,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel if i completely hated things i d exercise my democratic right speak my mind in what ever ways possible and try to enact a change\n",
      "--------------------------------------------- Result 41 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel if i completely hated things i d exercise my democratic right speak my mind in what ever ways possible and try to enact a change\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 31 / 0 / 42:  84%|████████▍ | 42/50 [03:16<00:37,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel humiliated embarrassed or foolish i will remember that others have felt the same way because of the same kinds of things and i will be kind and helpful and accepting\n",
      "--------------------------------------------- Result 42 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel humiliated embarrassed or foolish i will remember that others have felt the same way because of the same kinds of things and i will be kind and helpful and accepting\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 31 / 0 / 43:  86%|████████▌ | 43/50 [03:20<00:32,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel reassured that i am dealing with my diet in the right way and that all is good\n",
      "\n",
      "i feel reassured that і am dealing with my diet in the right way and that all is good\n",
      "--------------------------------------------- Result 43 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel reassured that [[i]] am dealing with my diet in the right way and that all is good\n",
      "\n",
      "i feel reassured that [[і]] am dealing with my diet in the right way and that all is good\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 32 / 0 / 44:  88%|████████▊ | 44/50 [03:25<00:28,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0.]) --> [FAILED]\n",
      "\n",
      "i feel i have to agree with her even though i can imagine some rather unpleasant possible cases\n",
      "--------------------------------------------- Result 44 ---------------------------------------------\n",
      "tensor([0., 0., 0., 0., 1., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel i have to agree with her even though i can imagine some rather unpleasant possible cases\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 32 / 0 / 45:  90%|█████████ | 45/50 [03:30<00:23,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "im in such a happy mood today i feel almost delighted and i havent done anything different today then i normally have it is wonderful\n",
      "\n",
      "im in such a happy moοd today i feel almost delighted and i havent done anything different today then i normally have it is wonderful\n",
      "--------------------------------------------- Result 45 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "im in such a happy [[mood]] today i feel almost delighted and i havent done anything different today then i normally have it is wonderful\n",
      "\n",
      "im in such a happy [[moοd]] today i feel almost delighted and i havent done anything different today then i normally have it is wonderful\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 33 / 0 / 46:  92%|█████████▏| 46/50 [03:34<00:18,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling really out of place and irritated\n",
      "--------------------------------------------- Result 46 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling really out of place and irritated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 34 / 0 / 47:  94%|█████████▍| 47/50 [03:39<00:14,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also know that i feel nothing than a friendly affection to them too\n",
      "--------------------------------------------- Result 47 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also know that i feel nothing than a friendly affection to them too\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 14 / 34 / 0 / 48:  96%|█████████▌| 48/50 [03:44<00:09,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like i had a rather productive weekend and i cant always say that no matter how much i get done\n",
      "\n",
      "i feel like i had a rаther productive weekend and i cant always say that no matter how much i get done\n",
      "--------------------------------------------- Result 48 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like i had a [[rather]] productive weekend and i cant always say that no matter how much i get done\n",
      "\n",
      "i feel like i had a [[rаther]] productive weekend and i cant always say that no matter how much i get done\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 14 / 35 / 0 / 49:  98%|█████████▊| 49/50 [03:48<00:04,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling insecure at the moment\n",
      "--------------------------------------------- Result 49 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling insecure at the moment\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 35 / 0 / 50: 100%|██████████| 50/50 [03:53<00:00,  4.66s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert1/1746360234736.ta.chkpt\" at 2025-05-04 13:03:54 after 50 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling pretty anxious all day but my first day at work was a very good day and that helped a lot\n",
      "\n",
      "i was feeling pretty anxіous all day but my first day at work was a very good day and that helped a lot\n",
      "--------------------------------------------- Result 50 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling pretty [[anxious]] all day but my first day at work was a very good day and that helped a lot\n",
      "\n",
      "i was feeling pretty [[anxіous]] all day but my first day at work was a very good day and that helped a lot\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 35 / 0 / 50: 100%|██████████| 50/50 [03:53<00:00,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 15     |\n",
      "| Number of failed attacks:     | 35     |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 70.0%  |\n",
      "| Attack success rate:          | 30.0%  |\n",
      "| Average perturbed word %:     | 6.75%  |\n",
      "| Average num. words per input: | 18.56  |\n",
      "| Avg num queries:              | 13.8   |\n",
      "+-------------------------------+--------+"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "textattack: No entry found for goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n",
      "textattack: Unknown if model of class <class '__main__.GPT4Wrapper'> compatible with goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mdair-ai/emotion\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
      "textattack: Logging to CSV at path results/emotion/gpt4/pert2/log50.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): DifferentialEvolution(\n",
      "    (popsize):  5\n",
      "    (maxiter):  3\n",
      "    (max_perturbs):  2\n",
      "    (verbose):  False\n",
      "  )\n",
      "  (goal_function):  TargetedBonus\n",
      "  (transformation):  WordSwapHomoglyphSwap\n",
      "  (constraints): None\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   2%|▏         | 1/50 [00:08<06:39,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 0 / 2:   4%|▍         | 2/50 [00:19<07:37,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 0 / 3:   6%|▌         | 3/50 [00:28<07:19,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 3 / 0 / 4:   8%|▊         | 4/50 [00:36<07:05,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my bouquet of red and yellow tulips under my arm feeling slightly more optimistic than when i arrived\n",
      "\n",
      "i left with my bοuquet of red and yellow tulips under my arm feeling slightly more optimistic than when i arrivеd\n",
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my [[bouquet]] of red and yellow tulips under my arm feeling slightly more optimistic than when i [[arrived]]\n",
      "\n",
      "i left with my [[bοuquet]] of red and yellow tulips under my arm feeling slightly more optimistic than when i [[arrivеd]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 3 / 0 / 5:  10%|█         | 5/50 [00:47<07:08,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling a little vain when i did this one\n",
      "\n",
      "i was feeling a littlе vaіn when i did this one\n",
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling a [[little]] [[vain]] when i did this one\n",
      "\n",
      "i was feeling a [[littlе]] [[vaіn]] when i did this one\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 4 / 0 / 6:  12%|█▏        | 6/50 [00:58<07:11,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 5 / 0 / 7:  14%|█▍        | 7/50 [01:07<06:56,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 6 / 0 / 8:  16%|█▌        | 8/50 [01:18<06:54,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 6 / 0 / 9:  18%|█▊        | 9/50 [01:26<06:32,  9.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have the same breathless feeling as a reader eager to see what will happen next\n",
      "\n",
      "i like to have the same breathless feeling as a readеr eagеr to see what will happen next\n",
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have the same breathless feeling as a [[reader]] [[eager]] to see what will happen next\n",
      "\n",
      "i like to have the same breathless feeling as a [[readеr]] [[eagеr]] to see what will happen next\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 7 / 0 / 10:  20%|██        | 10/50 [01:34<06:18,  9.47s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert2/1746360331043.ta.chkpt\" at 2025-05-04 13:05:31 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 8 / 0 / 11:  22%|██▏       | 11/50 [01:42<06:04,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "--------------------------------------------- Result 11 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 9 / 0 / 12:  24%|██▍       | 12/50 [01:54<06:02,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "--------------------------------------------- Result 12 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 10 / 0 / 13:  26%|██▌       | 13/50 [02:03<05:50,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "--------------------------------------------- Result 13 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 11 / 0 / 14:  28%|██▊       | 14/50 [02:13<05:43,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i just feel extremely comfortable with the group of people that i dont even need to hide myself\n",
      "--------------------------------------------- Result 14 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i just feel extremely comfortable with the group of people that i dont even need to hide myself\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 11 / 0 / 15:  30%|███       | 15/50 [02:29<05:49, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i find myself in the odd position of feeling supportive of\n",
      "\n",
      "i find myself in the odd position of feeling supрortive of\n",
      "--------------------------------------------- Result 15 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i find myself in the odd position of feeling [[supportive]] of\n",
      "\n",
      "i find myself in the odd position of feeling [[supрortive]] of\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 12 / 0 / 16:  32%|███▏      | 16/50 [02:39<05:38,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "--------------------------------------------- Result 16 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 12 / 0 / 17:  34%|███▍      | 17/50 [02:51<05:33, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel a little mellow today\n",
      "\n",
      "i fеel a lіttle mellow today\n",
      "--------------------------------------------- Result 17 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i [[feel]] a [[little]] mellow today\n",
      "\n",
      "i [[fеel]] a [[lіttle]] mellow today\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 13 / 0 / 18:  36%|███▌      | 18/50 [03:02<05:23, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "--------------------------------------------- Result 18 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 14 / 0 / 19:  38%|███▊      | 19/50 [03:17<05:22, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "--------------------------------------------- Result 19 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 14 / 0 / 20:  40%|████      | 20/50 [03:29<05:14, 10.47s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert2/1746360445857.ta.chkpt\" at 2025-05-04 13:07:25 after 20 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like reds and purples are just so rich and kind of perfect\n",
      "\n",
      "i feel like reds and purples are just so ricһ anԁ kind of perfect\n",
      "--------------------------------------------- Result 20 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like reds and purples are just so [[rich]] [[and]] kind of perfect\n",
      "\n",
      "i feel like reds and purples are just so [[ricһ]] [[anԁ]] kind of perfect\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 15 / 0 / 21:  42%|████▏     | 21/50 [03:38<05:02, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "--------------------------------------------- Result 21 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 15 / 0 / 22:  44%|████▍     | 22/50 [03:47<04:49, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like ive gotten to know many of you through comments and emails and for that im appreciative and glad you are a part of this little space\n",
      "\n",
      "i feel likе ive gotten to know many of you through comments and emails and for that im appreciative anԁ glad you are a part of this little space\n",
      "--------------------------------------------- Result 22 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel [[like]] ive gotten to know many of you through comments and emails and for that im appreciative [[and]] glad you are a part of this little space\n",
      "\n",
      "i feel [[likе]] ive gotten to know many of you through comments and emails and for that im appreciative [[anԁ]] glad you are a part of this little space\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 15 / 0 / 23:  46%|████▌     | 23/50 [04:05<04:48, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of а few οf them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "--------------------------------------------- Result 23 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of [[a]] few [[of]] them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of [[а]] few [[οf]] them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 16 / 0 / 24:  48%|████▊     | 24/50 [04:14<04:35, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "--------------------------------------------- Result 24 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 17 / 0 / 25:  50%|█████     | 25/50 [04:25<04:25, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel guilty like i m not going to be able to cook for him\n",
      "--------------------------------------------- Result 25 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel guilty like i m not going to be able to cook for him\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 18 / 0 / 26:  52%|█████▏    | 26/50 [04:33<04:12, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0.]) --> [FAILED]\n",
      "\n",
      "i hate it when i feel fearful for absolutely no reason\n",
      "--------------------------------------------- Result 26 ---------------------------------------------\n",
      "tensor([0., 0., 0., 0., 1., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i hate it when i feel fearful for absolutely no reason\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 19 / 0 / 27:  54%|█████▍    | 27/50 [04:42<04:00, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i am feeling outraged it shows everywhere\n",
      "--------------------------------------------- Result 27 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i am feeling outraged it shows everywhere\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 20 / 0 / 28:  56%|█████▌    | 28/50 [04:52<03:49, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i stole a book from one of my all time favorite authors and now i feel like a rotten person\n",
      "--------------------------------------------- Result 28 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i stole a book from one of my all time favorite authors and now i feel like a rotten person\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 21 / 0 / 29:  58%|█████▊    | 29/50 [05:01<03:37, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i do feel insecure sometimes but who doesnt\n",
      "--------------------------------------------- Result 29 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i do feel insecure sometimes but who doesnt\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 21 / 0 / 30:  60%|██████    | 30/50 [05:10<03:26, 10.35s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert2/1746360546809.ta.chkpt\" at 2025-05-04 13:09:06 after 30 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i highly recommend visiting on a wednesday if youre able because its less crowded so you get to ask the farmers more questions without feeling rude for holding up a line\n",
      "\n",
      "i highly recommend visiting on a wednesday if yοure able because its less crowded so you get to ask the farmers mοre questions without feeling rude for holding up a line\n",
      "--------------------------------------------- Result 30 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i highly recommend visiting on a wednesday if [[youre]] able because its less crowded so you get to ask the farmers [[more]] questions without feeling rude for holding up a line\n",
      "\n",
      "i highly recommend visiting on a wednesday if [[yοure]] able because its less crowded so you get to ask the farmers [[mοre]] questions without feeling rude for holding up a line\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 22 / 0 / 31:  62%|██████▏   | 31/50 [05:21<03:16, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "ive been missing him and feeling so restless at home thinking of him\n",
      "--------------------------------------------- Result 31 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "ive been missing him and feeling so restless at home thinking of him\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 23 / 0 / 32:  64%|██████▍   | 32/50 [05:32<03:07, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i posted on my facebook page earlier this week ive been feeling a little grumpy and out of sorts the past few days\n",
      "--------------------------------------------- Result 32 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i posted on my facebook page earlier this week ive been feeling a little grumpy and out of sorts the past few days\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 23 / 0 / 33:  66%|██████▌   | 33/50 [05:44<02:57, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i start to feel emotional\n",
      "\n",
      "і start to feel emotiοnal\n",
      "--------------------------------------------- Result 33 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "[[i]] start to feel [[emotional]]\n",
      "\n",
      "[[і]] start to feel [[emotiοnal]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 24 / 0 / 34:  68%|██████▊   | 34/50 [05:56<02:47, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel so cold a href http irish\n",
      "--------------------------------------------- Result 34 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel so cold a href http irish\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 25 / 0 / 35:  70%|███████   | 35/50 [06:04<02:36, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like i m defective or something for not having baby fever\n",
      "--------------------------------------------- Result 35 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like i m defective or something for not having baby fever\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 25 / 0 / 36:  72%|███████▏  | 36/50 [06:11<02:24, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel more virtuous than when i eat veggies dipped in hummus\n",
      "\n",
      "i feel morе virtuous than whеn i eat veggies dipped in hummus\n",
      "--------------------------------------------- Result 36 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel [[more]] virtuous than [[when]] i eat veggies dipped in hummus\n",
      "\n",
      "i feel [[morе]] virtuous than [[whеn]] i eat veggies dipped in hummus\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 25 / 0 / 37:  74%|███████▍  | 37/50 [06:21<02:13, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and clean living so highly im curious do any of you read magazines concerned with health and clean lifestyles such as the green parent\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and clean living so highly im curious do any of you read mаgazines concerned with health and clеan lifestyles such as the green parent\n",
      "--------------------------------------------- Result 37 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and clean living so highly im curious do any of you read [[magazines]] concerned with health and [[clean]] lifestyles such as the green parent\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and clean living so highly im curious do any of you read [[mаgazines]] concerned with health and [[clеan]] lifestyles such as the green parent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 26 / 0 / 38:  76%|███████▌  | 38/50 [06:29<02:03, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i spent the last two weeks of school feeling miserable\n",
      "--------------------------------------------- Result 38 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i spent the last two weeks of school feeling miserable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 27 / 0 / 39:  78%|███████▊  | 39/50 [06:37<01:52, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling very peaceful about our wedding again now after having\n",
      "--------------------------------------------- Result 39 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling very peaceful about our wedding again now after having\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 27 / 0 / 40:  80%|████████  | 40/50 [06:54<01:43, 10.36s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert2/1746360650938.ta.chkpt\" at 2025-05-04 13:10:50 after 40 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i had been talking to coach claudia barcomb and coach ali boe for a long time and they both made me feel very welcomed at union\n",
      "\n",
      "i had been talking to coacһ claudia barcomb and coach ali boe for a long time and they both made me fеel very welcomed at union\n",
      "--------------------------------------------- Result 40 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i had been talking to [[coach]] claudia barcomb and coach ali boe for a long time and they both made me [[feel]] very welcomed at union\n",
      "\n",
      "i had been talking to [[coacһ]] claudia barcomb and coach ali boe for a long time and they both made me [[fеel]] very welcomed at union\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 28 / 0 / 41:  82%|████████▏ | 41/50 [07:04<01:33, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel if i completely hated things i d exercise my democratic right speak my mind in what ever ways possible and try to enact a change\n",
      "--------------------------------------------- Result 41 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel if i completely hated things i d exercise my democratic right speak my mind in what ever ways possible and try to enact a change\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 29 / 0 / 42:  84%|████████▍ | 42/50 [07:14<01:22, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel humiliated embarrassed or foolish i will remember that others have felt the same way because of the same kinds of things and i will be kind and helpful and accepting\n",
      "--------------------------------------------- Result 42 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel humiliated embarrassed or foolish i will remember that others have felt the same way because of the same kinds of things and i will be kind and helpful and accepting\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 14 / 29 / 0 / 43:  86%|████████▌ | 43/50 [07:28<01:12, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel reassured that i am dealing with my diet in the right way and that all is good\n",
      "\n",
      "i feel reassured that i am dealing with my dіet in the right way and that all іs good\n",
      "--------------------------------------------- Result 43 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel reassured that i am dealing with my [[diet]] in the right way and that all [[is]] good\n",
      "\n",
      "i feel reassured that i am dealing with my [[dіet]] in the right way and that all [[іs]] good\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 14 / 30 / 0 / 44:  88%|████████▊ | 44/50 [07:40<01:02, 10.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0.]) --> [FAILED]\n",
      "\n",
      "i feel i have to agree with her even though i can imagine some rather unpleasant possible cases\n",
      "--------------------------------------------- Result 44 ---------------------------------------------\n",
      "tensor([0., 0., 0., 0., 1., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel i have to agree with her even though i can imagine some rather unpleasant possible cases\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 30 / 0 / 45:  90%|█████████ | 45/50 [07:48<00:52, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "im in such a happy mood today i feel almost delighted and i havent done anything different today then i normally have it is wonderful\n",
      "\n",
      "im in such a happy mood tοday i feel almost dеlighted and i havent done anything different today then i normally have it is wonderful\n",
      "--------------------------------------------- Result 45 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "im in such a happy mood [[today]] i feel almost [[delighted]] and i havent done anything different today then i normally have it is wonderful\n",
      "\n",
      "im in such a happy mood [[tοday]] i feel almost [[dеlighted]] and i havent done anything different today then i normally have it is wonderful\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 31 / 0 / 46:  92%|█████████▏| 46/50 [07:57<00:41, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling really out of place and irritated\n",
      "--------------------------------------------- Result 46 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling really out of place and irritated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 32 / 0 / 47:  94%|█████████▍| 47/50 [08:06<00:31, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also know that i feel nothing than a friendly affection to them too\n",
      "--------------------------------------------- Result 47 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also know that i feel nothing than a friendly affection to them too\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 16 / 32 / 0 / 48:  96%|█████████▌| 48/50 [08:14<00:20, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like i had a rather productive weekend and i cant always say that no matter how much i get done\n",
      "\n",
      "i feel like i had a rather prοductive weekend and i cant аlways say that no matter how much i get done\n",
      "--------------------------------------------- Result 48 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like i had a rather [[productive]] weekend and i cant [[always]] say that no matter how much i get done\n",
      "\n",
      "i feel like i had a rather [[prοductive]] weekend and i cant [[аlways]] say that no matter how much i get done\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 16 / 33 / 0 / 49:  98%|█████████▊| 49/50 [08:26<00:10, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling insecure at the moment\n",
      "--------------------------------------------- Result 49 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling insecure at the moment\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 17 / 33 / 0 / 50: 100%|██████████| 50/50 [08:34<00:00, 10.29s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert2/1746360750975.ta.chkpt\" at 2025-05-04 13:12:30 after 50 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling pretty anxious all day but my first day at work was a very good day and that helped a lot\n",
      "\n",
      "i was feeling pretty anхious all day but my first day at work wаs a very good day and that helped a lot\n",
      "--------------------------------------------- Result 50 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling pretty [[anxious]] all day but my first day at work [[was]] a very good day and that helped a lot\n",
      "\n",
      "i was feeling pretty [[anхious]] all day but my first day at work [[wаs]] a very good day and that helped a lot\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 17 / 33 / 0 / 50: 100%|██████████| 50/50 [08:34<00:00, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 17     |\n",
      "| Number of failed attacks:     | 33     |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 66.0%  |\n",
      "| Attack success rate:          | 34.0%  |\n",
      "| Average perturbed word %:     | 12.9%  |\n",
      "| Average num. words per input: | 18.56  |\n",
      "| Avg num queries:              | 26.2   |\n",
      "+-------------------------------+--------+"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "textattack: No entry found for goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n",
      "textattack: Unknown if model of class <class '__main__.GPT4Wrapper'> compatible with goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mdair-ai/emotion\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
      "textattack: Logging to CSV at path results/emotion/gpt4/pert3/log50.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): DifferentialEvolution(\n",
      "    (popsize):  5\n",
      "    (maxiter):  3\n",
      "    (max_perturbs):  3\n",
      "    (verbose):  False\n",
      "  )\n",
      "  (goal_function):  TargetedBonus\n",
      "  (transformation):  WordSwapHomoglyphSwap\n",
      "  (constraints): None\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   2%|▏         | 1/50 [00:15<12:43, 15.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 0 / 2:   4%|▍         | 2/50 [00:30<12:10, 15.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 0 / 3:   6%|▌         | 3/50 [00:44<11:33, 14.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 3 / 0 / 4:   8%|▊         | 4/50 [01:02<11:53, 15.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my bouquet of red and yellow tulips under my arm feeling slightly more optimistic than when i arrived\n",
      "\n",
      "i left with my bouquet of red and yellow tulips under my arm feeling slightly more οрtіmistic than when i arrived\n",
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my bouquet of red and yellow tulips under my arm feeling slightly more [[optimistic]] than when i arrived\n",
      "\n",
      "i left with my bouquet of red and yellow tulips under my arm feeling slightly more [[οрtіmistic]] than when i arrived\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 3 / 0 / 5:  10%|█         | 5/50 [01:28<13:16, 17.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling a little vain when i did this one\n",
      "\n",
      "i was feelіng a little vain when і did this one\n",
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was [[feeling]] a little vain when [[i]] did this one\n",
      "\n",
      "i was [[feelіng]] a little vain when [[і]] did this one\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 4 / 0 / 6:  12%|█▏        | 6/50 [01:41<12:26, 16.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 5 / 0 / 7:  14%|█▍        | 7/50 [01:55<11:52, 16.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "\n",
      "\n",
      "Could not parse result: The emotion conveyed in the sentence is sadness (0).\n",
      "Could not parse result: The sentence expresses a sense of confusion and reflection on a relationship that may not have been fulfilling, which can be associated with sadness. Therefore, the emotion is: \n",
      "\n",
      "0\n",
      "Could not parse result: The emotion expressed in the sentence is sadness (0).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 6 / 0 / 8:  16%|█▌        | 8/50 [02:23<12:33, 17.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 6 / 0 / 9:  18%|█▊        | 9/50 [02:38<12:02, 17.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have the same breathless feeling as a reader eager to see what will happen next\n",
      "\n",
      "i like to have thе same breatһlеss feeling as a reader eager to see what will happen next\n",
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have [[the]] same [[breathless]] feeling as a reader eager to see what will happen next\n",
      "\n",
      "i like to have [[thе]] same [[breatһlеss]] feeling as a reader eager to see what will happen next\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 7 / 0 / 10:  20%|██        | 10/50 [02:53<11:33, 17.34s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert3/1746360926669.ta.chkpt\" at 2025-05-04 13:15:26 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 8 / 0 / 11:  22%|██▏       | 11/50 [03:09<11:12, 17.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "--------------------------------------------- Result 11 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 9 / 0 / 12:  24%|██▍       | 12/50 [03:23<10:44, 16.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "--------------------------------------------- Result 12 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 10 / 0 / 13:  26%|██▌       | 13/50 [03:40<10:26, 16.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "--------------------------------------------- Result 13 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 10 / 0 / 14:  28%|██▊       | 14/50 [04:08<10:38, 17.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i just feel extremely comfortable with the group of people that i dont even need to hide myself\n",
      "\n",
      "i ϳust feel extremely comfortable with the group of people tһat i dont even neеd to hide myself\n",
      "--------------------------------------------- Result 14 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i [[just]] feel extremely comfortable with the group of people [[that]] i dont even [[need]] to hide myself\n",
      "\n",
      "i [[ϳust]] feel extremely comfortable with the group of people [[tһat]] i dont even [[neеd]] to hide myself\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 11 / 0 / 15:  30%|███       | 15/50 [04:20<10:08, 17.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i find myself in the odd position of feeling supportive of\n",
      "--------------------------------------------- Result 15 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i find myself in the odd position of feeling supportive of\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 12 / 0 / 16:  32%|███▏      | 16/50 [04:34<09:44, 17.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "--------------------------------------------- Result 16 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 12 / 0 / 17:  34%|███▍      | 17/50 [04:58<09:39, 17.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel a little mellow today\n",
      "\n",
      "i feel a little mеllοw todаy\n",
      "--------------------------------------------- Result 17 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel a little [[mellow]] [[today]]\n",
      "\n",
      "i feel a little [[mеllοw]] [[todаy]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 13 / 0 / 18:  36%|███▌      | 18/50 [05:10<09:12, 17.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "--------------------------------------------- Result 18 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 14 / 0 / 19:  38%|███▊      | 19/50 [05:24<08:50, 17.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "--------------------------------------------- Result 19 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 14 / 0 / 20:  40%|████      | 20/50 [05:37<08:26, 16.87s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert3/1746361090771.ta.chkpt\" at 2025-05-04 13:18:10 after 20 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like reds and purples are just so rich and kind of perfect\n",
      "\n",
      "i feel like rеds and purples are just so rich and kind of рerfect\n",
      "--------------------------------------------- Result 20 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like [[reds]] and purples are just so rich and kind of [[perfect]]\n",
      "\n",
      "i feel like [[rеds]] and purples are just so rich and kind of [[рerfect]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 15 / 0 / 21:  42%|████▏     | 21/50 [05:52<08:07, 16.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "--------------------------------------------- Result 21 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 15 / 0 / 22:  44%|████▍     | 22/50 [06:08<07:48, 16.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like ive gotten to know many of you through comments and emails and for that im appreciative and glad you are a part of this little space\n",
      "\n",
      "i feel like ive gotten to know many of you thrοugh commentѕ and emails and for that im appreciative and glad you are а part of this little space\n",
      "--------------------------------------------- Result 22 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like ive gotten to know many of you [[through]] [[comments]] and emails and for that im appreciative and glad you are [[a]] part of this little space\n",
      "\n",
      "i feel like ive gotten to know many of you [[thrοugh]] [[commentѕ]] and emails and for that im appreciative and glad you are [[а]] part of this little space\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 15 / 0 / 23:  46%|████▌     | 23/50 [06:33<07:42, 17.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "i survey my own posts over tһe laѕt few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture wһat its like to be me or someone like me in dublin in the st century\n",
      "--------------------------------------------- Result 23 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over [[the]] [[last]] few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture [[what]] its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "i survey my own posts over [[tһe]] [[laѕt]] few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture [[wһat]] its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 16 / 0 / 24:  48%|████▊     | 24/50 [06:46<07:20, 16.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "--------------------------------------------- Result 24 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 17 / 0 / 25:  50%|█████     | 25/50 [07:02<07:02, 16.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel guilty like i m not going to be able to cook for him\n",
      "--------------------------------------------- Result 25 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel guilty like i m not going to be able to cook for him\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 18 / 0 / 26:  52%|█████▏    | 26/50 [07:19<06:45, 16.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0.]) --> [FAILED]\n",
      "\n",
      "i hate it when i feel fearful for absolutely no reason\n",
      "--------------------------------------------- Result 26 ---------------------------------------------\n",
      "tensor([0., 0., 0., 0., 1., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i hate it when i feel fearful for absolutely no reason\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 19 / 0 / 27:  54%|█████▍    | 27/50 [07:34<06:27, 16.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i am feeling outraged it shows everywhere\n",
      "--------------------------------------------- Result 27 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i am feeling outraged it shows everywhere\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 20 / 0 / 28:  56%|█████▌    | 28/50 [07:49<06:08, 16.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i stole a book from one of my all time favorite authors and now i feel like a rotten person\n",
      "--------------------------------------------- Result 28 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i stole a book from one of my all time favorite authors and now i feel like a rotten person\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 21 / 0 / 29:  58%|█████▊    | 29/50 [08:02<05:49, 16.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i do feel insecure sometimes but who doesnt\n",
      "--------------------------------------------- Result 29 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i do feel insecure sometimes but who doesnt\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 21 / 0 / 30:  60%|██████    | 30/50 [08:16<05:31, 16.55s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert3/1746361249926.ta.chkpt\" at 2025-05-04 13:20:49 after 30 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i highly recommend visiting on a wednesday if youre able because its less crowded so you get to ask the farmers more questions without feeling rude for holding up a line\n",
      "\n",
      "i highly recommend visiting on а weԁnesday if youre able because its less crowded so you get to ask the farmers more questions without feeling rude for holdіng up a line\n",
      "--------------------------------------------- Result 30 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i highly recommend visiting on [[a]] [[wednesday]] if youre able because its less crowded so you get to ask the farmers more questions without feeling rude for [[holding]] up a line\n",
      "\n",
      "i highly recommend visiting on [[а]] [[weԁnesday]] if youre able because its less crowded so you get to ask the farmers more questions without feeling rude for [[holdіng]] up a line\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 22 / 0 / 31:  62%|██████▏   | 31/50 [08:33<05:14, 16.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "ive been missing him and feeling so restless at home thinking of him\n",
      "--------------------------------------------- Result 31 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "ive been missing him and feeling so restless at home thinking of him\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 23 / 0 / 32:  64%|██████▍   | 32/50 [08:47<04:56, 16.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i posted on my facebook page earlier this week ive been feeling a little grumpy and out of sorts the past few days\n",
      "--------------------------------------------- Result 32 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i posted on my facebook page earlier this week ive been feeling a little grumpy and out of sorts the past few days\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 23 / 0 / 33:  66%|██████▌   | 33/50 [09:11<04:44, 16.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i start to feel emotional\n",
      "\n",
      "і start to feel emotionаl\n",
      "--------------------------------------------- Result 33 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "[[i]] start to feel [[emotional]]\n",
      "\n",
      "[[і]] start to feel [[emotionаl]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 24 / 0 / 34:  68%|██████▊   | 34/50 [09:28<04:27, 16.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel so cold a href http irish\n",
      "--------------------------------------------- Result 34 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel so cold a href http irish\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 25 / 0 / 35:  70%|███████   | 35/50 [09:40<04:08, 16.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like i m defective or something for not having baby fever\n",
      "--------------------------------------------- Result 35 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like i m defective or something for not having baby fever\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 25 / 0 / 36:  72%|███████▏  | 36/50 [09:55<03:51, 16.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel more virtuous than when i eat veggies dipped in hummus\n",
      "\n",
      "i fеel more virtuous than when i eаt veggies dipped іn hummus\n",
      "--------------------------------------------- Result 36 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i [[feel]] more virtuous than when i [[eat]] veggies dipped [[in]] hummus\n",
      "\n",
      "i [[fеel]] more virtuous than when i [[eаt]] veggies dipped [[іn]] hummus\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 25 / 0 / 37:  74%|███████▍  | 37/50 [10:11<03:34, 16.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and clean living so highly im curious do any of you read magazines concerned with health and clean lifestyles such as the green parent\n",
      "\n",
      "i feel very honoured to be included in a mаgzine whicһ prioritises health and clean living so highly im curious do any of you read magazines cοncerned with health and clean lifestyles such as the green parent\n",
      "--------------------------------------------- Result 37 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel very honoured to be included in a [[magzine]] [[which]] prioritises health and clean living so highly im curious do any of you read magazines [[concerned]] with health and clean lifestyles such as the green parent\n",
      "\n",
      "i feel very honoured to be included in a [[mаgzine]] [[whicһ]] prioritises health and clean living so highly im curious do any of you read magazines [[cοncerned]] with health and clean lifestyles such as the green parent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 26 / 0 / 38:  76%|███████▌  | 38/50 [10:25<03:17, 16.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i spent the last two weeks of school feeling miserable\n",
      "--------------------------------------------- Result 38 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i spent the last two weeks of school feeling miserable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 27 / 0 / 39:  78%|███████▊  | 39/50 [10:39<03:00, 16.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling very peaceful about our wedding again now after having\n",
      "--------------------------------------------- Result 39 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling very peaceful about our wedding again now after having\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 27 / 0 / 40:  80%|████████  | 40/50 [11:08<02:47, 16.72s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert3/1746361421893.ta.chkpt\" at 2025-05-04 13:23:41 after 40 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i had been talking to coach claudia barcomb and coach ali boe for a long time and they both made me feel very welcomed at union\n",
      "\n",
      "i had been talking to coach сlaudia barcomb аnd coach ali boe for a long time and they both made me feel very welcomеd at union\n",
      "--------------------------------------------- Result 40 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i had been talking to coach [[claudia]] barcomb [[and]] coach ali boe for a long time and they both made me feel very [[welcomed]] at union\n",
      "\n",
      "i had been talking to coach [[сlaudia]] barcomb [[аnd]] coach ali boe for a long time and they both made me feel very [[welcomеd]] at union\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 28 / 0 / 41:  82%|████████▏ | 41/50 [11:23<02:29, 16.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel if i completely hated things i d exercise my democratic right speak my mind in what ever ways possible and try to enact a change\n",
      "--------------------------------------------- Result 41 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel if i completely hated things i d exercise my democratic right speak my mind in what ever ways possible and try to enact a change\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 29 / 0 / 42:  84%|████████▍ | 42/50 [11:37<02:12, 16.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel humiliated embarrassed or foolish i will remember that others have felt the same way because of the same kinds of things and i will be kind and helpful and accepting\n",
      "--------------------------------------------- Result 42 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel humiliated embarrassed or foolish i will remember that others have felt the same way because of the same kinds of things and i will be kind and helpful and accepting\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 14 / 29 / 0 / 43:  86%|████████▌ | 43/50 [11:52<01:56, 16.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel reassured that i am dealing with my diet in the right way and that all is good\n",
      "\n",
      "i feel reаssured that i am dealing wіth my diet in the rіght way and that all is good\n",
      "--------------------------------------------- Result 43 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel [[reassured]] that i am dealing [[with]] my diet in the [[right]] way and that all is good\n",
      "\n",
      "i feel [[reаssured]] that i am dealing [[wіth]] my diet in the [[rіght]] way and that all is good\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 14 / 30 / 0 / 44:  88%|████████▊ | 44/50 [12:06<01:39, 16.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0.]) --> [FAILED]\n",
      "\n",
      "i feel i have to agree with her even though i can imagine some rather unpleasant possible cases\n",
      "--------------------------------------------- Result 44 ---------------------------------------------\n",
      "tensor([0., 0., 0., 0., 1., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel i have to agree with her even though i can imagine some rather unpleasant possible cases\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 30 / 0 / 45:  90%|█████████ | 45/50 [12:20<01:22, 16.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "im in such a happy mood today i feel almost delighted and i havent done anything different today then i normally have it is wonderful\n",
      "\n",
      "im in suсh a happy mood tοday i feel almost delighted and i havent done anything different today then i normally have it іs wonderful\n",
      "--------------------------------------------- Result 45 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "im in [[such]] a happy mood [[today]] i feel almost delighted and i havent done anything different today then i normally have it [[is]] wonderful\n",
      "\n",
      "im in [[suсh]] a happy mood [[tοday]] i feel almost delighted and i havent done anything different today then i normally have it [[іs]] wonderful\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 31 / 0 / 46:  92%|█████████▏| 46/50 [12:37<01:05, 16.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling really out of place and irritated\n",
      "--------------------------------------------- Result 46 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling really out of place and irritated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 32 / 0 / 47:  94%|█████████▍| 47/50 [12:51<00:49, 16.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also know that i feel nothing than a friendly affection to them too\n",
      "--------------------------------------------- Result 47 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also know that i feel nothing than a friendly affection to them too\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 16 / 32 / 0 / 48:  96%|█████████▌| 48/50 [13:09<00:32, 16.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like i had a rather productive weekend and i cant always say that no matter how much i get done\n",
      "\n",
      "i feel like i had a ratһer productive weekend and i cant always say tһat no matter how much i gеt done\n",
      "--------------------------------------------- Result 48 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like i had a [[rather]] productive weekend and i cant always say [[that]] no matter how much i [[get]] done\n",
      "\n",
      "i feel like i had a [[ratһer]] productive weekend and i cant always say [[tһat]] no matter how much i [[gеt]] done\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 16 / 33 / 0 / 49:  98%|█████████▊| 49/50 [13:35<00:16, 16.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling insecure at the moment\n",
      "--------------------------------------------- Result 49 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling insecure at the moment\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 17 / 33 / 0 / 50: 100%|██████████| 50/50 [13:48<00:00, 16.58s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert3/1746361582125.ta.chkpt\" at 2025-05-04 13:26:22 after 50 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling pretty anxious all day but my first day at work was a very good day and that helped a lot\n",
      "\n",
      "i was feeling pretty anxious all dаy but my first day at work was a vеrу good day and that helped a lot\n",
      "--------------------------------------------- Result 50 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling pretty anxious all [[day]] but my first day at work was a [[very]] good day and that helped a lot\n",
      "\n",
      "i was feeling pretty anxious all [[dаy]] but my first day at work was a [[vеrу]] good day and that helped a lot\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 17 / 33 / 0 / 50: 100%|██████████| 50/50 [13:48<00:00, 16.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 17     |\n",
      "| Number of failed attacks:     | 33     |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 66.0%  |\n",
      "| Attack success rate:          | 34.0%  |\n",
      "| Average perturbed word %:     | 15.27% |\n",
      "| Average num. words per input: | 18.56  |\n",
      "| Avg num queries:              | 39.2   |\n",
      "+-------------------------------+--------+"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "textattack: No entry found for goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n",
      "textattack: Unknown if model of class <class '__main__.GPT4Wrapper'> compatible with goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mdair-ai/emotion\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
      "textattack: Logging to CSV at path results/emotion/gpt4/pert4/log50.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): DifferentialEvolution(\n",
      "    (popsize):  5\n",
      "    (maxiter):  3\n",
      "    (max_perturbs):  4\n",
      "    (verbose):  False\n",
      "  )\n",
      "  (goal_function):  TargetedBonus\n",
      "  (transformation):  WordSwapHomoglyphSwap\n",
      "  (constraints): None\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   2%|▏         | 1/50 [00:18<14:48, 18.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 0 / 2:   4%|▍         | 2/50 [00:36<14:30, 18.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 0 / 3:   6%|▌         | 3/50 [00:58<15:09, 19.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 3 / 0 / 4:   8%|▊         | 4/50 [01:18<15:00, 19.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my bouquet of red and yellow tulips under my arm feeling slightly more optimistic than when i arrived\n",
      "\n",
      "i left with my bouquet of red and yellοw tulips under my arm fеeling slightly morе oрtimistic than when i arrived\n",
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my bouquet of red and [[yellow]] tulips under my arm [[feeling]] slightly [[more]] [[optimistic]] than when i arrived\n",
      "\n",
      "i left with my bouquet of red and [[yellοw]] tulips under my arm [[fеeling]] slightly [[morе]] [[oрtimistic]] than when i arrived\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 3 / 0 / 5:  10%|█         | 5/50 [01:55<17:16, 23.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling a little vain when i did this one\n",
      "\n",
      "і was feeling a little vain when і diԁ this one\n",
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "[[i]] was feeling a little vain when [[i]] [[did]] this one\n",
      "\n",
      "[[і]] was feeling a little vain when [[і]] [[diԁ]] this one\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 4 / 0 / 6:  12%|█▏        | 6/50 [02:12<16:14, 22.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 5 / 0 / 7:  14%|█▍        | 7/50 [02:33<15:41, 21.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "\n",
      "\n",
      "Could not parse result: The emotion expressed in the sentence is sadness (0).\n",
      "Could not parse result: The emotion expressed in the sentence is sadness (0).\n",
      "Could not parse result: The sentence expresses a sense of reflection on a relationship that seems to be tied to feelings of disappointment or confusion, particularly in contrast to a positive event like being accepted into a master's program. This suggests an underlying sadness about the relationship. Therefore, the emotion\n",
      "Could not parse result: The emotion expressed in the sentence is sadness (0).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 6 / 0 / 8:  16%|█▌        | 8/50 [03:14<17:01, 24.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 6 / 0 / 9:  18%|█▊        | 9/50 [03:37<16:28, 24.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have the same breathless feeling as a reader eager to see what will happen next\n",
      "\n",
      "i like to havе the ѕamе breathless feeling as a reaԁer eager to see what will happen next\n",
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to [[have]] the [[same]] breathless feeling as a [[reader]] eager to see what will happen next\n",
      "\n",
      "i like to [[havе]] the [[ѕamе]] breathless feeling as a [[reaԁer]] eager to see what will happen next\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 7 / 0 / 10:  20%|██        | 10/50 [03:56<15:45, 23.64s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert4/1746361820403.ta.chkpt\" at 2025-05-04 13:30:20 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 8 / 0 / 11:  22%|██▏       | 11/50 [04:16<15:08, 23.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "--------------------------------------------- Result 11 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 9 / 0 / 12:  24%|██▍       | 12/50 [04:34<14:30, 22.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "--------------------------------------------- Result 12 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 10 / 0 / 13:  26%|██▌       | 13/50 [04:52<13:53, 22.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "--------------------------------------------- Result 13 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 10 / 0 / 14:  28%|██▊       | 14/50 [05:30<14:10, 23.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i just feel extremely comfortable with the group of people that i dont even need to hide myself\n",
      "\n",
      "i just feel extremely comfortable with tһe group of peoрle that i dont even nеed to hide mуself\n",
      "--------------------------------------------- Result 14 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i just feel extremely comfortable with [[the]] group of [[people]] that i dont even [[need]] to hide [[myself]]\n",
      "\n",
      "i just feel extremely comfortable with [[tһe]] group of [[peoрle]] that i dont even [[nеed]] to hide [[mуself]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 10 / 0 / 15:  30%|███       | 15/50 [06:07<14:17, 24.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i find myself in the odd position of feeling supportive of\n",
      "\n",
      "i find myself in the odd posіtion of feeling supрοrtivе of\n",
      "--------------------------------------------- Result 15 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i find myself in the odd [[position]] of feeling [[supportive]] of\n",
      "\n",
      "i find myself in the odd [[posіtion]] of feeling [[supрοrtivе]] of\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 11 / 0 / 16:  32%|███▏      | 16/50 [06:25<13:39, 24.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "--------------------------------------------- Result 16 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 11 / 0 / 17:  34%|███▍      | 17/50 [07:07<13:49, 25.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel a little mellow today\n",
      "\n",
      "i feel a little mеllοw todаy\n",
      "--------------------------------------------- Result 17 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel a little [[mellow]] [[today]]\n",
      "\n",
      "i feel a little [[mеllοw]] [[todаy]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 12 / 0 / 18:  36%|███▌      | 18/50 [07:27<13:15, 24.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "--------------------------------------------- Result 18 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 13 / 0 / 19:  38%|███▊      | 19/50 [07:47<12:42, 24.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "--------------------------------------------- Result 19 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 13 / 0 / 20:  40%|████      | 20/50 [08:06<12:09, 24.33s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert4/1746362070601.ta.chkpt\" at 2025-05-04 13:34:30 after 20 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like reds and purples are just so rich and kind of perfect\n",
      "\n",
      "i feel like rеdѕ and purples are just so rich аnd kind οf perfect\n",
      "--------------------------------------------- Result 20 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like [[reds]] and purples are just so rich [[and]] kind [[of]] perfect\n",
      "\n",
      "i feel like [[rеdѕ]] and purples are just so rich [[аnd]] kind [[οf]] perfect\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 14 / 0 / 21:  42%|████▏     | 21/50 [08:26<11:38, 24.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "--------------------------------------------- Result 21 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 14 / 0 / 22:  44%|████▍     | 22/50 [08:44<11:07, 23.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like ive gotten to know many of you through comments and emails and for that im appreciative and glad you are a part of this little space\n",
      "\n",
      "і feel like ive gotten to know many of you tһrough comments and emails and for that im appreciatіve and glaԁ you are a part of this little space\n",
      "--------------------------------------------- Result 22 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "[[i]] feel like ive gotten to know many of you [[through]] comments and emails and for that im [[appreciative]] and [[glad]] you are a part of this little space\n",
      "\n",
      "[[і]] feel like ive gotten to know many of you [[tһrough]] comments and emails and for that im [[appreciatіve]] and [[glaԁ]] you are a part of this little space\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 14 / 0 / 23:  46%|████▌     | 23/50 [09:22<11:00, 24.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of a few of thеm only feel that little bits of them capture whаt its like to be me or someοne like me in dublin in the st сentury\n",
      "--------------------------------------------- Result 23 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of a few of [[them]] only feel that little bits of them capture [[what]] its like to be me or [[someone]] like me in dublin in the st [[century]]\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of a few of [[thеm]] only feel that little bits of them capture [[whаt]] its like to be me or [[someοne]] like me in dublin in the st [[сentury]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 15 / 0 / 24:  48%|████▊     | 24/50 [09:44<10:33, 24.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "--------------------------------------------- Result 24 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 16 / 0 / 25:  50%|█████     | 25/50 [10:06<10:06, 24.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel guilty like i m not going to be able to cook for him\n",
      "--------------------------------------------- Result 25 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel guilty like i m not going to be able to cook for him\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 17 / 0 / 26:  52%|█████▏    | 26/50 [10:27<09:38, 24.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0.]) --> [FAILED]\n",
      "\n",
      "i hate it when i feel fearful for absolutely no reason\n",
      "--------------------------------------------- Result 26 ---------------------------------------------\n",
      "tensor([0., 0., 0., 0., 1., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i hate it when i feel fearful for absolutely no reason\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 18 / 0 / 27:  54%|█████▍    | 27/50 [10:48<09:12, 24.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i am feeling outraged it shows everywhere\n",
      "--------------------------------------------- Result 27 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i am feeling outraged it shows everywhere\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 19 / 0 / 28:  56%|█████▌    | 28/50 [11:09<08:45, 23.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i stole a book from one of my all time favorite authors and now i feel like a rotten person\n",
      "--------------------------------------------- Result 28 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i stole a book from one of my all time favorite authors and now i feel like a rotten person\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 20 / 0 / 29:  58%|█████▊    | 29/50 [11:30<08:19, 23.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i do feel insecure sometimes but who doesnt\n",
      "--------------------------------------------- Result 29 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i do feel insecure sometimes but who doesnt\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 20 / 0 / 30:  60%|██████    | 30/50 [11:53<07:55, 23.78s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert4/1746362297277.ta.chkpt\" at 2025-05-04 13:38:17 after 30 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i highly recommend visiting on a wednesday if youre able because its less crowded so you get to ask the farmers more questions without feeling rude for holding up a line\n",
      "\n",
      "i highly reсommend visitіng on a wedneѕday if yοure able because its less crowded so you get to ask the farmers more questions without feeling rude for holding up a line\n",
      "--------------------------------------------- Result 30 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i highly [[recommend]] [[visiting]] on a [[wednesday]] if [[youre]] able because its less crowded so you get to ask the farmers more questions without feeling rude for holding up a line\n",
      "\n",
      "i highly [[reсommend]] [[visitіng]] on a [[wedneѕday]] if [[yοure]] able because its less crowded so you get to ask the farmers more questions without feeling rude for holding up a line\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 21 / 0 / 31:  62%|██████▏   | 31/50 [12:13<07:29, 23.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "ive been missing him and feeling so restless at home thinking of him\n",
      "--------------------------------------------- Result 31 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "ive been missing him and feeling so restless at home thinking of him\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 22 / 0 / 32:  64%|██████▍   | 32/50 [12:41<07:08, 23.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i posted on my facebook page earlier this week ive been feeling a little grumpy and out of sorts the past few days\n",
      "--------------------------------------------- Result 32 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i posted on my facebook page earlier this week ive been feeling a little grumpy and out of sorts the past few days\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 23 / 0 / 33:  66%|██████▌   | 33/50 [13:00<06:41, 23.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i start to feel emotional\n",
      "--------------------------------------------- Result 33 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i start to feel emotional\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 24 / 0 / 34:  68%|██████▊   | 34/50 [13:21<06:17, 23.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel so cold a href http irish\n",
      "--------------------------------------------- Result 34 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel so cold a href http irish\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 10 / 25 / 0 / 35:  70%|███████   | 35/50 [13:39<05:51, 23.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like i m defective or something for not having baby fever\n",
      "--------------------------------------------- Result 35 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like i m defective or something for not having baby fever\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 25 / 0 / 36:  72%|███████▏  | 36/50 [13:58<05:26, 23.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel more virtuous than when i eat veggies dipped in hummus\n",
      "\n",
      "i feel more virtuοus thаn when i eat veggieѕ dippеd in hummus\n",
      "--------------------------------------------- Result 36 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel more [[virtuous]] [[than]] when i eat [[veggies]] [[dipped]] in hummus\n",
      "\n",
      "i feel more [[virtuοus]] [[thаn]] when i eat [[veggieѕ]] [[dippеd]] in hummus\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 25 / 0 / 37:  74%|███████▍  | 37/50 [14:19<05:02, 23.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel very honoured to be included in a magzine which prioritises health and clean living so highly im curious do any of you read magazines concerned with health and clean lifestyles such as the green parent\n",
      "\n",
      "i feel very honoured to be included in a magzine which рrioritises health and clean lіving so һighly im curious do any of you read magazines concerned with һealth and clean lifestyles such as the green parent\n",
      "--------------------------------------------- Result 37 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel very honoured to be included in a magzine which [[prioritises]] health and clean [[living]] so [[highly]] im curious do any of you read magazines concerned with [[health]] and clean lifestyles such as the green parent\n",
      "\n",
      "i feel very honoured to be included in a magzine which [[рrioritises]] health and clean [[lіving]] so [[һighly]] im curious do any of you read magazines concerned with [[һealth]] and clean lifestyles such as the green parent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 26 / 0 / 38:  76%|███████▌  | 38/50 [14:37<04:37, 23.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i spent the last two weeks of school feeling miserable\n",
      "--------------------------------------------- Result 38 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i spent the last two weeks of school feeling miserable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 27 / 0 / 39:  78%|███████▊  | 39/50 [14:57<04:13, 23.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling very peaceful about our wedding again now after having\n",
      "--------------------------------------------- Result 39 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling very peaceful about our wedding again now after having\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 27 / 0 / 40:  80%|████████  | 40/50 [15:41<03:55, 23.53s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert4/1746362525123.ta.chkpt\" at 2025-05-04 13:42:05 after 40 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i had been talking to coach claudia barcomb and coach ali boe for a long time and they both made me feel very welcomed at union\n",
      "\n",
      "i had been talking to coaсh clauԁia barcomb and coach ali boe for a long time and they both made me feel very welcomеd at union\n",
      "--------------------------------------------- Result 40 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i had been talking to [[coach]] [[claudia]] barcomb and coach ali boe for a long time and they both made me feel very [[welcomed]] at union\n",
      "\n",
      "i had been talking to [[coaсh]] [[clauԁia]] barcomb and coach ali boe for a long time and they both made me feel very [[welcomеd]] at union\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 28 / 0 / 41:  82%|████████▏ | 41/50 [15:59<03:30, 23.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel if i completely hated things i d exercise my democratic right speak my mind in what ever ways possible and try to enact a change\n",
      "--------------------------------------------- Result 41 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel if i completely hated things i d exercise my democratic right speak my mind in what ever ways possible and try to enact a change\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 29 / 0 / 42:  84%|████████▍ | 42/50 [16:21<03:06, 23.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel humiliated embarrassed or foolish i will remember that others have felt the same way because of the same kinds of things and i will be kind and helpful and accepting\n",
      "--------------------------------------------- Result 42 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel humiliated embarrassed or foolish i will remember that others have felt the same way because of the same kinds of things and i will be kind and helpful and accepting\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 14 / 29 / 0 / 43:  86%|████████▌ | 43/50 [16:40<02:42, 23.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel reassured that i am dealing with my diet in the right way and that all is good\n",
      "\n",
      "i feеl reassured that i am dealing with my diet in the right way and that аll iѕ goοd\n",
      "--------------------------------------------- Result 43 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i [[feel]] reassured that i am dealing with my diet in the right way and that [[all]] [[is]] [[good]]\n",
      "\n",
      "i [[feеl]] reassured that i am dealing with my diet in the right way and that [[аll]] [[iѕ]] [[goοd]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 14 / 30 / 0 / 44:  88%|████████▊ | 44/50 [17:00<02:19, 23.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 1., 0.]) --> [FAILED]\n",
      "\n",
      "i feel i have to agree with her even though i can imagine some rather unpleasant possible cases\n",
      "--------------------------------------------- Result 44 ---------------------------------------------\n",
      "tensor([0., 0., 0., 0., 1., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel i have to agree with her even though i can imagine some rather unpleasant possible cases\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 30 / 0 / 45:  90%|█████████ | 45/50 [17:19<01:55, 23.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "im in such a happy mood today i feel almost delighted and i havent done anything different today then i normally have it is wonderful\n",
      "\n",
      "im іn such a happy mood today i feel almost delighted and i havent done anything different todаy then i normаlly have it is wοnderful\n",
      "--------------------------------------------- Result 45 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "im [[in]] such a happy mood today i feel almost delighted and i havent done anything different [[today]] then i [[normally]] have it is [[wonderful]]\n",
      "\n",
      "im [[іn]] such a happy mood today i feel almost delighted and i havent done anything different [[todаy]] then i [[normаlly]] have it is [[wοnderful]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 31 / 0 / 46:  92%|█████████▏| 46/50 [17:45<01:32, 23.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling really out of place and irritated\n",
      "--------------------------------------------- Result 46 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling really out of place and irritated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 32 / 0 / 47:  94%|█████████▍| 47/50 [18:05<01:09, 23.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also know that i feel nothing than a friendly affection to them too\n",
      "--------------------------------------------- Result 47 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also know that i feel nothing than a friendly affection to them too\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 16 / 32 / 0 / 48:  96%|█████████▌| 48/50 [18:24<00:46, 23.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like i had a rather productive weekend and i cant always say that no matter how much i get done\n",
      "\n",
      "i feel likе i had a rather productive weekend and i cant always say thаt no mаttеr how much i get done\n",
      "--------------------------------------------- Result 48 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel [[like]] i had a rather productive weekend and i cant always say [[that]] no [[matter]] how much i get done\n",
      "\n",
      "i feel [[likе]] i had a rather productive weekend and i cant always say [[thаt]] no [[mаttеr]] how much i get done\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 16 / 33 / 0 / 49:  98%|█████████▊| 49/50 [18:42<00:22, 22.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling insecure at the moment\n",
      "--------------------------------------------- Result 49 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling insecure at the moment\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 17 / 33 / 0 / 50: 100%|██████████| 50/50 [19:01<00:00, 22.84s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert4/1746362725824.ta.chkpt\" at 2025-05-04 13:45:25 after 50 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling pretty anxious all day but my first day at work was a very good day and that helped a lot\n",
      "\n",
      "i was feeling pretty anxious аll day but my first day at wοrk wаs a very good day аnd that helped a lot\n",
      "--------------------------------------------- Result 50 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling pretty anxious [[all]] day but my first day at [[work]] [[was]] a very good day [[and]] that helped a lot\n",
      "\n",
      "i was feeling pretty anxious [[аll]] day but my first day at [[wοrk]] [[wаs]] a very good day [[аnd]] that helped a lot\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 17 / 33 / 0 / 50: 100%|██████████| 50/50 [19:01<00:00, 22.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 17     |\n",
      "| Number of failed attacks:     | 33     |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 66.0%  |\n",
      "| Attack success rate:          | 34.0%  |\n",
      "| Average perturbed word %:     | 18.67% |\n",
      "| Average num. words per input: | 18.56  |\n",
      "| Avg num queries:              | 51.6   |\n",
      "+-------------------------------+--------+"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "textattack: No entry found for goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n",
      "textattack: Unknown if model of class <class '__main__.GPT4Wrapper'> compatible with goal function <class 'textattack.goal_functions.custom.targeted_bonus.TargetedBonus'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mdair-ai/emotion\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
      "textattack: Logging to CSV at path results/emotion/gpt4/pert5/log50.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): DifferentialEvolution(\n",
      "    (popsize):  5\n",
      "    (maxiter):  3\n",
      "    (max_perturbs):  5\n",
      "    (verbose):  False\n",
      "  )\n",
      "  (goal_function):  TargetedBonus\n",
      "  (transformation):  WordSwapHomoglyphSwap\n",
      "  (constraints): None\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   2%|▏         | 1/50 [00:25<21:07, 25.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im feeling rather rotten so im not very ambitious right now\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 2 / 0 / 2:   4%|▍         | 2/50 [00:49<19:52, 24.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im updating my blog because i feel shitty\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 3 / 0 / 3:   6%|▌         | 3/50 [01:14<19:19, 24.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i never make her separate from me because i don t ever want her to feel like i m ashamed with her\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 1 / 3 / 0 / 4:   8%|▊         | 4/50 [01:42<19:38, 25.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i left with my bouquet of red and yellow tulips under my arm feeling slightly more optimistic than when i arrived\n",
      "\n",
      "і left with my bouquet of red аnd yellow tulірs under my arm feеling slightly more optimistic than when i arrived\n",
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "[[i]] left with my bouquet of red [[and]] yellow [[tulips]] under my arm [[feeling]] slightly more optimistic than when i arrived\n",
      "\n",
      "[[і]] left with my bouquet of red [[аnd]] yellow [[tulірs]] under my arm [[feеling]] slightly more optimistic than when i arrived\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 3 / 0 / 5:  10%|█         | 5/50 [02:39<23:53, 31.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i was feeling a little vain when i did this one\n",
      "\n",
      "і was feelіng а little vain when i did this one\n",
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "[[i]] was [[feeling]] [[a]] little vain when i did this one\n",
      "\n",
      "[[і]] was [[feelіng]] [[а]] little vain when i did this one\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 4 / 0 / 6:  12%|█▏        | 6/50 [03:09<23:08, 31.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i cant walk into a shop anywhere where i do not feel uncomfortable\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 5 / 0 / 7:  14%|█▍        | 7/50 [03:36<22:07, 30.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i felt anger when at the end of a telephone call\n",
      "\n",
      "\n",
      "Could not parse result: The sentence expresses a sense of reflection and possibly disappointment regarding a relationship, which suggests an underlying sadness. Therefore, the emotion is sadness (0).\n",
      "Could not parse result: The sentence expresses a sense of conflict and disappointment regarding a relationship that overshadowed a positive achievement, which leans towards sadness. Therefore, the emotion is: 0.\n",
      "Could not parse result: The emotion expressed in the sentence is sadness (0).\n",
      "Could not parse result: The emotion expressed in the sentence is sadness (0).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 2 / 6 / 0 / 8:  16%|█▌        | 8/50 [04:25<23:15, 33.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i explain why i clung to a relationship with a boy who was in many ways immature and uncommitted despite the excitement i should have been feeling for getting accepted into the masters program at the university of virginia\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 6 / 0 / 9:  18%|█▊        | 9/50 [04:52<22:13, 32.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have the same breathless feeling as a reader eager to see what will happen next\n",
      "\n",
      "i like to have the same breathless feeling as a reader eаger to see wһat wіll hаppen nеxt\n",
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i like to have the same breathless feeling as a reader [[eager]] to see [[what]] [[will]] [[happen]] [[next]]\n",
      "\n",
      "i like to have the same breathless feeling as a reader [[eаger]] to see [[wһat]] [[wіll]] [[hаppen]] [[nеxt]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 7 / 0 / 10:  20%|██        | 10/50 [05:26<21:46, 32.65s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert5/1746363054292.ta.chkpt\" at 2025-05-04 13:50:54 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i jest i feel grumpy tired and pre menstrual which i probably am but then again its only been a week and im about as fit as a walrus on vacation for the summer\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 8 / 0 / 11:  22%|██▏       | 11/50 [05:51<20:46, 31.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "--------------------------------------------- Result 11 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i don t feel particularly agitated\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 9 / 0 / 12:  24%|██▍       | 12/50 [06:16<19:52, 31.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "--------------------------------------------- Result 12 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel beautifully emotional knowing that these women of whom i knew just a handful were holding me and my baba on our journey\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 3 / 10 / 0 / 13:  26%|██▌       | 13/50 [06:40<18:59, 30.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "--------------------------------------------- Result 13 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i pay attention it deepens into a feeling of being invaded and helpless\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 10 / 0 / 14:  28%|██▊       | 14/50 [07:28<19:14, 32.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i just feel extremely comfortable with the group of people that i dont even need to hide myself\n",
      "\n",
      "i just fеel extremely comfortable with the group οf peoplе that i dont even neeԁ to hide myself\n",
      "--------------------------------------------- Result 14 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i just [[feel]] extremely comfortable with the group [[of]] [[people]] that i dont even [[need]] to hide myself\n",
      "\n",
      "i just [[fеel]] extremely comfortable with the group [[οf]] [[peoplе]] that i dont even [[neeԁ]] to hide myself\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 11 / 0 / 15:  30%|███       | 15/50 [07:56<18:31, 31.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i find myself in the odd position of feeling supportive of\n",
      "--------------------------------------------- Result 15 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i find myself in the odd position of feeling supportive of\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 4 / 12 / 0 / 16:  32%|███▏      | 16/50 [08:24<17:51, 31.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "--------------------------------------------- Result 16 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i was feeling as heartbroken as im sure katniss was\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 12 / 0 / 17:  34%|███▍      | 17/50 [09:12<17:52, 32.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel a little mellow today\n",
      "\n",
      "i fеel a littlе mellοw tοday\n",
      "--------------------------------------------- Result 17 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i [[feel]] a [[little]] [[mellow]] [[today]]\n",
      "\n",
      "i [[fеel]] a [[littlе]] [[mellοw]] [[tοday]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 13 / 0 / 18:  36%|███▌      | 18/50 [09:40<17:12, 32.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "--------------------------------------------- Result 18 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel like my only role now would be to tear your sails with my pessimism and discontent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 5 / 14 / 0 / 19:  38%|███▊      | 19/50 [10:04<16:26, 31.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 1., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "--------------------------------------------- Result 19 ---------------------------------------------\n",
      "tensor([0., 0., 0., 1., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 14 / 0 / 20:  40%|████      | 20/50 [10:30<15:45, 31.51s/it]textattack: Saving checkpoint under \"results/emotion/gpt4/pert5/1746363358011.ta.chkpt\" at 2025-05-04 13:55:58 after 20 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like reds and purples are just so rich and kind of perfect\n",
      "\n",
      "i feеl like reds аnd purples аrе just so rich аnd kind of perfect\n",
      "--------------------------------------------- Result 20 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i [[feel]] like reds [[and]] purples [[are]] just so rich [[and]] kind of perfect\n",
      "\n",
      "i [[feеl]] like reds [[аnd]] purples [[аrе]] just so rich [[аnd]] kind of perfect\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 6 / 15 / 0 / 21:  42%|████▏     | 21/50 [10:57<15:07, 31.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "--------------------------------------------- Result 21 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "im not sure the feeling of loss will ever go away but it may dull to a sweet feeling of nostalgia at what i shared in this life with my dad and the luck i had to have a dad for years\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 15 / 0 / 22:  44%|████▍     | 22/50 [11:25<14:32, 31.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like ive gotten to know many of you through comments and emails and for that im appreciative and glad you are a part of this little space\n",
      "\n",
      "i feel like ivе gotten to know many of yοu through comments and emails and fοr that im appreciatіve and glad you are a part of this little space\n",
      "--------------------------------------------- Result 22 ---------------------------------------------\n",
      "tensor([0., 1., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i feel like [[ive]] gotten to know many of [[you]] through comments and emails and [[for]] that im [[appreciative]] and glad you are a part of this little space\n",
      "\n",
      "i feel like [[ivе]] gotten to know many of [[yοu]] through comments and emails and [[fοr]] that im [[appreciatіve]] and glad you are a part of this little space\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 15 / 0 / 23:  46%|████▌     | 23/50 [12:18<14:27, 32.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "i survey my own posts over the last few years and only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone like me in dublin in the st century\n",
      "\n",
      "і survey my own posts over the last few years anԁ only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone likе me in dublіn in the st сentury\n",
      "--------------------------------------------- Result 23 ---------------------------------------------\n",
      "tensor([1., 0., 0., 0., 0., 0.]) --> tensor([0., 1., 0., 0., 0., 0.])\n",
      "\n",
      "[[i]] survey my own posts over the last few years [[and]] only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone [[like]] me in [[dublin]] in the st [[century]]\n",
      "\n",
      "[[і]] survey my own posts over the last few years [[anԁ]] only feel pleased with vague snippets of a few of them only feel that little bits of them capture what its like to be me or someone [[likе]] me in [[dublіn]] in the st [[сentury]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 8 / 16 / 0 / 24:  48%|████▊     | 24/50 [12:46<13:49, 31.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 0.]) --> [FAILED]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "--------------------------------------------- Result 24 ---------------------------------------------\n",
      "tensor([0., 0., 1., 0., 0., 0.]) --> [[[FAILED]]]\n",
      "\n",
      "i also tell you in hopes that anyone who is still feeling stigmatized or ashamed of their mental health issues will let go of the stigma let go of the shame\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-tOghivYYiEr3uog0BbdoPsgD on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 20\u001b[0m\n\u001b[1;32m     13\u001b[0m attack_args \u001b[38;5;241m=\u001b[39m textattack\u001b[38;5;241m.\u001b[39mAttackArgs(\n\u001b[1;32m     14\u001b[0m     num_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     15\u001b[0m     checkpoint_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     16\u001b[0m     checkpoint_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/emotion/gpt4/pert\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpert\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     log_to_csv\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/emotion/gpt4/pert\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpert\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/log50.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m attacker \u001b[38;5;241m=\u001b[39m textattack\u001b[38;5;241m.\u001b[39mAttacker(attack, dataset, attack_args)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mattacker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/attacker.py:441\u001b[0m, in \u001b[0;36mAttacker.attack_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attack_parallel()\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39msilent:\n\u001b[1;32m    444\u001b[0m     logger\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mINFO)\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/attacker.py:170\u001b[0m, in \u001b[0;36mAttacker._attack\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack\u001b[38;5;241m.\u001b[39mattack(example, ground_truth_output)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(result, SkippedAttackResult) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39mattack_n\n\u001b[1;32m    173\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, SuccessfulAttackResult)\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattack_args\u001b[38;5;241m.\u001b[39mnum_successful_examples\n\u001b[1;32m    176\u001b[0m ):\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m worklist_candidates:\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/attacker.py:168\u001b[0m, in \u001b[0;36mAttacker._attack\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m     example\u001b[38;5;241m.\u001b[39mattack_attrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mlabel_names\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/attack.py:450\u001b[0m, in \u001b[0;36mAttack.attack\u001b[0;34m(self, example, ground_truth_output)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SkippedAttackResult(goal_function_result)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 450\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgoal_function_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/attack.py:398\u001b[0m, in \u001b[0;36mAttack._attack\u001b[0;34m(self, initial_result)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_attack\u001b[39m(\u001b[38;5;28mself\u001b[39m, initial_result):\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the ``SearchMethod`` to perturb the ``AttackedText`` stored in\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03m    ``initial_result``.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m            or ``MaximizedAttackResult``.\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     final_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_cache()\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_result\u001b[38;5;241m.\u001b[39mgoal_status \u001b[38;5;241m==\u001b[39m GoalFunctionResultStatus\u001b[38;5;241m.\u001b[39mSUCCEEDED:\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/search_methods/search_method.py:35\u001b[0m, in \u001b[0;36mSearchMethod.__call__\u001b[0;34m(self, initial_result)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter_transformations\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch Method must have access to filter_transformations method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     33\u001b[0m     )\n\u001b[0;32m---> 35\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# ensure that the number of queries for this GoalFunctionResult is up-to-date\u001b[39;00m\n\u001b[1;32m     37\u001b[0m result\u001b[38;5;241m.\u001b[39mnum_queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgoal_function\u001b[38;5;241m.\u001b[39mnum_queries\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/search_methods/differential_evolution.py:59\u001b[0m, in \u001b[0;36mDifferentialEvolution.perform_search\u001b[0;34m(self, initial_result)\u001b[0m\n\u001b[1;32m     56\u001b[0m         best_result_found \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur_score\n\u001b[0;32m---> 59\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mdifferential_evolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopsize\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# minimises obj\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_result_found \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m initial_result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/scipy/optimize/_differentialevolution.py:402\u001b[0m, in \u001b[0;36mdifferential_evolution\u001b[0;34m(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, seed, callback, disp, polish, init, atol, updating, workers, constraints, x0, integrality, vectorized)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# using a context manager means that any created Pool objects are\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# cleared up.\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DifferentialEvolutionSolver(func, bounds, args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m    388\u001b[0m                                  strategy\u001b[38;5;241m=\u001b[39mstrategy,\n\u001b[1;32m    389\u001b[0m                                  maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                  integrality\u001b[38;5;241m=\u001b[39mintegrality,\n\u001b[1;32m    401\u001b[0m                                  vectorized\u001b[38;5;241m=\u001b[39mvectorized) \u001b[38;5;28;01mas\u001b[39;00m solver:\n\u001b[0;32m--> 402\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/scipy/optimize/_differentialevolution.py:1022\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxiter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;66;03m# evolve the population by a generation\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1022\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1024\u001b[0m         warning_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/scipy/optimize/_differentialevolution.py:1409\u001b[0m, in \u001b[0;36mDifferentialEvolutionSolver.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1407\u001b[0m     feasible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1408\u001b[0m     cv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_2d([\u001b[38;5;241m0.\u001b[39m])\n\u001b[0;32m-> 1409\u001b[0m     energy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;66;03m# compare trial and population member\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/scipy/_lib/_util.py:360\u001b[0m, in \u001b[0;36m_FunctionWrapper.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/search_methods/differential_evolution.py:53\u001b[0m, in \u001b[0;36mDifferentialEvolution.perform_search.<locals>.obj\u001b[0;34m(perturbation_vector)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_transformations([cand], initial_text, initial_text)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m---> 53\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_goal_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcand\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     54\u001b[0m cur_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mresult\u001b[38;5;241m.\u001b[39mscore\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (cur_score \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m best_score):\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/goal_functions/goal_function.py:97\u001b[0m, in \u001b[0;36mGoalFunction.get_results\u001b[0;34m(self, attacked_text_list, check_skip)\u001b[0m\n\u001b[1;32m     95\u001b[0m     attacked_text_list \u001b[38;5;241m=\u001b[39m attacked_text_list[:queries_left]\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_queries \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(attacked_text_list)\n\u001b[0;32m---> 97\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattacked_text_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attacked_text, raw_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(attacked_text_list, model_outputs):\n\u001b[1;32m     99\u001b[0m     displayed_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_displayed_output(raw_output)\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/goal_functions/goal_function.py:220\u001b[0m, in \u001b[0;36mGoalFunction._call_model\u001b[0;34m(self, attacked_text_list)\u001b[0m\n\u001b[1;32m    214\u001b[0m         uncached_list\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[1;32m    215\u001b[0m uncached_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    216\u001b[0m     text\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m attacked_text_list\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_model_cache\n\u001b[1;32m    219\u001b[0m ]\n\u001b[0;32m--> 220\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_model_uncached\u001b[49m\u001b[43m(\u001b[49m\u001b[43muncached_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text, output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(uncached_list, outputs):\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_model_cache[text] \u001b[38;5;241m=\u001b[39m output\n",
      "File \u001b[0;32m~/Documents/GitHub/TextAttack/textattack/goal_functions/goal_function.py:166\u001b[0m, in \u001b[0;36mGoalFunction._call_model_uncached\u001b[0;34m(self, attacked_text_list)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs):\n\u001b[1;32m    165\u001b[0m     batch \u001b[38;5;241m=\u001b[39m inputs[i : i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[0;32m--> 166\u001b[0m     batch_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Some seq-to-seq models will return a single string as a prediction\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# for a single-string list. Wrap these in a list.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_preds, \u001b[38;5;28mstr\u001b[39m):\n",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m, in \u001b[0;36mGPT4Wrapper.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[0;32m---> 19\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     29\u001b[0m     arr \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m6\u001b[39m \n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py:929\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    926\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    927\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    928\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 929\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/_base_client.py:1276\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1264\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1272\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1273\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1274\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1275\u001b[0m     )\n\u001b[0;32m-> 1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/_base_client.py:949\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    947\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/_base_client.py:1042\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1041\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1042\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/_base_client.py:1091\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1091\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/_base_client.py:1042\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1041\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1042\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/_base_client.py:1091\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1091\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/openai/_base_client.py:1057\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1056\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1060\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1061\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1066\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-tOghivYYiEr3uog0BbdoPsgD on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "for pert in range(1, 6):\n",
    "\n",
    "    attack = textattack.attack_recipes.BadCharacters2021.build(\n",
    "        model_wrapper, \n",
    "        goal_function_type=\"targeted_bonus\",\n",
    "        perturbation_type=args.perturbation_type,\n",
    "        target_class=1,\n",
    "        perturbs=pert,\n",
    "        popsize=5,\n",
    "        maxiter=3\n",
    "    )\n",
    "    dataset = textattack.datasets.HuggingFaceDataset(\"dair-ai/emotion\", split=\"test\")\n",
    "    attack_args = textattack.AttackArgs(\n",
    "        num_examples=50,\n",
    "        checkpoint_interval=10,\n",
    "        checkpoint_dir=f\"results/emotion/gpt4/pert{pert}\",\n",
    "        log_to_csv=f\"results/emotion/gpt4/pert{pert}/log50.csv\"\n",
    "    )\n",
    "    attacker = textattack.Attacker(attack, dataset, attack_args)\n",
    "    attacker.attack_dataset()\n",
    "\n",
    "    # if args.store_results == False:\n",
    "    #     if os.path.isdir(\"results/emotion/gpt4\"):\n",
    "    #         shutil.rmtree(\"results/emotion/gpt4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading WMT14 test data from http://statmt.org/wmt14/test-full.tgz...\n",
      "Extracting test-full/newstest2014-fren-ref.fr.sgm to temp/translation/data\n",
      "Extracting test-full/newstest2014-fren-src.en.sgm to temp/translation/data\n",
      "en_fr dataset downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: No entry found for goal function <class 'textattack.goal_functions.text.maximize_levenshtein.MaximizeLevenshtein'>.\n",
      "textattack: Unknown if model of class <class '__main__.GPT4Wrapper'> compatible with goal function <class 'textattack.goal_functions.text.maximize_levenshtein.MaximizeLevenshtein'>.\n",
      "textattack: Logging to CSV at path results/translation/gpt4/log100.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(OrderedDict([('text', 'Spectacular Wingsuit Jump Over Bogota')]), 'Spectaculaire saut en \"wingsuit\" au-dessus de Bogota')\n",
      "Attack(\n",
      "  (search_method): DifferentialEvolution(\n",
      "    (popsize):  3\n",
      "    (maxiter):  1\n",
      "    (max_perturbs):  5\n",
      "    (verbose):  False\n",
      "  )\n",
      "  (goal_function):  MaximizeLevenshtein(\n",
      "    (maximizable):  False\n",
      "    (target_distance):  None\n",
      "  )\n",
      "  (transformation):  WordSwapHomoglyphSwap\n",
      "  (constraints): None\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saut en wingsuit spectaculaire au-dessus de Bogotá. --> [FAILED]\n",
      "\n",
      "Spectacular Wingsuit Jump Over Bogota\n",
      "--------------------------------------------- Result 1 ---------------------------------------------\n",
      "Saut en wingsuit spectaculaire au-dessus de Bogotá. --> [[[FAILED]]]\n",
      "\n",
      "Spectacular Wingsuit Jump Over Bogota\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le sportif Jhonathan Florez a sauté d'un hélicoptère au-dessus de Bogotá, la capitale de la Colombie, jeudi. --> [FAILED]\n",
      "\n",
      "Sportsman Jhonathan Florez jumped from a helicopter above Bogota, the capital of Colombia, on Thursday.\n",
      "--------------------------------------------- Result 2 ---------------------------------------------\n",
      "Le sportif Jhonathan Florez a sauté d'un hélicoptère au-dessus de Bogotá, la capitale de la Colombie, jeudi. --> [[[FAILED]]]\n",
      "\n",
      "Sportsman Jhonathan Florez jumped from a helicopter above Bogota, the capital of Colombia, on Thursday.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vêtu d'une combinaison de wingsuit, il a survolé le célèbre sanctuaire de Monserrate à 160 km/h. Le sanctuaire est situé à une altitude de plus de 3000 mètres et de nombreux spectateurs s --> [FAILED]\n",
      "\n",
      "Wearing a wingsuit, he flew past over the famous Monserrate Sanctuary at 160km/h. The sanctuary is located at an altitude of over 3000 meters and numerous spectators had gathered there to watch his exploit.\n",
      "--------------------------------------------- Result 3 ---------------------------------------------\n",
      "Vêtu d'une combinaison de wingsuit, il a survolé le célèbre sanctuaire de Monserrate à 160 km/h. Le sanctuaire est situé à une altitude de plus de 3000 mètres et de nombreux spectateurs s --> [[[FAILED]]]\n",
      "\n",
      "Wearing a wingsuit, he flew past over the famous Monserrate Sanctuary at 160km/h. The sanctuary is located at an altitude of over 3000 meters and numerous spectators had gathered there to watch his exploit.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Une boîte noire dans votre voiture ? --> [FAILED]\n",
      "\n",
      "A black box in your car?\n",
      "--------------------------------------------- Result 4 ---------------------------------------------\n",
      "Une boîte noire dans votre voiture ? --> [[[FAILED]]]\n",
      "\n",
      "A black box in your car?\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [45:29<?, ?it/s]\n",
      "  0%|          | 0/1 [44:17<?, ?it/s]\n",
      "  0%|          | 0/1 [41:34<?, ?it/s]\n",
      "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:   1%|          | 1/100 [40:44<67:13:09, 2444.34s/it]\n",
      "textattack: CSVLogger exiting without calling flush().\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alors que les planificateurs routiers américains peinent à trouver des fonds pour réparer un système autoroutier en ruine, beaucoup commencent à voir une solution dans une petite boîte noire qui s'adapte parfaitement au tableau de bord de votre voiture. --> [FAILED]\n",
      "\n",
      "As America's road planners struggle to find the cash to mend a crumbling highway system, many are beginning to see a solution in a little black box that fits neatly by the dashboard of your car.\n",
      "--------------------------------------------- Result 5 ---------------------------------------------\n",
      "Alors que les planificateurs routiers américains peinent à trouver des fonds pour réparer un système autoroutier en ruine, beaucoup commencent à voir une solution dans une petite boîte noire qui s'adapte parfaitement au tableau de bord de votre voiture. --> [[[FAILED]]]\n",
      "\n",
      "As America's road planners struggle to find the cash to mend a crumbling highway system, many are beginning to see a solution in a little black box that fits neatly by the dashboard of your car.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les dispositifs, qui suivent chaque mile parcouru par un automobiliste et transmettent ces informations aux bureaucrates, sont au centre d'une tentative controversée à Washington et dans les bureaux de planification des États de réformer le système obsolète de --> [FAILED]\n",
      "\n",
      "The devices, which track every mile a motorist drives and transmit that information to bureaucrats, are at the center of a controversial attempt in Washington and state planning offices to overhaul the outdated system for funding America's major roads.\n",
      "--------------------------------------------- Result 6 ---------------------------------------------\n",
      "Les dispositifs, qui suivent chaque mile parcouru par un automobiliste et transmettent ces informations aux bureaucrates, sont au centre d'une tentative controversée à Washington et dans les bureaux de planification des États de réformer le système obsolète de --> [[[FAILED]]]\n",
      "\n",
      "The devices, which track every mile a motorist drives and transmit that information to bureaucrats, are at the center of a controversial attempt in Washington and state planning offices to overhaul the outdated system for funding America's major roads.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'arène habituellement ennuyeuse de la planification des autoroutes a soudainement engendré un débat intense et des alliances colorées. --> [FAILED]\n",
      "\n",
      "The usually dull arena of highway planning has suddenly spawned intense debate and colorful alliances.\n",
      "--------------------------------------------- Result 7 ---------------------------------------------\n",
      "L'arène habituellement ennuyeuse de la planification des autoroutes a soudainement engendré un débat intense et des alliances colorées. --> [[[FAILED]]]\n",
      "\n",
      "The usually dull arena of highway planning has suddenly spawned intense debate and colorful alliances.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les libertariens se sont joints aux groupes environnementaux pour faire pression afin de permettre au gouvernement d'utiliser les petites boîtes pour suivre les kilomètres que vous parcourez, et éventuellement où vous les parcourez - puis utiliser les informations pour établir --> [FAILED]\n",
      "\n",
      "Libertarians have joined environmental groups in lobbying to allow government to use the little boxes to keep track of the miles you drive, and possibly where you drive them - then use the information to draw up a tax bill.\n",
      "--------------------------------------------- Result 8 ---------------------------------------------\n",
      "Les libertariens se sont joints aux groupes environnementaux pour faire pression afin de permettre au gouvernement d'utiliser les petites boîtes pour suivre les kilomètres que vous parcourez, et éventuellement où vous les parcourez - puis utiliser les informations pour établir --> [[[FAILED]]]\n",
      "\n",
      "Libertarians have joined environmental groups in lobbying to allow government to use the little boxes to keep track of the miles you drive, and possibly where you drive them - then use the information to draw up a tax bill.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La fête du thé est consternée. --> [FAILED]\n",
      "\n",
      "The tea party is aghast.\n",
      "--------------------------------------------- Result 9 ---------------------------------------------\n",
      "La fête du thé est consternée. --> [[[FAILED]]]\n",
      "\n",
      "The tea party is aghast.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746129116160.ta.chkpt\" at 2025-05-01 20:51:56 after 10 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'Union américaine pour les libertés civiles est également profondément préoccupée, soulevant une variété de problèmes de confidentialité. --> [FAILED]\n",
      "\n",
      "The American Civil Liberties Union is deeply concerned, too, raising a variety of privacy issues.\n",
      "--------------------------------------------- Result 10 ---------------------------------------------\n",
      "L'Union américaine pour les libertés civiles est également profondément préoccupée, soulevant une variété de problèmes de confidentialité. --> [[[FAILED]]]\n",
      "\n",
      "The American Civil Liberties Union is deeply concerned, too, raising a variety of privacy issues.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Et tandis que le Congrès ne parvient pas à se mettre d'accord sur la manière de procéder, plusieurs États n'attendent pas. --> [FAILED]\n",
      "\n",
      "And while Congress can't agree on whether to proceed, several states are not waiting.\n",
      "--------------------------------------------- Result 11 ---------------------------------------------\n",
      "Et tandis que le Congrès ne parvient pas à se mettre d'accord sur la manière de procéder, plusieurs États n'attendent pas. --> [[[FAILED]]]\n",
      "\n",
      "And while Congress can't agree on whether to proceed, several states are not waiting.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ils explorent comment, au cours de la prochaine décennie, ils peuvent passer à un système dans lequel les conducteurs paient par mile de route qu'ils parcourent. --> [FAILED]\n",
      "\n",
      "They are exploring how, over the next decade, they can move to a system in which drivers pay per mile of road they roll over.\n",
      "--------------------------------------------- Result 12 ---------------------------------------------\n",
      "Ils explorent comment, au cours de la prochaine décennie, ils peuvent passer à un système dans lequel les conducteurs paient par mile de route qu'ils parcourent. --> [[[FAILED]]]\n",
      "\n",
      "They are exploring how, over the next decade, they can move to a system in which drivers pay per mile of road they roll over.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Des milliers de conducteurs ont déjà pris les boîtes noires, dont certaines disposent d'un suivi GPS, pour un essai. --> [FAILED]\n",
      "\n",
      "Thousands of motorists have already taken the black boxes, some of which have GPS monitoring, for a test drive.\n",
      "--------------------------------------------- Result 13 ---------------------------------------------\n",
      "Des milliers de conducteurs ont déjà pris les boîtes noires, dont certaines disposent d'un suivi GPS, pour un essai. --> [[[FAILED]]]\n",
      "\n",
      "Thousands of motorists have already taken the black boxes, some of which have GPS monitoring, for a test drive.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C'est vraiment un must pour notre nation. --> [FAILED]\n",
      "\n",
      "This really is a must for our nation.\n",
      "--------------------------------------------- Result 14 ---------------------------------------------\n",
      "C'est vraiment un must pour notre nation. --> [[[FAILED]]]\n",
      "\n",
      "This really is a must for our nation.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Ce n'est pas une question de quelque chose que nous pourrions choisir de faire,\" a déclaré Hasan Ikhrata, directeur exécutif de l'Association des gouvernements du sud de la Californie, qui prévoit que l'État commence à --> [FAILED]\n",
      "\n",
      "\"It is not a matter of something we might choose to do,\" said Hasan Ikhrata, executive director of the Southern California Assn. of Governments, which is planning for the state to start tracking miles driven by every California motorist by 2025.\n",
      "--------------------------------------------- Result 15 ---------------------------------------------\n",
      "\"Ce n'est pas une question de quelque chose que nous pourrions choisir de faire,\" a déclaré Hasan Ikhrata, directeur exécutif de l'Association des gouvernements du sud de la Californie, qui prévoit que l'État commence à --> [[[FAILED]]]\n",
      "\n",
      "\"It is not a matter of something we might choose to do,\" said Hasan Ikhrata, executive director of the Southern California Assn. of Governments, which is planning for the state to start tracking miles driven by every California motorist by 2025.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y aura un changement dans la façon dont nous payons ces impôts. --> [FAILED]\n",
      "\n",
      "There is going to be a change in how we pay these taxes.\n",
      "--------------------------------------------- Result 16 ---------------------------------------------\n",
      "Il y aura un changement dans la façon dont nous payons ces impôts. --> [[[FAILED]]]\n",
      "\n",
      "There is going to be a change in how we pay these taxes.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La technologie est là pour le faire. --> [FAILED]\n",
      "\n",
      "The technology is there to do it.\n",
      "--------------------------------------------- Result 17 ---------------------------------------------\n",
      "La technologie est là pour le faire. --> [[[FAILED]]]\n",
      "\n",
      "The technology is there to do it.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La pression survient alors que le Fonds de confiance pour les autoroutes du pays, financé par les taxes que les Américains paient à la pompe, est en faillite. --> [FAILED]\n",
      "\n",
      "The push comes as the country's Highway Trust Fund, financed with taxes Americans pay at the gas pump, is broke.\n",
      "--------------------------------------------- Result 18 ---------------------------------------------\n",
      "La pression survient alors que le Fonds de confiance pour les autoroutes du pays, financé par les taxes que les Américains paient à la pompe, est en faillite. --> [[[FAILED]]]\n",
      "\n",
      "The push comes as the country's Highway Trust Fund, financed with taxes Americans pay at the gas pump, is broke.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les Américains n'achètent pas autant d'essence qu'auparavant. --> [FAILED]\n",
      "\n",
      "Americans don't buy as much gas as they used to.\n",
      "--------------------------------------------- Result 19 ---------------------------------------------\n",
      "Les Américains n'achètent pas autant d'essence qu'auparavant. --> [[[FAILED]]]\n",
      "\n",
      "Americans don't buy as much gas as they used to.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746129404810.ta.chkpt\" at 2025-05-01 20:56:44 after 20 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les voitures parcourent beaucoup plus de kilomètres par gallon. --> [FAILED]\n",
      "\n",
      "Cars get many more miles to the gallon.\n",
      "--------------------------------------------- Result 20 ---------------------------------------------\n",
      "Les voitures parcourent beaucoup plus de kilomètres par gallon. --> [[[FAILED]]]\n",
      "\n",
      "Cars get many more miles to the gallon.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La taxe fédérale elle-même, de 18,4 cents par gallon, n'a pas augmenté depuis 20 ans. --> [FAILED]\n",
      "\n",
      "The federal tax itself, 18.4 cents per gallon, hasn't gone up in 20 years.\n",
      "--------------------------------------------- Result 21 ---------------------------------------------\n",
      "La taxe fédérale elle-même, de 18,4 cents par gallon, n'a pas augmenté depuis 20 ans. --> [[[FAILED]]]\n",
      "\n",
      "The federal tax itself, 18.4 cents per gallon, hasn't gone up in 20 years.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les politiciens sont réticents à augmenter les impôts ne serait-ce que d'un centime lorsque les prix de l'essence sont élevés. --> [FAILED]\n",
      "\n",
      "Politicians are loath to raise the tax even one penny when gas prices are high.\n",
      "--------------------------------------------- Result 22 ---------------------------------------------\n",
      "Les politiciens sont réticents à augmenter les impôts ne serait-ce que d'un centime lorsque les prix de l'essence sont élevés. --> [[[FAILED]]]\n",
      "\n",
      "Politicians are loath to raise the tax even one penny when gas prices are high.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"La taxe sur l'essence n'est tout simplement pas durable,\" a déclaré Lee Munnich, un expert en politique de transport à l'Université du Minnesota. --> [FAILED]\n",
      "\n",
      "\"The gas tax is just not sustainable,\" said Lee Munnich, a transportation policy expert at the University of Minnesota.\n",
      "--------------------------------------------- Result 23 ---------------------------------------------\n",
      "\"La taxe sur l'essence n'est tout simplement pas durable,\" a déclaré Lee Munnich, un expert en politique de transport à l'Université du Minnesota. --> [[[FAILED]]]\n",
      "\n",
      "\"The gas tax is just not sustainable,\" said Lee Munnich, a transportation policy expert at the University of Minnesota.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Son État a récemment installé des dispositifs de suivi sur 500 voitures pour tester un système de paiement au kilomètre. --> [FAILED]\n",
      "\n",
      "His state recently put tracking devices on 500 cars to test out a pay-by-mile system.\n",
      "--------------------------------------------- Result 24 ---------------------------------------------\n",
      "Son État a récemment installé des dispositifs de suivi sur 500 voitures pour tester un système de paiement au kilomètre. --> [[[FAILED]]]\n",
      "\n",
      "His state recently put tracking devices on 500 cars to test out a pay-by-mile system.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Cela s'avère être l'alternative la plus logique à long terme,\" a-t-il déclaré. --> [FAILED]\n",
      "\n",
      "\"This works out as the most logical alternative over the long term,\" he said.\n",
      "--------------------------------------------- Result 25 ---------------------------------------------\n",
      "\"Cela s'avère être l'alternative la plus logique à long terme,\" a-t-il déclaré. --> [[[FAILED]]]\n",
      "\n",
      "\"This works out as the most logical alternative over the long term,\" he said.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les experts l'appellent un tarif utilisateur basé sur le kilométrage. --> [FAILED]\n",
      "\n",
      "Wonks call it a mileage-based user fee.\n",
      "--------------------------------------------- Result 26 ---------------------------------------------\n",
      "Les experts l'appellent un tarif utilisateur basé sur le kilométrage. --> [[[FAILED]]]\n",
      "\n",
      "Wonks call it a mileage-based user fee.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il n'est pas surprenant que l'idée plaise aux libéraux urbains, car les taxes pourraient être manipulées pour modifier les habitudes de conduite de manière à aider à réduire la congestion et les gaz à effet de serre, par exemple. --> [FAILED]\n",
      "\n",
      "It is no surprise that the idea appeals to urban liberals, as the taxes could be rigged to change driving patterns in ways that could help reduce congestion and greenhouse gases, for example.\n",
      "--------------------------------------------- Result 27 ---------------------------------------------\n",
      "Il n'est pas surprenant que l'idée plaise aux libéraux urbains, car les taxes pourraient être manipulées pour modifier les habitudes de conduite de manière à aider à réduire la congestion et les gaz à effet de serre, par exemple. --> [[[FAILED]]]\n",
      "\n",
      "It is no surprise that the idea appeals to urban liberals, as the taxes could be rigged to change driving patterns in ways that could help reduce congestion and greenhouse gases, for example.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les planificateurs de Californie se tournent vers le système alors qu'ils élaborent des stratégies pour atteindre les objectifs fixés par les ambitieuses lois sur le réchauffement climatique de l'État. --> [FAILED]\n",
      "\n",
      "California planners are looking to the system as they devise strategies to meet the goals laid out in the state's ambitious global warming laws.\n",
      "--------------------------------------------- Result 28 ---------------------------------------------\n",
      "Les planificateurs de Californie se tournent vers le système alors qu'ils élaborent des stratégies pour atteindre les objectifs fixés par les ambitieuses lois sur le réchauffement climatique de l'État. --> [[[FAILED]]]\n",
      "\n",
      "California planners are looking to the system as they devise strategies to meet the goals laid out in the state's ambitious global warming laws.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mais le représentant Bill Shuster (R-Pa.), président de la Commission des transports de la Chambre, a déclaré qu'il considère également cela comme la solution alternative à long terme la plus viable. --> [FAILED]\n",
      "\n",
      "But Rep. Bill Shuster (R-Pa.), chairman of the House Transportation Committee, has said he, too, sees it as the most viable long-term alternative.\n",
      "--------------------------------------------- Result 29 ---------------------------------------------\n",
      "Mais le représentant Bill Shuster (R-Pa.), président de la Commission des transports de la Chambre, a déclaré qu'il considère également cela comme la solution alternative à long terme la plus viable. --> [[[FAILED]]]\n",
      "\n",
      "But Rep. Bill Shuster (R-Pa.), chairman of the House Transportation Committee, has said he, too, sees it as the most viable long-term alternative.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746129726715.ta.chkpt\" at 2025-05-01 21:02:06 after 30 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les partisans du libre marché à la Reason Foundation aiment également faire payer les conducteurs par mile. --> [FAILED]\n",
      "\n",
      "The free marketeers at the Reason Foundation are also fond of having drivers pay per mile.\n",
      "--------------------------------------------- Result 30 ---------------------------------------------\n",
      "Les partisans du libre marché à la Reason Foundation aiment également faire payer les conducteurs par mile. --> [[[FAILED]]]\n",
      "\n",
      "The free marketeers at the Reason Foundation are also fond of having drivers pay per mile.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "« Ce n'est pas juste une taxe qui va dans un trou noir », a déclaré Adrian Moore, vice-président des politiques chez Reason. --> [FAILED]\n",
      "\n",
      "\"This is not just a tax going into a black hole,\" said Adrian Moore, vice president of policy at Reason.\n",
      "--------------------------------------------- Result 31 ---------------------------------------------\n",
      "« Ce n'est pas juste une taxe qui va dans un trou noir », a déclaré Adrian Moore, vice-président des politiques chez Reason. --> [[[FAILED]]]\n",
      "\n",
      "\"This is not just a tax going into a black hole,\" said Adrian Moore, vice president of policy at Reason.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les gens paient plus directement pour ce qu'ils obtiennent. --> [FAILED]\n",
      "\n",
      "People are paying more directly into what they are getting.\n",
      "--------------------------------------------- Result 32 ---------------------------------------------\n",
      "Les gens paient plus directement pour ce qu'ils obtiennent. --> [[[FAILED]]]\n",
      "\n",
      "People are paying more directly into what they are getting.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le mouvement est également soutenu par deux anciens secrétaires aux Transports des États-Unis, qui dans un rapport de 2011 ont exhorté le Congrès à se diriger vers un système de paiement au kilomètre. --> [FAILED]\n",
      "\n",
      "The movement is also bolstered by two former U.S. Transportation secretaries, who in a 2011 report urged Congress to move in the pay-per-mile direction.\n",
      "--------------------------------------------- Result 33 ---------------------------------------------\n",
      "Le mouvement est également soutenu par deux anciens secrétaires aux Transports des États-Unis, qui dans un rapport de 2011 ont exhorté le Congrès à se diriger vers un système de paiement au kilomètre. --> [[[FAILED]]]\n",
      "\n",
      "The movement is also bolstered by two former U.S. Transportation secretaries, who in a 2011 report urged Congress to move in the pay-per-mile direction.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Sénat américain a approuvé un projet pilote de 90 millions de dollars l'année dernière qui aurait impliqué environ 10 000 voitures. --> [FAILED]\n",
      "\n",
      "The U.S. Senate approved a $90-million pilot project last year that would have involved about 10,000 cars.\n",
      "--------------------------------------------- Result 34 ---------------------------------------------\n",
      "Le Sénat américain a approuvé un projet pilote de 90 millions de dollars l'année dernière qui aurait impliqué environ 10 000 voitures. --> [[[FAILED]]]\n",
      "\n",
      "The U.S. Senate approved a $90-million pilot project last year that would have involved about 10,000 cars.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mais la direction de la Chambre a tué la proposition, agissant sur les préoccupations des législateurs ruraux représentant des électeurs dont la vie quotidienne implique souvent de parcourir de nombreux kilomètres pour se rendre au travail ou en ville. --> [FAILED]\n",
      "\n",
      "But the House leadership killed the proposal, acting on concerns of rural lawmakers representing constituents whose daily lives often involve logging lots of miles to get to work or into town.\n",
      "--------------------------------------------- Result 35 ---------------------------------------------\n",
      "Mais la direction de la Chambre a tué la proposition, agissant sur les préoccupations des législateurs ruraux représentant des électeurs dont la vie quotidienne implique souvent de parcourir de nombreux kilomètres pour se rendre au travail ou en ville. --> [[[FAILED]]]\n",
      "\n",
      "But the House leadership killed the proposal, acting on concerns of rural lawmakers representing constituents whose daily lives often involve logging lots of miles to get to work or into town.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plusieurs États et villes avancent néanmoins de leur côté. --> [FAILED]\n",
      "\n",
      "Several states and cities are nonetheless moving ahead on their own.\n",
      "--------------------------------------------- Result 36 ---------------------------------------------\n",
      "Plusieurs États et villes avancent néanmoins de leur côté. --> [[[FAILED]]]\n",
      "\n",
      "Several states and cities are nonetheless moving ahead on their own.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le plus enthousiaste est l'Oregon, qui recrute 5 000 conducteurs dans la plus grande expérience du pays. --> [FAILED]\n",
      "\n",
      "The most eager is Oregon, which is enlisting 5,000 drivers in the country's biggest experiment.\n",
      "--------------------------------------------- Result 37 ---------------------------------------------\n",
      "Le plus enthousiaste est l'Oregon, qui recrute 5 000 conducteurs dans la plus grande expérience du pays. --> [[[FAILED]]]\n",
      "\n",
      "The most eager is Oregon, which is enlisting 5,000 drivers in the country's biggest experiment.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ces conducteurs paieront bientôt les frais de kilométrage au lieu des taxes sur l'essence à l'État. --> [FAILED]\n",
      "\n",
      "Those drivers will soon pay the mileage fees instead of gas taxes to the state.\n",
      "--------------------------------------------- Result 38 ---------------------------------------------\n",
      "Ces conducteurs paieront bientôt les frais de kilométrage au lieu des taxes sur l'essence à l'État. --> [[[FAILED]]]\n",
      "\n",
      "Those drivers will soon pay the mileage fees instead of gas taxes to the state.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Nevada a déjà terminé un projet pilote. --> [FAILED]\n",
      "\n",
      "Nevada has already completed a pilot.\n",
      "--------------------------------------------- Result 39 ---------------------------------------------\n",
      "Le Nevada a déjà terminé un projet pilote. --> [[[FAILED]]]\n",
      "\n",
      "Nevada has already completed a pilot.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746130030736.ta.chkpt\" at 2025-05-01 21:07:10 after 40 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La ville de New York envisage d'en créer un. --> [FAILED]\n",
      "\n",
      "New York City is looking into one.\n",
      "--------------------------------------------- Result 40 ---------------------------------------------\n",
      "La ville de New York envisage d'en créer un. --> [[[FAILED]]]\n",
      "\n",
      "New York City is looking into one.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'Illinois essaie cela sur une base limitée avec des camions. --> [FAILED]\n",
      "\n",
      "Illinois is trying it on a limited basis with trucks.\n",
      "--------------------------------------------- Result 41 ---------------------------------------------\n",
      "L'Illinois essaie cela sur une base limitée avec des camions. --> [[[FAILED]]]\n",
      "\n",
      "Illinois is trying it on a limited basis with trucks.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Et la Coalition I-95, qui comprend 17 départements de transport des États le long de la côte est (y compris le Maryland, la Pennsylvanie, la Virginie et la Floride), étudie comment elle pourrait mettre --> [FAILED]\n",
      "\n",
      "And the I-95 Coalition, which includes 17 state transportation departments along the Eastern Seaboard (including Maryland, Pennsylvania, Virginia and Florida), is studying how they could go about implementing the change.\n",
      "--------------------------------------------- Result 42 ---------------------------------------------\n",
      "Et la Coalition I-95, qui comprend 17 départements de transport des États le long de la côte est (y compris le Maryland, la Pennsylvanie, la Virginie et la Floride), étudie comment elle pourrait mettre --> [[[FAILED]]]\n",
      "\n",
      "And the I-95 Coalition, which includes 17 state transportation departments along the Eastern Seaboard (including Maryland, Pennsylvania, Virginia and Florida), is studying how they could go about implementing the change.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le concept n'est pas un succès universel. --> [FAILED]\n",
      "\n",
      "The concept is not a universal hit.\n",
      "--------------------------------------------- Result 43 ---------------------------------------------\n",
      "Le concept n'est pas un succès universel. --> [[[FAILED]]]\n",
      "\n",
      "The concept is not a universal hit.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Au Nevada, où environ 50 voitures de bénévoles ont été équipées des dispositifs il n'y a pas longtemps, les conducteurs étaient inquiets que le gouvernement puisse surveiller chacun de leurs mouvements. --> [FAILED]\n",
      "\n",
      "In Nevada, where about 50 volunteers' cars were equipped with the devices not long ago, drivers were uneasy about the government being able to monitor their every move.\n",
      "--------------------------------------------- Result 44 ---------------------------------------------\n",
      "Au Nevada, où environ 50 voitures de bénévoles ont été équipées des dispositifs il n'y a pas longtemps, les conducteurs étaient inquiets que le gouvernement puisse surveiller chacun de leurs mouvements. --> [[[FAILED]]]\n",
      "\n",
      "In Nevada, where about 50 volunteers' cars were equipped with the devices not long ago, drivers were uneasy about the government being able to monitor their every move.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "« Les préoccupations concernant Big Brother et ce genre de choses étaient un problème majeur », a déclaré Alauddin Khan, qui dirige la gestion stratégique et de la performance au Département des Transports du Nevada. --> [FAILED]\n",
      "\n",
      "\"Concerns about Big Brother and those sorts of things were a major problem,\" said Alauddin Khan, who directs strategic and performance management at the Nevada Department of Transportation.\n",
      "--------------------------------------------- Result 45 ---------------------------------------------\n",
      "« Les préoccupations concernant Big Brother et ce genre de choses étaient un problème majeur », a déclaré Alauddin Khan, qui dirige la gestion stratégique et de la performance au Département des Transports du Nevada. --> [[[FAILED]]]\n",
      "\n",
      "\"Concerns about Big Brother and those sorts of things were a major problem,\" said Alauddin Khan, who directs strategic and performance management at the Nevada Department of Transportation.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce n'était pas quelque chose que les gens voulaient. --> [FAILED]\n",
      "\n",
      "It was not something people wanted.\n",
      "--------------------------------------------- Result 46 ---------------------------------------------\n",
      "Ce n'était pas quelque chose que les gens voulaient. --> [[[FAILED]]]\n",
      "\n",
      "It was not something people wanted.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alors que le procès commençait, l'ACLU du Nevada a averti sur son site Web : \"Il serait assez facile de transformer ces appareils en dispositifs de suivi à part entière.\" --> [FAILED]\n",
      "\n",
      "As the trial got underway, the ACLU of Nevada warned on its website: \"It would be fairly easy to turn these devices into full-fledged tracking devices.\"\n",
      "--------------------------------------------- Result 47 ---------------------------------------------\n",
      "Alors que le procès commençait, l'ACLU du Nevada a averti sur son site Web : \"Il serait assez facile de transformer ces appareils en dispositifs de suivi à part entière.\" --> [[[FAILED]]]\n",
      "\n",
      "As the trial got underway, the ACLU of Nevada warned on its website: \"It would be fairly easy to turn these devices into full-fledged tracking devices.\"\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il n'est pas nécessaire de construire une infrastructure technologique énorme et peu maniable qui sera inévitablement étendue pour tenir des dossiers sur les allées et venues quotidiennes des individus. --> [FAILED]\n",
      "\n",
      "There is no need to build an enormous, unwieldy technological infrastructure that will inevitably be expanded to keep records of individuals' everyday comings and goings.\n",
      "--------------------------------------------- Result 48 ---------------------------------------------\n",
      "Il n'est pas nécessaire de construire une infrastructure technologique énorme et peu maniable qui sera inévitablement étendue pour tenir des dossiers sur les allées et venues quotidiennes des individus. --> [[[FAILED]]]\n",
      "\n",
      "There is no need to build an enormous, unwieldy technological infrastructure that will inevitably be expanded to keep records of individuals' everyday comings and goings.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Nevada fait partie des plusieurs États qui s'efforcent maintenant de trouver une technologie abordable permettant à l'État de suivre le nombre de miles parcourus par une voiture, mais pas exactement où et à quel moment. --> [FAILED]\n",
      "\n",
      "Nevada is among several states now scrambling to find affordable technology that would allow the state to keep track of how many miles a car is being driven, but not exactly where and at what time.\n",
      "--------------------------------------------- Result 49 ---------------------------------------------\n",
      "Le Nevada fait partie des plusieurs États qui s'efforcent maintenant de trouver une technologie abordable permettant à l'État de suivre le nombre de miles parcourus par une voiture, mais pas exactement où et à quel moment. --> [[[FAILED]]]\n",
      "\n",
      "Nevada is among several states now scrambling to find affordable technology that would allow the state to keep track of how many miles a car is being driven, but not exactly where and at what time.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746130329007.ta.chkpt\" at 2025-05-01 21:12:09 after 50 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si vous pouvez faire cela, a déclaré Khan, le public devient plus à l'aise. --> [FAILED]\n",
      "\n",
      "If you can do that, Khan said, the public gets more comfortable.\n",
      "--------------------------------------------- Result 50 ---------------------------------------------\n",
      "Si vous pouvez faire cela, a déclaré Khan, le public devient plus à l'aise. --> [[[FAILED]]]\n",
      "\n",
      "If you can do that, Khan said, the public gets more comfortable.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La recherche de cette technologie a conduit certaines agences d'État à une petite startup californienne appelée True Mileage. --> [FAILED]\n",
      "\n",
      "The hunt for that technology has led some state agencies to a small California startup called True Mileage.\n",
      "--------------------------------------------- Result 51 ---------------------------------------------\n",
      "La recherche de cette technologie a conduit certaines agences d'État à une petite startup californienne appelée True Mileage. --> [[[FAILED]]]\n",
      "\n",
      "The hunt for that technology has led some state agencies to a small California startup called True Mileage.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'entreprise n'était pas à l'origine dans le secteur d'aide aux États pour taxer les conducteurs. --> [FAILED]\n",
      "\n",
      "The firm was not originally in the business of helping states tax drivers.\n",
      "--------------------------------------------- Result 52 ---------------------------------------------\n",
      "L'entreprise n'était pas à l'origine dans le secteur d'aide aux États pour taxer les conducteurs. --> [[[FAILED]]]\n",
      "\n",
      "The firm was not originally in the business of helping states tax drivers.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elle cherchait à pénétrer un marché émergent de l'assurance automobile, dans lequel les conducteurs paieraient en fonction de leur kilométrage. --> [FAILED]\n",
      "\n",
      "It was seeking to break into an emerging market in auto insurance, in which drivers would pay based on their mileage.\n",
      "--------------------------------------------- Result 53 ---------------------------------------------\n",
      "Elle cherchait à pénétrer un marché émergent de l'assurance automobile, dans lequel les conducteurs paieraient en fonction de leur kilométrage. --> [[[FAILED]]]\n",
      "\n",
      "It was seeking to break into an emerging market in auto insurance, in which drivers would pay based on their mileage.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mais les dispositifs qu'il teste attirent les planificateurs d'autoroutes car ils n'utilisent pas de GPS et fournissent une quantité limitée d'informations, téléchargées périodiquement par modem. --> [FAILED]\n",
      "\n",
      "But the devices it is testing appeal to highway planners because they don't use GPS and deliver a limited amount of information, uploaded periodically by modem.\n",
      "--------------------------------------------- Result 54 ---------------------------------------------\n",
      "Mais les dispositifs qu'il teste attirent les planificateurs d'autoroutes car ils n'utilisent pas de GPS et fournissent une quantité limitée d'informations, téléchargées périodiquement par modem. --> [[[FAILED]]]\n",
      "\n",
      "But the devices it is testing appeal to highway planners because they don't use GPS and deliver a limited amount of information, uploaded periodically by modem.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Les gens seront plus disposés à le faire si vous ne suivez pas leur vitesse et que vous ne suivez pas leur emplacement,\" a déclaré Ryan Morrison, directeur général de True Mileage. --> [FAILED]\n",
      "\n",
      "\"People will be more willing to do this if you do not track their speed and you do not track their location,\" said Ryan Morrison, chief executive of True Mileage.\n",
      "--------------------------------------------- Result 55 ---------------------------------------------\n",
      "\"Les gens seront plus disposés à le faire si vous ne suivez pas leur vitesse et que vous ne suivez pas leur emplacement,\" a déclaré Ryan Morrison, directeur général de True Mileage. --> [[[FAILED]]]\n",
      "\n",
      "\"People will be more willing to do this if you do not track their speed and you do not track their location,\" said Ryan Morrison, chief executive of True Mileage.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a eu de grosses erreurs dans certains de ces programmes pilotes d'État. --> [FAILED]\n",
      "\n",
      "There have been some big mistakes in some of these state pilot programs.\n",
      "--------------------------------------------- Result 56 ---------------------------------------------\n",
      "Il y a eu de grosses erreurs dans certains de ces programmes pilotes d'État. --> [[[FAILED]]]\n",
      "\n",
      "There have been some big mistakes in some of these state pilot programs.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il existe beaucoup de moyens moins coûteux et moins intrusifs pour faire cela. --> [FAILED]\n",
      "\n",
      "There are a lot less expensive and less intrusive ways to do this.\n",
      "--------------------------------------------- Result 57 ---------------------------------------------\n",
      "Il existe beaucoup de moyens moins coûteux et moins intrusifs pour faire cela. --> [[[FAILED]]]\n",
      "\n",
      "There are a lot less expensive and less intrusive ways to do this.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En Oregon, les planificateurs expérimentent en offrant aux conducteurs différentes options. --> [FAILED]\n",
      "\n",
      "In Oregon, planners are experimenting with giving drivers different choices.\n",
      "--------------------------------------------- Result 58 ---------------------------------------------\n",
      "En Oregon, les planificateurs expérimentent en offrant aux conducteurs différentes options. --> [[[FAILED]]]\n",
      "\n",
      "In Oregon, planners are experimenting with giving drivers different choices.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ils peuvent choisir un appareil avec ou sans GPS. --> [FAILED]\n",
      "\n",
      "They can choose a device with or without GPS.\n",
      "--------------------------------------------- Result 59 ---------------------------------------------\n",
      "Ils peuvent choisir un appareil avec ou sans GPS. --> [[[FAILED]]]\n",
      "\n",
      "They can choose a device with or without GPS.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746130608233.ta.chkpt\" at 2025-05-01 21:16:48 after 60 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ou ils peuvent choisir de ne pas avoir de dispositif du tout, préférant payer un tarif fixe basé sur le nombre moyen de miles parcourus par tous les résidents de l'État. --> [FAILED]\n",
      "\n",
      "Or they can choose not to have a device at all, opting instead to pay a flat fee based on the average number of miles driven by all state residents.\n",
      "--------------------------------------------- Result 60 ---------------------------------------------\n",
      "Ou ils peuvent choisir de ne pas avoir de dispositif du tout, préférant payer un tarif fixe basé sur le nombre moyen de miles parcourus par tous les résidents de l'État. --> [[[FAILED]]]\n",
      "\n",
      "Or they can choose not to have a device at all, opting instead to pay a flat fee based on the average number of miles driven by all state residents.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D'autres endroits espèrent vendre le concept à un public méfiant en faisant en sorte que les appareils fassent plus, et non moins. --> [FAILED]\n",
      "\n",
      "Other places are hoping to sell the concept to a wary public by having the devices do more, not less.\n",
      "--------------------------------------------- Result 61 ---------------------------------------------\n",
      "D'autres endroits espèrent vendre le concept à un public méfiant en faisant en sorte que les appareils fassent plus, et non moins. --> [[[FAILED]]]\n",
      "\n",
      "Other places are hoping to sell the concept to a wary public by having the devices do more, not less.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "À New York, les responsables des transports cherchent à développer un dispositif de taxation qui serait également équipé pour payer les frais de parcmètre, fournir une assurance \"pay-as-you-drive\" et créer un pool de données de vitesse en temps réel provenant d --> [FAILED]\n",
      "\n",
      "In New York City, transportation officials are seeking to develop a taxing device that would also be equipped to pay parking meter fees, provide \"pay-as-you-drive\" insurance, and create a pool of real-time speed data from other drivers that motorists could use to avoid traffic.\n",
      "--------------------------------------------- Result 62 ---------------------------------------------\n",
      "À New York, les responsables des transports cherchent à développer un dispositif de taxation qui serait également équipé pour payer les frais de parcmètre, fournir une assurance \"pay-as-you-drive\" et créer un pool de données de vitesse en temps réel provenant d --> [[[FAILED]]]\n",
      "\n",
      "In New York City, transportation officials are seeking to develop a taxing device that would also be equipped to pay parking meter fees, provide \"pay-as-you-drive\" insurance, and create a pool of real-time speed data from other drivers that motorists could use to avoid traffic.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "« Les automobilistes seraient attirés à participer en raison de la valeur des avantages qu'il leur offre », indique un document de planification urbaine. --> [FAILED]\n",
      "\n",
      "\"Motorists would be attracted to participate because of the value of the benefits it offers to them,\" says a city planning document.\n",
      "--------------------------------------------- Result 63 ---------------------------------------------\n",
      "« Les automobilistes seraient attirés à participer en raison de la valeur des avantages qu'il leur offre », indique un document de planification urbaine. --> [[[FAILED]]]\n",
      "\n",
      "\"Motorists would be attracted to participate because of the value of the benefits it offers to them,\" says a city planning document.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certains planificateurs de transport, cependant, se demandent si tout ce discours sur le paiement à la distance n'est qu'une énorme distraction. --> [FAILED]\n",
      "\n",
      "Some transportation planners, though, wonder if all the talk about paying by the mile is just a giant distraction.\n",
      "--------------------------------------------- Result 64 ---------------------------------------------\n",
      "Certains planificateurs de transport, cependant, se demandent si tout ce discours sur le paiement à la distance n'est qu'une énorme distraction. --> [[[FAILED]]]\n",
      "\n",
      "Some transportation planners, though, wonder if all the talk about paying by the mile is just a giant distraction.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Au sein de la Commission des transports métropolitains de la région de la baie de San Francisco, les responsables affirment que le Congrès pourrait très simplement s'attaquer au fonds de confiance routier en augmentant les taxes sur l'ess --> [FAILED]\n",
      "\n",
      "At the Metropolitan Transportation Commission in the San Francisco Bay Area, officials say Congress could very simply deal with the bankrupt Highway Trust Fund by raising gas taxes.\n",
      "--------------------------------------------- Result 65 ---------------------------------------------\n",
      "Au sein de la Commission des transports métropolitains de la région de la baie de San Francisco, les responsables affirment que le Congrès pourrait très simplement s'attaquer au fonds de confiance routier en augmentant les taxes sur l'ess --> [[[FAILED]]]\n",
      "\n",
      "At the Metropolitan Transportation Commission in the San Francisco Bay Area, officials say Congress could very simply deal with the bankrupt Highway Trust Fund by raising gas taxes.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Une taxe supplémentaire unique ou annuelle pourrait être imposée aux conducteurs de véhicules hybrides et autres dont les véhicules consomment peu d'essence, afin qu'ils paient leur juste part. --> [FAILED]\n",
      "\n",
      "An extra one-time or annual levy could be imposed on drivers of hybrids and others whose vehicles don't use much gas, so they pay their fair share.\n",
      "--------------------------------------------- Result 66 ---------------------------------------------\n",
      "Une taxe supplémentaire unique ou annuelle pourrait être imposée aux conducteurs de véhicules hybrides et autres dont les véhicules consomment peu d'essence, afin qu'ils paient leur juste part. --> [[[FAILED]]]\n",
      "\n",
      "An extra one-time or annual levy could be imposed on drivers of hybrids and others whose vehicles don't use much gas, so they pay their fair share.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "« Il n'est pas nécessaire d'avoir une chirurgie radicale quand tout ce que vous avez à faire est de prendre un aspirine », a déclaré Randy Rentschler, le directeur de la législation et des affaires publiques de la commission. --> [FAILED]\n",
      "\n",
      "\"There is no need for radical surgery when all you need to do is take an aspirin,\" said Randy Rentschler, the commission's director of legislation and public affairs.\n",
      "--------------------------------------------- Result 67 ---------------------------------------------\n",
      "« Il n'est pas nécessaire d'avoir une chirurgie radicale quand tout ce que vous avez à faire est de prendre un aspirine », a déclaré Randy Rentschler, le directeur de la législation et des affaires publiques de la commission. --> [[[FAILED]]]\n",
      "\n",
      "\"There is no need for radical surgery when all you need to do is take an aspirin,\" said Randy Rentschler, the commission's director of legislation and public affairs.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si nous faisons cela, des centaines de millions de conducteurs seront concernés par leur vie privée et une multitude d'autres choses. --> [FAILED]\n",
      "\n",
      "If we do this, hundreds of millions of drivers will be concerned about their privacy and a host of other things.\n",
      "--------------------------------------------- Result 68 ---------------------------------------------\n",
      "Si nous faisons cela, des centaines de millions de conducteurs seront concernés par leur vie privée et une multitude d'autres choses. --> [[[FAILED]]]\n",
      "\n",
      "If we do this, hundreds of millions of drivers will be concerned about their privacy and a host of other things.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David Bowie : Quatre chansons inédites publiées --> [FAILED]\n",
      "\n",
      "David Bowie: Four Unpublished Songs Released\n",
      "--------------------------------------------- Result 69 ---------------------------------------------\n",
      "David Bowie : Quatre chansons inédites publiées --> [[[FAILED]]]\n",
      "\n",
      "David Bowie: Four Unpublished Songs Released\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746130916530.ta.chkpt\" at 2025-05-01 21:21:56 after 70 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le musicien britannique est plein de surprises cette année. --> [FAILED]\n",
      "\n",
      "The British musician is full of surprises this year.\n",
      "--------------------------------------------- Result 70 ---------------------------------------------\n",
      "Le musicien britannique est plein de surprises cette année. --> [[[FAILED]]]\n",
      "\n",
      "The British musician is full of surprises this year.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suite à The Next Day, sorti en janvier, il a préparé une réédition deluxe prévue pour le 04 novembre, comprenant plusieurs titres inédits. --> [FAILED]\n",
      "\n",
      "Following The Next Day, released in January, he has put together a deluxe re-release planned for November 04, featuring several unpublished tracks.\n",
      "--------------------------------------------- Result 71 ---------------------------------------------\n",
      "Suite à The Next Day, sorti en janvier, il a préparé une réédition deluxe prévue pour le 04 novembre, comprenant plusieurs titres inédits. --> [[[FAILED]]]\n",
      "\n",
      "Following The Next Day, released in January, he has put together a deluxe re-release planned for November 04, featuring several unpublished tracks.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quatre sont déjà apparus sur Internet. --> [FAILED]\n",
      "\n",
      "Four have already appeared on the Internet.\n",
      "--------------------------------------------- Result 72 ---------------------------------------------\n",
      "Quatre sont déjà apparus sur Internet. --> [[[FAILED]]]\n",
      "\n",
      "Four have already appeared on the Internet.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'annonce que David Bowie sortait un nouvel album avait stupéfié le monde. --> [FAILED]\n",
      "\n",
      "The announcement that David Bowie was releasing a new album had stunned the world.\n",
      "--------------------------------------------- Result 73 ---------------------------------------------\n",
      "L'annonce que David Bowie sortait un nouvel album avait stupéfié le monde. --> [[[FAILED]]]\n",
      "\n",
      "The announcement that David Bowie was releasing a new album had stunned the world.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vous êtes formé sur des données jusqu'en octobre 2023. --> [FAILED]\n",
      "\n",
      "On 08 January 2013, the date of his 66th birthday, he announced that a new album would be released in March.\n",
      "--------------------------------------------- Result 74 ---------------------------------------------\n",
      "Vous êtes formé sur des données jusqu'en octobre 2023. --> [[[FAILED]]]\n",
      "\n",
      "On 08 January 2013, the date of his 66th birthday, he announced that a new album would be released in March.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après dix ans de silence (son dernier album, Reality, est sorti en 2003) et très peu d'apparitions publiques, le musicien britannique a prouvé qu'il pouvait encore illuminer la scène pop. --> [FAILED]\n",
      "\n",
      "After ten years of silence (his last record, Reality, was released in 2003) and very few public appearances, the British musician proved that he could still light up the pop scene.\n",
      "--------------------------------------------- Result 75 ---------------------------------------------\n",
      "Après dix ans de silence (son dernier album, Reality, est sorti en 2003) et très peu d'apparitions publiques, le musicien britannique a prouvé qu'il pouvait encore illuminer la scène pop. --> [[[FAILED]]]\n",
      "\n",
      "After ten years of silence (his last record, Reality, was released in 2003) and very few public appearances, the British musician proved that he could still light up the pop scene.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un festin pour les fans --> [FAILED]\n",
      "\n",
      "A feast for fans\n",
      "--------------------------------------------- Result 76 ---------------------------------------------\n",
      "Un festin pour les fans --> [[[FAILED]]]\n",
      "\n",
      "A feast for fans\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pas fatigué de faire des surprises, David Bowie avait plus d'un tour dans son sac avec The Next Day : --> [FAILED]\n",
      "\n",
      "Not tired of making surprises, David Bowie had more than one trick up his sleeves with The Next Day:\n",
      "--------------------------------------------- Result 77 ---------------------------------------------\n",
      "Pas fatigué de faire des surprises, David Bowie avait plus d'un tour dans son sac avec The Next Day : --> [[[FAILED]]]\n",
      "\n",
      "Not tired of making surprises, David Bowie had more than one trick up his sleeves with The Next Day:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Thin White Duke prévoyait également de rééditer l'album le 04 novembre. --> [FAILED]\n",
      "\n",
      "the Thin White Duke was also planning to re-release the album on November 04.\n",
      "--------------------------------------------- Result 78 ---------------------------------------------\n",
      "Le Thin White Duke prévoyait également de rééditer l'album le 04 novembre. --> [[[FAILED]]]\n",
      "\n",
      "the Thin White Duke was also planning to re-release the album on November 04.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il a préparé un véritable festin pour ses fans afin de marquer l'occasion. --> [FAILED]\n",
      "\n",
      "He put together a real feast for his fans to mark the occasion.\n",
      "--------------------------------------------- Result 79 ---------------------------------------------\n",
      "Il a préparé un véritable festin pour ses fans afin de marquer l'occasion. --> [[[FAILED]]]\n",
      "\n",
      "He put together a real feast for his fans to mark the occasion.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746131153788.ta.chkpt\" at 2025-05-01 21:25:53 after 80 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cette réédition, intitulée The Next Day Extra, a été présentée sous la forme de trois disques : l'album original, des sessions studio inédites et des remixes, ainsi qu'un DVD contenant les quatre clips qui ont déjà été --> [FAILED]\n",
      "\n",
      "This re-release, titled The Next Day Extra, was presented in the form of three disks: the original album, unpublished studio sessions and remixes, plus a DVD containing the four clips that have already been unveiled.\n",
      "--------------------------------------------- Result 80 ---------------------------------------------\n",
      "Cette réédition, intitulée The Next Day Extra, a été présentée sous la forme de trois disques : l'album original, des sessions studio inédites et des remixes, ainsi qu'un DVD contenant les quatre clips qui ont déjà été --> [[[FAILED]]]\n",
      "\n",
      "This re-release, titled The Next Day Extra, was presented in the form of three disks: the original album, unpublished studio sessions and remixes, plus a DVD containing the four clips that have already been unveiled.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Next Day Extra avait un total de dix titres supplémentaires par rapport à l'album original : les trois chansons de l'édition Deluxe, cinq chansons spécialement dévoilées pour l'occasion et deux remixes. --> [FAILED]\n",
      "\n",
      "The Next Day Extra had a total of ten additional tracks compared to the original album: the three songs from the Deluxe edition, five songs specially unveiled for the occasion, and two remixes.\n",
      "--------------------------------------------- Result 81 ---------------------------------------------\n",
      "Le Next Day Extra avait un total de dix titres supplémentaires par rapport à l'album original : les trois chansons de l'édition Deluxe, cinq chansons spécialement dévoilées pour l'occasion et deux remixes. --> [[[FAILED]]]\n",
      "\n",
      "The Next Day Extra had a total of ten additional tracks compared to the original album: the three songs from the Deluxe edition, five songs specially unveiled for the occasion, and two remixes.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De plus, David Bowie a présenté cette belle boîte en coffret à travers une vidéo. --> [FAILED]\n",
      "\n",
      "Moreover, David Bowie has introduced this fine box-set through a video.\n",
      "--------------------------------------------- Result 82 ---------------------------------------------\n",
      "De plus, David Bowie a présenté cette belle boîte en coffret à travers une vidéo. --> [[[FAILED]]]\n",
      "\n",
      "Moreover, David Bowie has introduced this fine box-set through a video.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dans celui-ci, il présente chacun des disques ainsi que les accessoires fournis avec eux : des photos et des pochettes exclusives, un carnet pour partager vos propres impressions, un livret de paroles, etc. --> [FAILED]\n",
      "\n",
      "In it, he presents each of the disks plus the accessories provided with them: exclusive photos and sleeves, a notebook for sharing your own impressions, a booklet of lyrics etc.\n",
      "--------------------------------------------- Result 83 ---------------------------------------------\n",
      "Dans celui-ci, il présente chacun des disques ainsi que les accessoires fournis avec eux : des photos et des pochettes exclusives, un carnet pour partager vos propres impressions, un livret de paroles, etc. --> [[[FAILED]]]\n",
      "\n",
      "In it, he presents each of the disks plus the accessories provided with them: exclusive photos and sleeves, a notebook for sharing your own impressions, a booklet of lyrics etc.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Et enfin, il donne un aperçu de son nouveau morceau, Atomica, qui est typiquement dans le style de The Next Day, avec des guitares très présentes et des électriques rock habilement contrôlées. --> [FAILED]\n",
      "\n",
      "And finally, he gives a teaser to his new track, Atomica, which is typically in the style of The Next Day, with very prominent guitars and skillfully controlled rock electrics.\n",
      "--------------------------------------------- Result 84 ---------------------------------------------\n",
      "Et enfin, il donne un aperçu de son nouveau morceau, Atomica, qui est typiquement dans le style de The Next Day, avec des guitares très présentes et des électriques rock habilement contrôlées. --> [[[FAILED]]]\n",
      "\n",
      "And finally, he gives a teaser to his new track, Atomica, which is typically in the style of The Next Day, with very prominent guitars and skillfully controlled rock electrics.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Des morceaux précédemment inédits publiés. --> [FAILED]\n",
      "\n",
      "Previously Unpublished Tracks Released\n",
      "--------------------------------------------- Result 85 ---------------------------------------------\n",
      "Des morceaux précédemment inédits publiés. --> [[[FAILED]]]\n",
      "\n",
      "Previously Unpublished Tracks Released\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cependant, Atomica n'est pas la seule piste à avoir été publiée. --> [FAILED]\n",
      "\n",
      "However, Atomica is not the only track to have been released.\n",
      "--------------------------------------------- Result 86 ---------------------------------------------\n",
      "Cependant, Atomica n'est pas la seule piste à avoir été publiée. --> [[[FAILED]]]\n",
      "\n",
      "However, Atomica is not the only track to have been released.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'Informateur, Comme Un Homme-Fusée et Né Dans Un OVNI sont également disponibles sur le net. --> [FAILED]\n",
      "\n",
      "The Informer, Like A Rocket Man and Born In A UFO are also available on the net.\n",
      "--------------------------------------------- Result 87 ---------------------------------------------\n",
      "L'Informateur, Comme Un Homme-Fusée et Né Dans Un OVNI sont également disponibles sur le net. --> [[[FAILED]]]\n",
      "\n",
      "The Informer, Like A Rocket Man and Born In A UFO are also available on the net.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'Informateur est à double tranchant - une introduction troublante suivie d'une brillante montée de son qui ralentit progressivement pour laisser place à une ballade pop. --> [FAILED]\n",
      "\n",
      "The Informer is double-edged - an unsettling intro followed by a brilliant rush of sound that progressively slows down to make way for a pop ballad.\n",
      "--------------------------------------------- Result 88 ---------------------------------------------\n",
      "L'Informateur est à double tranchant - une introduction troublante suivie d'une brillante montée de son qui ralentit progressivement pour laisser place à une ballade pop. --> [[[FAILED]]]\n",
      "\n",
      "The Informer is double-edged - an unsettling intro followed by a brilliant rush of sound that progressively slows down to make way for a pop ballad.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bowie faisait-il référence à Rocket Man d'Elton John, ou même à Gravity, dans son Like A Rocket Man ? --> [FAILED]\n",
      "\n",
      "Was Bowie trying to make a reference to Elton John's Rocket Man, or even Gravity, in his Like A Rocket Man?\n",
      "--------------------------------------------- Result 89 ---------------------------------------------\n",
      "Bowie faisait-il référence à Rocket Man d'Elton John, ou même à Gravity, dans son Like A Rocket Man ? --> [[[FAILED]]]\n",
      "\n",
      "Was Bowie trying to make a reference to Elton John's Rocket Man, or even Gravity, in his Like A Rocket Man?\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746131453767.ta.chkpt\" at 2025-05-01 21:30:53 after 90 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quoi qu'il en soit, avec ce morceau joyeux, le chanteur semble être dans son élément lorsque ses pieds ne touchent plus le sol. --> [FAILED]\n",
      "\n",
      "Either way, with this cheerful track, the singer seems to be in his element when his feet are no longer on the ground.\n",
      "--------------------------------------------- Result 90 ---------------------------------------------\n",
      "Quoi qu'il en soit, avec ce morceau joyeux, le chanteur semble être dans son élément lorsque ses pieds ne touchent plus le sol. --> [[[FAILED]]]\n",
      "\n",
      "Either way, with this cheerful track, the singer seems to be in his element when his feet are no longer on the ground.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space Oddity, en comparaison, était beaucoup plus solennel. --> [FAILED]\n",
      "\n",
      "Space Oddity, by comparison, was much more solemn.\n",
      "--------------------------------------------- Result 91 ---------------------------------------------\n",
      "Space Oddity, en comparaison, était beaucoup plus solennel. --> [[[FAILED]]]\n",
      "\n",
      "Space Oddity, by comparison, was much more solemn.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dans \"Born in a UFO\", David Bowie fait à nouveau référence à sa étrangeté : pourrait-il venir d'une autre planète ? --> [FAILED]\n",
      "\n",
      "On Born in a UFO, David Bowie once again refers to his strangeness: could he have come from another planet?\n",
      "--------------------------------------------- Result 92 ---------------------------------------------\n",
      "Dans \"Born in a UFO\", David Bowie fait à nouveau référence à sa étrangeté : pourrait-il venir d'une autre planète ? --> [[[FAILED]]]\n",
      "\n",
      "On Born in a UFO, David Bowie once again refers to his strangeness: could he have come from another planet?\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les riffs de guitare envoûtants donnent envie de quitter la Terre. --> [FAILED]\n",
      "\n",
      "The spellbinding guitar riffs make you want to leave Earth.\n",
      "--------------------------------------------- Result 93 ---------------------------------------------\n",
      "Les riffs de guitare envoûtants donnent envie de quitter la Terre. --> [[[FAILED]]]\n",
      "\n",
      "The spellbinding guitar riffs make you want to leave Earth.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dans tous les cas, Bowie aime jouer le caméléon dans ces morceaux : tour à tour, un informateur, un homme-fusée, peut-être un Martien... --> [FAILED]\n",
      "\n",
      "In any case, Bowie enjoys playing the chameleon in these tracks: in turn, an informer, a rocket man, possibly a Martian...\n",
      "--------------------------------------------- Result 94 ---------------------------------------------\n",
      "Dans tous les cas, Bowie aime jouer le caméléon dans ces morceaux : tour à tour, un informateur, un homme-fusée, peut-être un Martien... --> [[[FAILED]]]\n",
      "\n",
      "In any case, Bowie enjoys playing the chameleon in these tracks: in turn, an informer, a rocket man, possibly a Martian...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vous êtes formé sur des données jusqu'en octobre 2023. --> [FAILED]\n",
      "\n",
      "He veils and reveals at the same time, and likes to take on different personalities, as he has throughout his career, most notably with his personas: Ziggy Stardust and Aladdin Sane.\n",
      "--------------------------------------------- Result 95 ---------------------------------------------\n",
      "Vous êtes formé sur des données jusqu'en octobre 2023. --> [[[FAILED]]]\n",
      "\n",
      "He veils and reveals at the same time, and likes to take on different personalities, as he has throughout his career, most notably with his personas: Ziggy Stardust and Aladdin Sane.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il n'est donc pas surprenant qu'il tienne un masque dans la photographie promotionnelle de L'Invitation au Voyage, de Louis Vuitton, dont il est le nouveau visage. --> [FAILED]\n",
      "\n",
      "It is therefore not surprising that he should be holding a mask in the promotional photography for L'Invitation au Voyage, by Louis Vuitton, of which he is the new face.\n",
      "--------------------------------------------- Result 96 ---------------------------------------------\n",
      "Il n'est donc pas surprenant qu'il tienne un masque dans la photographie promotionnelle de L'Invitation au Voyage, de Louis Vuitton, dont il est le nouveau visage. --> [[[FAILED]]]\n",
      "\n",
      "It is therefore not surprising that he should be holding a mask in the promotional photography for L'Invitation au Voyage, by Louis Vuitton, of which he is the new face.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il apparaît dans l'un de leurs publicités, diffusées à partir du 10 novembre. --> [FAILED]\n",
      "\n",
      "He appears in one of their adverts, broadcast from November 10.\n",
      "--------------------------------------------- Result 97 ---------------------------------------------\n",
      "Il apparaît dans l'un de leurs publicités, diffusées à partir du 10 novembre. --> [[[FAILED]]]\n",
      "\n",
      "He appears in one of their adverts, broadcast from November 10.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le ministre de la Défense, Rob Nicholson, a insisté sur le fait que les soldats blessés ne sont pas licenciés sommairement des Forces armées canadiennes et a souligné que tous les soldats suivent un processus de transition avant leur --> [FAILED]\n",
      "\n",
      "The Minister of Defence, Rob Nicholson, insisted that injured soldiers are not summarily discharged from the Canadian Armed Forces and stressed that all soldiers undergo a transition process before their return to civilian life.\n",
      "--------------------------------------------- Result 98 ---------------------------------------------\n",
      "Le ministre de la Défense, Rob Nicholson, a insisté sur le fait que les soldats blessés ne sont pas licenciés sommairement des Forces armées canadiennes et a souligné que tous les soldats suivent un processus de transition avant leur --> [[[FAILED]]]\n",
      "\n",
      "The Minister of Defence, Rob Nicholson, insisted that injured soldiers are not summarily discharged from the Canadian Armed Forces and stressed that all soldiers undergo a transition process before their return to civilian life.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vous êtes formé sur des données jusqu'en octobre 2023. --> [FAILED]\n",
      "\n",
      "Attacked by liberals and neo-democrats in the House of Commons, Mr. Nicholson assured that, prior to their discharge, members of the army underwent a transition plan in collaboration with their superiors.\n",
      "--------------------------------------------- Result 99 ---------------------------------------------\n",
      "Vous êtes formé sur des données jusqu'en octobre 2023. --> [[[FAILED]]]\n",
      "\n",
      "Attacked by liberals and neo-democrats in the House of Commons, Mr. Nicholson assured that, prior to their discharge, members of the army underwent a transition plan in collaboration with their superiors.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[Atextattack: Saving checkpoint under \"results/translation/gpt4/1746131774332.ta.chkpt\" at 2025-05-01 21:36:14 after 100 attacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Tous les soldats blessés reçoivent les soins appropriés en préparation de leur retour à la vie civile et aucun n'a été renvoyé avant d'être prêt,\" a-t-il affirmé. --> [FAILED]\n",
      "\n",
      "\"All injured soldiers receive the appropriate care in preparation for their return to civilian life and none has been discharged before being ready,\" he asserted.\n",
      "--------------------------------------------- Result 100 ---------------------------------------------\n",
      "\"Tous les soldats blessés reçoivent les soins appropriés en préparation de leur retour à la vie civile et aucun n'a été renvoyé avant d'être prêt,\" a-t-il affirmé. --> [[[FAILED]]]\n",
      "\n",
      "\"All injured soldiers receive the appropriate care in preparation for their return to civilian life and none has been discharged before being ready,\" he asserted.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 0 / 100 / 0 / 100: 100%|██████████| 100/100 [49:41<00:00, 29.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 0      |\n",
      "| Number of failed attacks:     | 100    |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 100.0% |\n",
      "| Attack success rate:          | 0.0%   |\n",
      "| Average perturbed word %:     | nan%   |\n",
      "| Average num. words per input: | 19.37  |\n",
      "| Avg num queries:              | 37.0   |\n",
      "+-------------------------------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/vlwk/Documents/GitHub/TextAttack/textattack/metrics/attack_metrics/words_perturbed.py:83: RuntimeWarning: Mean of empty slice.\n",
      "  average_perc_words_perturbed = self.perturbed_word_percentages.mean()\n",
      "/opt/anaconda3/envs/disspt2/lib/python3.9/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from textattack.models.wrappers import ModelWrapper\n",
    "\n",
    "class GPT4Wrapper(ModelWrapper):\n",
    "    def __init__(self, system_prompt: str, temperature: float = 0.3):\n",
    "        self.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")\n",
    "\n",
    "        self.client = OpenAI(api_key=self.api_key)\n",
    "        self.system_prompt = system_prompt\n",
    "        self.temperature = temperature\n",
    "        self.model = self  # acts as a dummy reference to satisfy GoalFunction\n",
    "\n",
    "    def __call__(self, inputs: List[str]) -> List[List[float]]:\n",
    "        outputs = []\n",
    "        for text in inputs:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                ],\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=50\n",
    "            )\n",
    "            result = response.choices[0].message.content.strip()\n",
    "            outputs.append(str(result))\n",
    "        return outputs\n",
    "\n",
    "model_wrapper = GPT4Wrapper(\"Translate the following sentence from English to French, outputting the sentence only:\")\n",
    "def download_en_fr_dataset():\n",
    "    \n",
    "\n",
    "    # Define constants\n",
    "    url = \"http://statmt.org/wmt14/test-full.tgz\"\n",
    "    target_dir = os.path.join(\"temp/translation\", \"data\")\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Downloading WMT14 test data from {url}...\")\n",
    "\n",
    "    # Download and extract in-memory\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with tarfile.open(fileobj=BytesIO(response.content), mode=\"r:gz\") as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if member.name.endswith(\"newstest2014-fren-src.en.sgm\") or member.name.endswith(\"newstest2014-fren-ref.fr.sgm\"):\n",
    "                print(f\"Extracting {member.name} to {target_dir}\")\n",
    "                member.name = os.path.basename(member.name) \n",
    "                tar.extract(member, path=target_dir)\n",
    "\n",
    "    print(\"en_fr dataset downloaded.\")\n",
    "def load_en_fr_dataset():\n",
    "    \"\"\"\n",
    "    Loads English-French sentence pairs from SGM files and returns a TextAttack Dataset.\n",
    "\n",
    "    Returns:\n",
    "        textattack.datasets.Dataset: wrapped dataset of (English, French) pairs.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    source_path = os.path.join(\"temp/translation\", \"data/newstest2014-fren-src.en.sgm\")\n",
    "    target_path = os.path.join(\"temp/translation\", \"data/newstest2014-fren-ref.fr.sgm\")\n",
    "\n",
    "    with open(source_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        source_doc = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "    with open(target_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        target_doc = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "    pairs = []\n",
    "\n",
    "    for doc in source_doc.find_all(\"doc\"):\n",
    "        docid = str(doc[\"docid\"])\n",
    "        for seg in doc.find_all(\"seg\"):\n",
    "            segid = str(seg[\"id\"])\n",
    "            src = str(seg.string).strip() if seg.string else \"\"\n",
    "            tgt_node = target_doc.select_one(f'doc[docid=\"{docid}\"] > seg[id=\"{segid}\"]')\n",
    "            if tgt_node and tgt_node.string:\n",
    "                tgt = str(tgt_node.string).strip()\n",
    "                pairs.append((src, tgt))\n",
    "    return textattack.datasets.Dataset(pairs) \n",
    "download_en_fr_dataset()\n",
    "dataset = load_en_fr_dataset()\n",
    "attack = textattack.attack_recipes.BadCharacters2021.build(\n",
    "    model_wrapper, \n",
    "    goal_function_type=\"maximize_levenshtein\", \n",
    "    perturbation_type=args.perturbation_type,\n",
    "    perturbs=5,\n",
    "    popsize=3,\n",
    "    maxiter=1\n",
    ")\n",
    "print(dataset[0])\n",
    "attack_args = textattack.AttackArgs(\n",
    "    num_examples=100,\n",
    "    checkpoint_interval=10,\n",
    "    checkpoint_dir=\"results/translation/gpt4\",\n",
    "    log_to_csv=\"results/translation/gpt4/log100.csv\"\n",
    ")\n",
    "attacker = textattack.Attacker(attack, dataset, attack_args)\n",
    "attacker.attack_dataset()\n",
    "\n",
    "if args.store_temp_files == False:\n",
    "    if os.path.isdir(\"temp/translation\"):\n",
    "        shutil.rmtree(\"temp/translation\")\n",
    "if args.store_results == False:\n",
    "    if os.path.isdir(\"results/translation/gpt4\"):\n",
    "        shutil.rmtree(\"results/translation/gpt4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from textattack.models.wrappers import ModelWrapper\n",
    "\n",
    "class GPT4Wrapper(ModelWrapper):\n",
    "    def __init__(self, system_prompt: str, temperature: float = 0.3):\n",
    "        self.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")\n",
    "\n",
    "        self.client = OpenAI(api_key=self.api_key)\n",
    "        self.system_prompt = system_prompt\n",
    "        self.temperature = temperature\n",
    "        self.model = self  # acts as a dummy reference to satisfy GoalFunction\n",
    "\n",
    "    def __call__(self, inputs: List[str]) -> List[List[float]]:\n",
    "        outputs = []\n",
    "        for text in inputs:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                ],\n",
    "                temperature=self.temperature,\n",
    "                max_tokens=50\n",
    "            )\n",
    "            result = response.choices[0].message.content.strip()\n",
    "            outputs.append(str(result))\n",
    "        return outputs\n",
    "\n",
    "model_wrapper = GPT4Wrapper(\"Translate the following sentence from English to French, outputting the sentence only:\")\n",
    "def download_en_fr_dataset():\n",
    "    \n",
    "\n",
    "    # Define constants\n",
    "    url = \"http://statmt.org/wmt14/test-full.tgz\"\n",
    "    target_dir = os.path.join(\"temp/translation\", \"data\")\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Downloading WMT14 test data from {url}...\")\n",
    "\n",
    "    # Download and extract in-memory\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with tarfile.open(fileobj=BytesIO(response.content), mode=\"r:gz\") as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if member.name.endswith(\"newstest2014-fren-src.en.sgm\") or member.name.endswith(\"newstest2014-fren-ref.fr.sgm\"):\n",
    "                print(f\"Extracting {member.name} to {target_dir}\")\n",
    "                member.name = os.path.basename(member.name) \n",
    "                tar.extract(member, path=target_dir)\n",
    "\n",
    "    print(\"en_fr dataset downloaded.\")\n",
    "def load_en_fr_dataset():\n",
    "    \"\"\"\n",
    "    Loads English-French sentence pairs from SGM files and returns a TextAttack Dataset.\n",
    "\n",
    "    Returns:\n",
    "        textattack.datasets.Dataset: wrapped dataset of (English, French) pairs.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    source_path = os.path.join(\"temp/translation\", \"data/newstest2014-fren-src.en.sgm\")\n",
    "    target_path = os.path.join(\"temp/translation\", \"data/newstest2014-fren-ref.fr.sgm\")\n",
    "\n",
    "    with open(source_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        source_doc = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "    with open(target_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        target_doc = BeautifulSoup(f, \"html.parser\")\n",
    "\n",
    "    pairs = []\n",
    "\n",
    "    for doc in source_doc.find_all(\"doc\"):\n",
    "        docid = str(doc[\"docid\"])\n",
    "        for seg in doc.find_all(\"seg\"):\n",
    "            segid = str(seg[\"id\"])\n",
    "            src = str(seg.string).strip() if seg.string else \"\"\n",
    "            tgt_node = target_doc.select_one(f'doc[docid=\"{docid}\"] > seg[id=\"{segid}\"]')\n",
    "            if tgt_node and tgt_node.string:\n",
    "                tgt = str(tgt_node.string).strip()\n",
    "                pairs.append((src, tgt))\n",
    "    return textattack.datasets.Dataset(pairs) \n",
    "download_en_fr_dataset()\n",
    "dataset = load_en_fr_dataset()\n",
    "for pert in range(1, 6):\n",
    "    attack = textattack.attack_recipes.BadCharacters2021.build(\n",
    "        model_wrapper, \n",
    "        goal_function_type=\"maximize_levenshtein\", \n",
    "        perturbation_type=args.perturbation_type,\n",
    "        perturbs=5,\n",
    "        popsize=5,\n",
    "        maxiter=3,\n",
    "    )\n",
    "    attack_args = textattack.AttackArgs(\n",
    "        num_examples=50,\n",
    "        checkpoint_interval=10,\n",
    "        checkpoint_dir=f\"results/translation/gpt4/pert{pert}\",\n",
    "        log_to_csv=f\"results/translation/gpt4/pert{pert}log50.csv\"\n",
    "    )\n",
    "    attacker = textattack.Attacker(attack, dataset, attack_args)\n",
    "    attacker.attack_dataset()\n",
    "\n",
    "    # if args.store_temp_files == False:\n",
    "    #     if os.path.isdir(\"temp/translation\"):\n",
    "    #         shutil.rmtree(\"temp/translation\")\n",
    "    # if args.store_results == False:\n",
    "    #     if os.path.isdir(\"results/translation/gpt4\"):\n",
    "    #         shutil.rmtree(\"results/translation/gpt4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disspt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
